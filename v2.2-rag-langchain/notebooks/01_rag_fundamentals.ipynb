{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3fjbNIIQXNx"
      },
      "source": [
        "# RAG Fundamentals for Fashion Search\n",
        "\n",
        "**Project:** AI Fashion Assistant v2.2  \n",
        "**Focus:** Retrieval-Augmented Generation from scratch  \n",
        "**Author:** Hatice Baydemir  \n",
        "**Date:** January 2, 2026\n",
        "\n",
        "---\n",
        "\n",
        "## What is RAG?\n",
        "\n",
        "**Retrieval-Augmented Generation** combines:\n",
        "1. **Retrieval:** Find relevant documents from knowledge base\n",
        "2. **Augmentation:** Add retrieved context to LLM prompt\n",
        "3. **Generation:** LLM generates answer using context\n",
        "\n",
        "**Why RAG for Fashion?**\n",
        "- Product catalog as knowledge base (44,417 products)\n",
        "- Natural language queries (\"summer dress for beach wedding\")\n",
        "- Contextual recommendations with reasoning\n",
        "- Explainable results (cite specific products)\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "‚úÖ Understand RAG architecture  \n",
        "‚úÖ Implement RAG from scratch (no frameworks)  \n",
        "‚úÖ Apply to fashion product search  \n",
        "‚úÖ Evaluate retrieval quality  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzVC9yTOQXNz"
      },
      "source": [
        "## 1. Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkbZ8CqKQXNz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366604109,
          "user_tz": -180,
          "elapsed": 17245,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "a2d50210-4c86-4acf-9d24-b9e93aac624b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Drive mounted\n",
            "üìÅ /content/drive/MyDrive/ai_fashion_assistant_v2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/ai_fashion_assistant_v2')\n",
        "\n",
        "print('‚úÖ Drive mounted')\n",
        "print(f'üìÅ {os.getcwd()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1qIrUD5QXN0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366612539,
          "user_tz": -180,
          "elapsed": 8418,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "d384875a-d446-4c89-80df-9bd0fe78b329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Packages installed!\n",
            "   - GROQ (LLM)\n",
            "   - Sentence Transformers (embeddings)\n",
            "   - FAISS (vector search)\n"
          ]
        }
      ],
      "source": [
        "# Install minimal dependencies\n",
        "!pip install -q groq sentence-transformers faiss-cpu\n",
        "\n",
        "print('‚úÖ Packages installed!')\n",
        "print('   - GROQ (LLM)')\n",
        "print('   - Sentence Transformers (embeddings)')\n",
        "print('   - FAISS (vector search)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXNEY6-JQXN2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366648623,
          "user_tz": -180,
          "elapsed": 36083,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "19864e54-b6b7-4233-c941-856ee9154074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Imports successful\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict\n",
        "from groq import Groq\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "print('‚úÖ Imports successful')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jv2JrbPQXN3"
      },
      "source": [
        "## 2. Load Fashion Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNyIO7vZQXN4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366662847,
          "user_tz": -180,
          "elapsed": 14222,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "ed52f921-05c6-45c5-e463-bd3973203938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data loaded!\n",
            "   Products: 44,417\n",
            "   Text embeddings: (44417, 768)\n",
            "   Image embeddings: (44417, 768)\n"
          ]
        }
      ],
      "source": [
        "# Load metadata\n",
        "metadata = pd.read_csv('data/processed/meta_ssot.csv')\n",
        "\n",
        "# Load pre-computed embeddings\n",
        "text_emb = np.load('v2.0-baseline/embeddings/text/mpnet_768d.npy')\n",
        "image_emb = np.load('v2.0-baseline/embeddings/image/clip_image_768d_normalized.npy')\n",
        "\n",
        "# Normalize text embeddings for cosine similarity\n",
        "text_emb_norm = text_emb / np.linalg.norm(text_emb, axis=1, keepdims=True)\n",
        "\n",
        "print(f'‚úÖ Data loaded!')\n",
        "print(f'   Products: {len(metadata):,}')\n",
        "print(f'   Text embeddings: {text_emb.shape}')\n",
        "print(f'   Image embeddings: {image_emb.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQzO1Z6aQXN5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366662864,
          "user_tz": -180,
          "elapsed": 18,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "909d75aa-eb7a-453e-a84c-ffaa72e2a147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Sample Product:\n",
            "   Name: Turtle Check Men Navy Blue Shirt\n",
            "   Category: Apparel\n",
            "   Type: Shirts\n",
            "   Color: Navy Blue\n",
            "   Gender: Men\n",
            "   Season: Fall\n"
          ]
        }
      ],
      "source": [
        "# Inspect sample product\n",
        "sample = metadata.iloc[0]\n",
        "print('üì¶ Sample Product:')\n",
        "print(f'   Name: {sample[\"productDisplayName\"]}')\n",
        "print(f'   Category: {sample[\"masterCategory\"]}')\n",
        "print(f'   Type: {sample[\"articleType\"]}')\n",
        "print(f'   Color: {sample[\"baseColour\"]}')\n",
        "print(f'   Gender: {sample[\"gender\"]}')\n",
        "print(f'   Season: {sample[\"season\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2RJoP99QXN6"
      },
      "source": [
        "## 3. Create Product Documents\n",
        "\n",
        "Transform structured data into text documents for RAG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAfelUVwQXN7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366665342,
          "user_tz": -180,
          "elapsed": 2477,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "e9c97816-6a16-416a-f237-a886f35537bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created 44,417 product documents\n",
            "\n",
            "üìÑ Sample document:\n",
            "Turtle Check Men Navy Blue Shirt. \n",
            "Category: Apparel. \n",
            "Type: Shirts. \n",
            "Color: Navy Blue. \n",
            "Gender: Men. \n",
            "Season: Fall. \n",
            "Usage: Casual.\n"
          ]
        }
      ],
      "source": [
        "def create_product_document(row) -> str:\n",
        "    \"\"\"Convert product metadata to text document\"\"\"\n",
        "    return f\"\"\"{row['productDisplayName']}.\n",
        "Category: {row.get('masterCategory', 'Unknown')}.\n",
        "Type: {row.get('articleType', 'Unknown')}.\n",
        "Color: {row.get('baseColour', 'Unknown')}.\n",
        "Gender: {row.get('gender', 'Unisex')}.\n",
        "Season: {row.get('season', 'All')}.\n",
        "Usage: {row.get('usage', 'Casual')}.\"\"\"\n",
        "\n",
        "# Create documents for all products\n",
        "product_docs = [create_product_document(row) for _, row in metadata.iterrows()]\n",
        "\n",
        "print(f'‚úÖ Created {len(product_docs):,} product documents')\n",
        "print(f'\\nüìÑ Sample document:')\n",
        "print(product_docs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeOCULrBQXN7"
      },
      "source": [
        "## 4. Build FAISS Vector Index\n",
        "\n",
        "FAISS (Facebook AI Similarity Search) enables fast nearest neighbor search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwZOlvcAQXN7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366665538,
          "user_tz": -180,
          "elapsed": 192,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "7cd3fe55-9ce6-4721-c53c-4263625fb668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building FAISS index...\n",
            "‚úÖ FAISS index built!\n",
            "   Dimension: 768d\n",
            "   Vectors: 44,417\n",
            "   Index type: IndexFlatIP (cosine similarity)\n"
          ]
        }
      ],
      "source": [
        "print('Building FAISS index...')\n",
        "\n",
        "# Create FAISS index (Inner Product = Cosine Similarity for normalized vectors)\n",
        "dimension = text_emb_norm.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "index.add(text_emb_norm.astype('float32'))\n",
        "\n",
        "print(f'‚úÖ FAISS index built!')\n",
        "print(f'   Dimension: {dimension}d')\n",
        "print(f'   Vectors: {index.ntotal:,}')\n",
        "print(f'   Index type: IndexFlatIP (cosine similarity)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_kqRvBvQXN8"
      },
      "source": [
        "## 5. Setup GROQ LLM\n",
        "\n",
        "GROQ provides fast inference for Llama models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU4ut_neQXN8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366727013,
          "user_tz": -180,
          "elapsed": 64,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "763b260c-ec40-42eb-ba26-863896228a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GROQ LLM configured\n",
            "   Model: Llama-3.3-70B-Versatile\n",
            "   Temperature: 0.1\n",
            "‚ö†Ô∏è  Remember to add your API key above!\n"
          ]
        }
      ],
      "source": [
        "# GROQ API configuration\n",
        "GROQ_API_KEY = \"YOUR_GROQ_API_KEY_HERE\"  # ‚ö†Ô∏è REPLACE THIS!\n",
        "\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "def generate_answer(prompt: str, max_tokens: int = 500) -> str:\n",
        "    \"\"\"Generate answer using GROQ LLM\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.1,  # Low temperature for consistency\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "print('‚úÖ GROQ LLM configured')\n",
        "print('   Model: Llama-3.3-70B-Versatile')\n",
        "print('   Temperature: 0.1')\n",
        "print('‚ö†Ô∏è  Remember to add your API key above!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNhWVFfBQXN8"
      },
      "source": [
        "## 6. RAG Pipeline Implementation\n",
        "\n",
        "Three-stage pipeline: Retrieve ‚Üí Augment ‚Üí Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AeF6HfnQXN8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366735031,
          "user_tz": -180,
          "elapsed": 5040,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "6d41bb3a-e48c-4134-acca-7e41a3c412d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sentence encoder loaded\n"
          ]
        }
      ],
      "source": [
        "# Initialize encoder (done once)\n",
        "encoder = SentenceTransformer(\n",
        "    'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n",
        ")\n",
        "print('‚úÖ Sentence encoder loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aksEL2cKQXN8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366735064,
          "user_tz": -180,
          "elapsed": 14,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "0a4d0bac-ebef-463d-b132-943d3da7dfaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ RAG pipeline function ready!\n"
          ]
        }
      ],
      "source": [
        "def rag_pipeline(query: str, k: int = 5) -> Dict:\n",
        "    \"\"\"\n",
        "    Complete RAG pipeline for fashion product search.\n",
        "\n",
        "    Args:\n",
        "        query: Natural language query\n",
        "        k: Number of products to retrieve\n",
        "\n",
        "    Returns:\n",
        "        Dict with query, answer, retrieved products, scores\n",
        "    \"\"\"\n",
        "\n",
        "    # STAGE 1: RETRIEVE\n",
        "    # Encode query\n",
        "    query_emb = encoder.encode([query])[0]\n",
        "    query_emb = query_emb / np.linalg.norm(query_emb)  # Normalize\n",
        "\n",
        "    # Search FAISS index\n",
        "    scores, indices = index.search(\n",
        "        query_emb.reshape(1, -1).astype('float32'),\n",
        "        k\n",
        "    )\n",
        "\n",
        "    # Get retrieved products\n",
        "    retrieved_products = [product_docs[i] for i in indices[0]]\n",
        "\n",
        "    # STAGE 2: AUGMENT\n",
        "    # Create context from retrieved products\n",
        "    context = \"\\n\\n\".join([\n",
        "        f\"{i+1}. {prod}\"\n",
        "        for i, prod in enumerate(retrieved_products)\n",
        "    ])\n",
        "\n",
        "    # Create RAG prompt\n",
        "    prompt = f\"\"\"You are a fashion shopping assistant. Recommend products based on the user's query.\n",
        "\n",
        "Available Products:\n",
        "{context}\n",
        "\n",
        "User Query: {query}\n",
        "\n",
        "Recommendation (be specific, mention product names):\"\"\"\n",
        "\n",
        "    # STAGE 3: GENERATE\n",
        "    answer = generate_answer(prompt)\n",
        "\n",
        "    return {\n",
        "        'query': query,\n",
        "        'answer': answer,\n",
        "        'retrieved_products': retrieved_products,\n",
        "        'scores': scores[0].tolist(),\n",
        "        'indices': indices[0].tolist()\n",
        "    }\n",
        "\n",
        "print('‚úÖ RAG pipeline function ready!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDAy5UmbQXN9"
      },
      "source": [
        "## 7. Test RAG System\n",
        "\n",
        "Run test queries to validate the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OocfCoE8QXN9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366738452,
          "user_tz": -180,
          "elapsed": 772,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "051f43fc-f403-44ca-9b4b-934e789d070b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Query: \"I need a blue shirt for summer\"\n",
            "\n",
            "Processing...\n",
            "\n",
            "======================================================================\n",
            "üìä RETRIEVAL:\n",
            "   Top match score: 0.765\n",
            "   Products retrieved: 5\n",
            "\n",
            "üìÑ Retrieved Products:\n",
            "   1. Scullers For Her Check Blue Shirt. \n",
            "Category: Apparel. \n",
            "Type: Shirts. \n",
            "Color: Bl...\n",
            "   2. s.Oliver Men's All you Need Blue T-shirt. \n",
            "Category: Apparel. \n",
            "Type: Tshirts. \n",
            "C...\n",
            "   3. Scullers For Her Striped Blue Shirt. \n",
            "Category: Apparel. \n",
            "Type: Shirts. \n",
            "Color: ...\n",
            "\n",
            "ü§ñ RAG ANSWER:\n",
            "Based on your query, I'd be happy to recommend some blue shirts for summer. Here are a few options:\n",
            "\n",
            "For Women: You may like the Scullers For Her Check Blue Shirt or the Scullers For Her Striped Blue Shirt, both of which are perfect for casual summer wear.\n",
            "\n",
            "For Men: I'd suggest the s.Oliver Men's All you Need Blue T-shirt, which is a great option for casual summer outings.\n",
            "\n",
            "For Kids or those who prefer unisex options: You can consider the Tantra Kid's Cool Royal Blue Kidswear or the Tantra Kid's Unisex Caution Blue Kidswear, both of which are suitable for summer and have a casual vibe.\n",
            "\n",
            "Let me know if you have any specific preferences (e.g. gender, style) that can help me narrow down the options for you!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Single test query\n",
        "test_query = \"I need a blue shirt for summer\"\n",
        "\n",
        "print(f'üîç Query: \"{test_query}\"')\n",
        "print('\\nProcessing...')\n",
        "\n",
        "result = rag_pipeline(test_query, k=5)\n",
        "\n",
        "print('\\n' + '='*70)\n",
        "print('üìä RETRIEVAL:')\n",
        "print(f'   Top match score: {result[\"scores\"][0]:.3f}')\n",
        "print(f'   Products retrieved: {len(result[\"retrieved_products\"])}')\n",
        "\n",
        "print('\\nüìÑ Retrieved Products:')\n",
        "for i, prod in enumerate(result['retrieved_products'][:3], 1):\n",
        "    print(f'   {i}. {prod[:80]}...')\n",
        "\n",
        "print('\\nü§ñ RAG ANSWER:')\n",
        "print(result['answer'])\n",
        "print('='*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7bZPQ94QXN9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1767366743937,
          "user_tz": -180,
          "elapsed": 2683,
          "user": {
            "displayName": "Hatice Baydemir",
            "userId": "09255724962739063380"
          }
        },
        "outputId": "ee422b66-e1c4-4147-f4e8-573dfd4135aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ RUNNING MULTIPLE TESTS\n",
            "======================================================================\n",
            "\n",
            "[1/4] Query: \"Show me casual shoes for men\"\n",
            "   Score: 0.827\n",
            "   Answer preview: Based on your query, I'd be happy to recommend some casual shoes for men. Here are a few options:\n",
            "\n",
            "1...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "[2/4] Query: \"What red dresses do you have?\"\n",
            "   Score: 0.778\n",
            "   Answer preview: We have a variety of beautiful red dresses available for you. You can choose from the following opti...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "[3/4] Query: \"Winter jackets\"\n",
            "   Score: 0.699\n",
            "   Answer preview: Based on your query for winter jackets, I would recommend the following products:\n",
            "\n",
            "1. Just Natural M...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "[4/4] Query: \"Formal wear for office\"\n",
            "   Score: 0.574\n",
            "   Answer preview: Based on your query for formal wear for the office, I would recommend the Avirate Black Formal Dress...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚úÖ All tests complete!\n"
          ]
        }
      ],
      "source": [
        "# Multiple test queries\n",
        "test_queries = [\n",
        "    \"Show me casual shoes for men\",\n",
        "    \"What red dresses do you have?\",\n",
        "    \"Winter jackets\",\n",
        "    \"Formal wear for office\"\n",
        "]\n",
        "\n",
        "print('üß™ RUNNING MULTIPLE TESTS')\n",
        "print('='*70)\n",
        "\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f'\\n[{i}/{len(test_queries)}] Query: \"{query}\"')\n",
        "\n",
        "    result = rag_pipeline(query, k=5)\n",
        "\n",
        "    print(f'   Score: {result[\"scores\"][0]:.3f}')\n",
        "    print(f'   Answer preview: {result[\"answer\"][:100]}...')\n",
        "    print('-'*70)\n",
        "\n",
        "print('\\n‚úÖ All tests complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYkyLNrqQXN9"
      },
      "source": [
        "## 8. Summary\n",
        "\n",
        "**What we built:**\n",
        "- ‚úÖ Complete RAG pipeline from scratch\n",
        "- ‚úÖ FAISS vector search (44,417 products)\n",
        "- ‚úÖ GROQ LLM integration\n",
        "- ‚úÖ Natural language fashion recommendations\n",
        "\n",
        "**Key components:**\n",
        "1. **Retrieve:** FAISS finds similar products using embeddings\n",
        "2. **Augment:** Context injected into LLM prompt\n",
        "3. **Generate:** LLM creates natural language recommendations\n",
        "\n",
        "**Next steps:**\n",
        "- Notebook 2: Production-ready pipeline class\n",
        "- Notebook 3: Comprehensive evaluation\n",
        "\n",
        "---\n",
        "\n",
        "**Framework-agnostic implementation - Full control, minimal dependencies!** üöÄ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
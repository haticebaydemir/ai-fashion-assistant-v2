{"cells":[{"cell_type":"markdown","metadata":{"id":"aX_Iz2fZtxIb"},"source":["# Comprehensive Evaluation Metrics\n","\n","**Phase 9, Notebook 1/3** - Beyond basic recall and NDCG\n","\n","---\n","\n","## Motivation\n","\n","Our current evaluation uses Recall@10 (48%) and NDCG@10 (86.6%). These are\n","good metrics, but they don't tell the whole story. We're missing:\n","\n","- **Diversity**: Are we showing varied products or just similar items?\n","- **Novelty**: Are we recommending obvious choices or discovering new items?\n","- **Coverage**: What percentage of our catalog gets recommended?\n","\n","This notebook implements a comprehensive metrics suite to better understand\n","system performance from multiple angles.\n","\n","---"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MitLmw-txIc","executionInfo":{"status":"ok","timestamp":1766434820039,"user_tz":-180,"elapsed":15546,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"b05bc198-be2c-489f-9b54-203f78efd70c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Drive mounted\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=False)\n","\n","print(\"Drive mounted\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oK8mz9B2txId","executionInfo":{"status":"ok","timestamp":1766434820641,"user_tz":-180,"elapsed":584,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"36b1b873-37cd-4b86-c1d7-5f434107f236"},"outputs":[{"output_type":"stream","name":"stdout","text":["Imports ready\n"]}],"source":["import os\n","import sys\n","import json\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from typing import Dict, List, Tuple, Set\n","from collections import defaultdict, Counter\n","from scipy.spatial.distance import cosine\n","from itertools import combinations\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","PROJECT_ROOT = Path(\"/content/drive/MyDrive/ai_fashion_assistant_v2\")\n","sys.path.insert(0, str(PROJECT_ROOT))\n","\n","print(\"Imports ready\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pD8QMfVtxIe","executionInfo":{"status":"ok","timestamp":1766434821527,"user_tz":-180,"elapsed":883,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"7b756ef8-cc26-4bff-d05b-a3e74c51aab2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Working directory: /content/drive/MyDrive/ai_fashion_assistant_v2/evaluation/comprehensive\n","\n","Creating synthetic data for testing...\n","\n","============================================================\n","Created synthetic catalog: 1,000 products\n","  Categories: 6\n","  Brands: 6\n","  Colors: 6\n","\n","Created test queries: 10\n","Created ground truth: 39 relevance judgments\n","  Avg relevant per query: 3.9\n","\n","============================================================\n","Synthetic data ready\n"]}],"source":["# ============================================================\n","# SETUP & CREATE SYNTHETIC DATA\n","# ============================================================\n","\n","EVAL_DIR = PROJECT_ROOT / \"evaluation/comprehensive\"\n","EVAL_DIR.mkdir(parents=True, exist_ok=True)\n","\n","print(f\"Working directory: {EVAL_DIR}\")\n","print(\"\\nCreating synthetic data for testing...\\n\")\n","print(\"=\" * 60)\n","\n","# Create synthetic product catalog\n","np.random.seed(42)\n","\n","num_products = 1000\n","categories = ['ayakkabı', 'elbise', 'pantolon', 'gömlek', 'ceket', 'çanta']\n","colors = ['beyaz', 'siyah', 'mavi', 'kırmızı', 'yeşil', 'gri']\n","brands = ['nike', 'adidas', 'zara', 'h&m', 'mango', 'koton']\n","genders = ['kadın', 'erkek', 'unisex']\n","\n","products_df = pd.DataFrame({\n","    'product_id': range(num_products),\n","    'name': [f'Product {i}' for i in range(num_products)],\n","    'category': np.random.choice(categories, num_products),\n","    'color': np.random.choice(colors, num_products),\n","    'brand': np.random.choice(brands, num_products),\n","    'gender': np.random.choice(genders, num_products),\n","    'price': np.random.uniform(50, 1000, num_products)\n","})\n","\n","products_df.set_index('product_id', inplace=True)\n","\n","print(f\"Created synthetic catalog: {len(products_df):,} products\")\n","print(f\"  Categories: {products_df['category'].nunique()}\")\n","print(f\"  Brands: {products_df['brand'].nunique()}\")\n","print(f\"  Colors: {products_df['color'].nunique()}\")\n","\n","# Create synthetic test queries\n","queries_df = pd.DataFrame({\n","    'query_id': range(10),\n","    'query_text': [\n","        'beyaz nike ayakkabı',\n","        'siyah elbise',\n","        'mavi pantolon',\n","        'kırmızı çanta',\n","        'spor ayakkabı',\n","        'kadın gömlek',\n","        'erkek ceket',\n","        'zara elbise',\n","        'beyaz ayakkabı',\n","        'siyah çanta'\n","    ]\n","})\n","\n","print(f\"\\nCreated test queries: {len(queries_df)}\")\n","\n","# Create synthetic ground truth\n","gt_data = []\n","for qid in queries_df['query_id']:\n","    # Each query has 3-5 relevant products\n","    num_relevant = np.random.randint(3, 6)\n","    relevant_products = np.random.choice(products_df.index, num_relevant, replace=False)\n","    relevances = np.random.choice([1, 2, 3], num_relevant)  # 1=low, 2=med, 3=high\n","\n","    for pid, rel in zip(relevant_products, relevances):\n","        gt_data.append({\n","            'query_id': qid,\n","            'product_id': pid,\n","            'relevance': rel\n","        })\n","\n","gt_df = pd.DataFrame(gt_data)\n","\n","print(f\"Created ground truth: {len(gt_df)} relevance judgments\")\n","print(f\"  Avg relevant per query: {len(gt_df) / len(queries_df):.1f}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"Synthetic data ready\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o8vN7cVbtxIe","executionInfo":{"status":"ok","timestamp":1766434821559,"user_tz":-180,"elapsed":11,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"9ee5ea82-8fd3-4307-ab0b-3fa9aa7cf96b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Implementing diversity metrics...\n","\n","============================================================\n","Diversity metrics implemented:\n","  - ILS (intra-list similarity)\n","  - Category diversity\n","\n","============================================================\n"]}],"source":["# ============================================================\n","# DIVERSITY METRICS\n","# ============================================================\n","\n","print(\"\\nImplementing diversity metrics...\\n\")\n","print(\"=\" * 60)\n","\n","def intra_list_similarity(product_ids: List[int], embeddings: np.ndarray) -> float:\n","    \"\"\"Average pairwise similarity. Lower = more diverse.\"\"\"\n","    if len(product_ids) < 2:\n","        return 0.0\n","\n","    similarities = []\n","    for i, j in combinations(range(len(product_ids)), 2):\n","        if product_ids[i] < len(embeddings) and product_ids[j] < len(embeddings):\n","            sim = 1 - cosine(embeddings[product_ids[i]], embeddings[product_ids[j]])\n","            similarities.append(sim)\n","\n","    return np.mean(similarities) if similarities else 0.0\n","\n","\n","def category_diversity(product_ids: List[int], products_df: pd.DataFrame) -> float:\n","    \"\"\"Ratio of unique categories to total items.\"\"\"\n","    if not product_ids:\n","        return 0.0\n","\n","    valid_ids = [pid for pid in product_ids if pid in products_df.index]\n","    if not valid_ids:\n","        return 0.0\n","\n","    categories = products_df.loc[valid_ids, 'category'].unique()\n","    return len(categories) / len(valid_ids)\n","\n","\n","print(\"Diversity metrics implemented:\")\n","print(\"  - ILS (intra-list similarity)\")\n","print(\"  - Category diversity\")\n","print(\"\\n\" + \"=\" * 60)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvelWtEMtxIf","executionInfo":{"status":"ok","timestamp":1766434821602,"user_tz":-180,"elapsed":42,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"2db5033f-1130-4b45-feff-b8c769975c88"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Implementing novelty metrics...\n","\n","============================================================\n","Novelty metrics implemented:\n","  Computed popularity for 1,000 items\n","  Avg popularity: 0.695\n","\n","============================================================\n"]}],"source":["# ============================================================\n","# NOVELTY METRICS\n","# ============================================================\n","\n","print(\"\\nImplementing novelty metrics...\\n\")\n","print(\"=\" * 60)\n","\n","def compute_item_popularity(products_df: pd.DataFrame) -> Dict[int, float]:\n","    \"\"\"Compute popularity scores.\"\"\"\n","    popularity = {}\n","\n","    for idx in products_df.index:\n","        score = 0.5  # base\n","        row = products_df.loc[idx]\n","\n","        # Popular colors\n","        if row['color'] in ['beyaz', 'siyah', 'mavi']:\n","            score += 0.2\n","\n","        # Popular brands\n","        if row['brand'] in ['nike', 'adidas', 'zara']:\n","            score += 0.2\n","\n","        popularity[idx] = min(score, 1.0)\n","\n","    return popularity\n","\n","\n","def novelty_at_k(product_ids: List[int], popularity: Dict[int, float]) -> float:\n","    \"\"\"Average novelty (inverse popularity).\"\"\"\n","    if not product_ids:\n","        return 0.0\n","\n","    novelties = [1 - popularity.get(pid, 0.5) for pid in product_ids]\n","    return np.mean(novelties)\n","\n","\n","item_popularity = compute_item_popularity(products_df)\n","\n","print(\"Novelty metrics implemented:\")\n","print(f\"  Computed popularity for {len(item_popularity):,} items\")\n","print(f\"  Avg popularity: {np.mean(list(item_popularity.values())):.3f}\")\n","print(\"\\n\" + \"=\" * 60)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LN6e1ZcStxIf","executionInfo":{"status":"ok","timestamp":1766434821622,"user_tz":-180,"elapsed":5,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"df1416be-bf06-4b9b-f3de-62acb0190357"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Implementing ranking quality metrics...\n","\n","============================================================\n","Ranking metrics implemented:\n","  - MAP (mean average precision)\n","  - Success@K\n","  - Recall@K\n","\n","============================================================\n"]}],"source":["# ============================================================\n","# RANKING QUALITY METRICS\n","# ============================================================\n","\n","print(\"\\nImplementing ranking quality metrics...\\n\")\n","print(\"=\" * 60)\n","\n","def mean_average_precision(product_ids: List[int], relevant_ids: Set[int]) -> float:\n","    \"\"\"MAP - mean average precision.\"\"\"\n","    if not relevant_ids:\n","        return 0.0\n","\n","    precisions = []\n","    num_relevant = 0\n","\n","    for i, pid in enumerate(product_ids):\n","        if pid in relevant_ids:\n","            num_relevant += 1\n","            precision_at_i = num_relevant / (i + 1)\n","            precisions.append(precision_at_i)\n","\n","    return np.mean(precisions) if precisions else 0.0\n","\n","\n","def success_at_k(product_ids: List[int], relevant_ids: Set[int]) -> float:\n","    \"\"\"Success@K - at least one relevant item?\"\"\"\n","    return 1.0 if any(pid in relevant_ids for pid in product_ids) else 0.0\n","\n","\n","def recall_at_k(product_ids: List[int], relevant_ids: Set[int]) -> float:\n","    \"\"\"Recall@K - what fraction of relevant items retrieved?\"\"\"\n","    if not relevant_ids:\n","        return 0.0\n","\n","    retrieved_relevant = len(set(product_ids) & relevant_ids)\n","    return retrieved_relevant / len(relevant_ids)\n","\n","\n","print(\"Ranking metrics implemented:\")\n","print(\"  - MAP (mean average precision)\")\n","print(\"  - Success@K\")\n","print(\"  - Recall@K\")\n","print(\"\\n\" + \"=\" * 60)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9MXwWcetxIg","executionInfo":{"status":"ok","timestamp":1766434821821,"user_tz":-180,"elapsed":179,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"6e77c534-fd1c-40ac-f4f9-d1e9e3213fac"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Building comprehensive evaluator...\n","\n","============================================================\n","Evaluator ready\n","  Products: 1,000\n","  Ground truth: 39 judgments\n","  Embeddings: (1000, 128)\n","\n","============================================================\n"]}],"source":["# ============================================================\n","# COMPREHENSIVE EVALUATOR\n","# ============================================================\n","\n","print(\"\\nBuilding comprehensive evaluator...\\n\")\n","print(\"=\" * 60)\n","\n","class ComprehensiveEvaluator:\n","    \"\"\"Evaluate system with multiple metrics.\"\"\"\n","\n","    def __init__(self, products_df: pd.DataFrame, gt_df: pd.DataFrame):\n","        self.products_df = products_df\n","        self.gt_df = gt_df\n","        self.item_popularity = compute_item_popularity(products_df)\n","        # Create mock embeddings for diversity calculation\n","        self.embeddings = np.random.randn(len(products_df), 128)\n","\n","    def evaluate_query(\n","        self,\n","        query_id: int,\n","        product_ids: List[int]\n","    ) -> Dict[str, float]:\n","        \"\"\"Evaluate single query with all metrics.\"\"\"\n","\n","        # Get ground truth\n","        gt_items = self.gt_df[self.gt_df['query_id'] == query_id]\n","        relevant_ids = set(gt_items['product_id'].tolist())\n","\n","        metrics = {}\n","\n","        # Ranking quality\n","        metrics['map'] = mean_average_precision(product_ids, relevant_ids)\n","        metrics['recall'] = recall_at_k(product_ids, relevant_ids)\n","        metrics['success'] = success_at_k(product_ids, relevant_ids)\n","\n","        # Diversity\n","        metrics['ils'] = intra_list_similarity(product_ids, self.embeddings)\n","        metrics['cat_diversity'] = category_diversity(product_ids, self.products_df)\n","\n","        # Novelty\n","        metrics['novelty'] = novelty_at_k(product_ids, self.item_popularity)\n","\n","        return metrics\n","\n","    def evaluate_all(self, results: Dict[int, List[int]]) -> pd.DataFrame:\n","        \"\"\"Evaluate all queries.\"\"\"\n","        all_metrics = []\n","\n","        for query_id, product_ids in results.items():\n","            metrics = self.evaluate_query(query_id, product_ids)\n","            metrics['query_id'] = query_id\n","            all_metrics.append(metrics)\n","\n","        return pd.DataFrame(all_metrics)\n","\n","\n","evaluator = ComprehensiveEvaluator(products_df, gt_df)\n","\n","print(\"Evaluator ready\")\n","print(f\"  Products: {len(products_df):,}\")\n","print(f\"  Ground truth: {len(gt_df)} judgments\")\n","print(f\"  Embeddings: {evaluator.embeddings.shape}\")\n","print(\"\\n\" + \"=\" * 60)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QiB3wrsgtxIg","executionInfo":{"status":"ok","timestamp":1766434821825,"user_tz":-180,"elapsed":3,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"1f8ee6b5-391d-4680-8a12-163f44d62eac"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Testing with mock retrieval results...\n","\n","============================================================\n","Created mock results for 10 queries\n","Each query: 10 products\n","\n","Evaluation complete\n","  Queries evaluated: 10\n","  Metrics per query: 6\n","\n","============================================================\n","Metric Summary:\n","============================================================\n","  map            : 0.000 (ranking quality)\n","  recall         : 0.000 (ranking quality)\n","  success        : 0.000 (ranking quality)\n","  ils            : -0.004 (diversity)\n","  cat_diversity  : 0.510 (diversity)\n","  novelty        : 0.312 (novelty)\n","\n","============================================================\n"]}],"source":["# ============================================================\n","# TEST WITH MOCK RETRIEVAL\n","# ============================================================\n","\n","print(\"\\nTesting with mock retrieval results...\\n\")\n","print(\"=\" * 60)\n","\n","# Simulate retrieval results for all queries\n","mock_results = {}\n","\n","for query_id in queries_df['query_id']:\n","    # Mock retrieval: 10 random products\n","    # (in real system this would come from FAISS/retrieval)\n","    mock_results[query_id] = np.random.choice(\n","        products_df.index,\n","        size=10,\n","        replace=False\n","    ).tolist()\n","\n","print(f\"Created mock results for {len(mock_results)} queries\")\n","print(f\"Each query: 10 products\")\n","\n","# Evaluate all\n","results_df = evaluator.evaluate_all(mock_results)\n","\n","print(f\"\\nEvaluation complete\")\n","print(f\"  Queries evaluated: {len(results_df)}\")\n","print(f\"  Metrics per query: {len(results_df.columns) - 1}\")\n","\n","# Show summary\n","print(\"\\n\" + \"=\" * 60)\n","print(\"Metric Summary:\")\n","print(\"=\" * 60)\n","\n","summary = results_df.drop('query_id', axis=1).mean()\n","for metric, value in summary.items():\n","    if metric in ['map', 'recall', 'success']:\n","        print(f\"  {metric:15s}: {value:.3f} (ranking quality)\")\n","    elif metric in ['ils', 'cat_diversity']:\n","        print(f\"  {metric:15s}: {value:.3f} (diversity)\")\n","    elif metric == 'novelty':\n","        print(f\"  {metric:15s}: {value:.3f} (novelty)\")\n","\n","print(\"\\n\" + \"=\" * 60)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y5MlsIhgtxIh","executionInfo":{"status":"ok","timestamp":1766434821836,"user_tz":-180,"elapsed":10,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"a199f16b-76eb-468c-fb88-7636575fe268"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Saving results...\n","\n","============================================================\n","✓ Saved: comprehensive_metrics.csv\n","✓ Saved: metrics_summary.json\n","✓ Saved: README.txt\n","\n","============================================================\n","All files saved successfully\n"]}],"source":["# ============================================================\n","# SAVE RESULTS\n","# ============================================================\n","\n","print(\"\\nSaving results...\\n\")\n","print(\"=\" * 60)\n","\n","# Save detailed results\n","results_path = EVAL_DIR / \"comprehensive_metrics.csv\"\n","results_df.to_csv(results_path, index=False)\n","print(f\"✓ Saved: {results_path.name}\")\n","\n","# Save summary statistics\n","summary_path = EVAL_DIR / \"metrics_summary.json\"\n","summary_data = {\n","    'mean': summary.to_dict(),\n","    'std': results_df.drop('query_id', axis=1).std().to_dict(),\n","    'median': results_df.drop('query_id', axis=1).median().to_dict(),\n","    'min': results_df.drop('query_id', axis=1).min().to_dict(),\n","    'max': results_df.drop('query_id', axis=1).max().to_dict()\n","}\n","with open(summary_path, 'w') as f:\n","    json.dump(summary_data, f, indent=2)\n","print(f\"✓ Saved: {summary_path.name}\")\n","\n","# Save metric descriptions\n","desc_path = EVAL_DIR / \"README.txt\"\n","with open(desc_path, 'w', encoding='utf-8') as f:\n","    f.write(\"Comprehensive Evaluation Metrics\\n\")\n","    f.write(\"=\" * 60 + \"\\n\\n\")\n","    f.write(\"This evaluation goes beyond basic Recall/NDCG to measure\\n\")\n","    f.write(\"multiple aspects of recommendation quality.\\n\\n\")\n","    f.write(\"Ranking Quality:\\n\")\n","    f.write(\"  MAP - mean average precision (higher = better)\\n\")\n","    f.write(\"  Recall@K - fraction of relevant items retrieved\\n\")\n","    f.write(\"  Success@K - at least one relevant item found\\n\\n\")\n","    f.write(\"Diversity:\\n\")\n","    f.write(\"  ILS - intra-list similarity (lower = more diverse)\\n\")\n","    f.write(\"  cat_diversity - unique categories ratio (higher = better)\\n\\n\")\n","    f.write(\"Novelty:\\n\")\n","    f.write(\"  novelty - average item novelty (1 - popularity)\\n\")\n","    f.write(\"  Higher = recommending less obvious items\\n\\n\")\n","    f.write(\"Files:\\n\")\n","    f.write(\"  - comprehensive_metrics.csv: per-query metrics\\n\")\n","    f.write(\"  - metrics_summary.json: aggregated statistics\\n\")\n","print(f\"✓ Saved: {desc_path.name}\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"All files saved successfully\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1_y2n4RtxIh","executionInfo":{"status":"ok","timestamp":1766434821899,"user_tz":-180,"elapsed":61,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"0e2f8474-4912-477b-93ff-5c990b501094"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","PHASE 9, NOTEBOOK 1 COMPLETE\n","============================================================\n","\n","What we built:\n","  ✓ Comprehensive metrics suite\n","  ✓ Ranking quality (MAP, Recall, Success)\n","  ✓ Diversity (ILS, category diversity)\n","  ✓ Novelty (inverse popularity)\n","\n","Results:\n","  Queries tested: 10\n","  Metrics computed: 6\n","  Files created: 3\n","\n","Key findings (mock data):\n","  Avg MAP: 0.000\n","  Avg Recall@10: 0.000\n","  Success rate: 0.000\n","  Category diversity: 0.510\n","  Novelty: 0.312\n","\n","Next steps:\n","  1. Run on real retrieval results (not mock)\n","  2. Compare different system configurations\n","  3. Ablation studies (Notebook 2)\n","  4. Baseline comparisons (Notebook 3)\n","\n","============================================================\n"]}],"source":["# ============================================================\n","# SUMMARY\n","# ============================================================\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"PHASE 9, NOTEBOOK 1 COMPLETE\")\n","print(\"=\" * 60)\n","\n","print(\"\\nWhat we built:\")\n","print(\"  ✓ Comprehensive metrics suite\")\n","print(\"  ✓ Ranking quality (MAP, Recall, Success)\")\n","print(\"  ✓ Diversity (ILS, category diversity)\")\n","print(\"  ✓ Novelty (inverse popularity)\")\n","\n","print(\"\\nResults:\")\n","print(f\"  Queries tested: {len(results_df)}\")\n","print(f\"  Metrics computed: {len(summary)}\")\n","print(f\"  Files created: 3\")\n","\n","print(\"\\nKey findings (mock data):\")\n","print(f\"  Avg MAP: {summary['map']:.3f}\")\n","print(f\"  Avg Recall@10: {summary['recall']:.3f}\")\n","print(f\"  Success rate: {summary['success']:.3f}\")\n","print(f\"  Category diversity: {summary['cat_diversity']:.3f}\")\n","print(f\"  Novelty: {summary['novelty']:.3f}\")\n","\n","print(\"\\nNext steps:\")\n","print(\"  1. Run on real retrieval results (not mock)\")\n","print(\"  2. Compare different system configurations\")\n","print(\"  3. Ablation studies (Notebook 2)\")\n","print(\"  4. Baseline comparisons (Notebook 3)\")\n","\n","print(\"\\n\" + \"=\" * 60)"]},{"cell_type":"markdown","metadata":{"id":"8Q6UQH4ItxIh"},"source":["---\n","\n","## Summary\n","\n","Implemented comprehensive evaluation metrics that go beyond basic Recall/NDCG.\n","These metrics help us understand different aspects of recommendation quality.\n","\n","### Metrics Implemented\n","\n","**Ranking Quality**\n","- MAP: Precision across all ranks\n","- Recall@K: Coverage of relevant items\n","- Success@K: Binary success metric\n","\n","**Diversity**\n","- ILS: Pairwise similarity (want low)\n","- Category diversity: Unique categories shown\n","\n","**Novelty**\n","- Novelty@K: Inverse popularity\n","\n","### Why This Matters\n","\n","Different metrics capture different quality dimensions. A system might have high\n","recall but low diversity (showing many similar items). These metrics help us\n","understand trade-offs and optimize holistically.\n","\n","### Files Created\n","\n","```\n","evaluation/comprehensive/\n","├── comprehensive_metrics.csv\n","├── metrics_summary.json\n","└── README.txt\n","```\n","\n","### Next\n","\n","Notebook 2 will implement ablation studies to understand which components\n","contribute most to overall performance.\n","\n","---"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ho65ohp9lRv"
   },
   "source": [
    "# üîç AI Fashion Assistant v2.0 - Baseline Retrieval System\n",
    "\n",
    "**Phase 3, Notebook 1/2** - Complete Baseline Search Implementation\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "1. **Query Understanding:** Text normalization, intent detection\n",
    "2. **Multi-Modal Retrieval:** Text, Image, Hybrid search modes\n",
    "3. **Baseline Ranking:** Distance-based scoring\n",
    "4. **Evaluation Framework:** Test with sample queries\n",
    "5. **Production Module:** Save reusable search engine\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Architecture\n",
    "\n",
    "```\n",
    "Query Input (Text/Image/Both)\n",
    "    ‚Üì\n",
    "Query Understanding & Normalization\n",
    "    ‚Üì\n",
    "Encoding (mpnet + CLIP)\n",
    "    ‚Üì\n",
    "FAISS Search (Hybrid Space)\n",
    "    ‚Üì\n",
    "Baseline Ranking (Distance)\n",
    "    ‚Üì\n",
    "Results (Top-K Products)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üé® Search Modes\n",
    "\n",
    "| Mode | Input | Use Case |\n",
    "|------|-------|----------|\n",
    "| **Text** | Query string | \"red dress for women\" |\n",
    "| **Image** | Product image | Visual similarity search |\n",
    "| **Hybrid** | Text + Image | \"find similar red dresses\" |\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Quality Gates\n",
    "\n",
    "- ‚úì Query normalization consistent with SSOT\n",
    "- ‚úì All search modes functional\n",
    "- ‚úì Results ranked by relevance\n",
    "- ‚úì Performance: <50ms per query\n",
    "- ‚úì Module saved for production\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24432,
     "status": "ok",
     "timestamp": 1766153733126,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "xOwO3Nym9lRy",
    "outputId": "0f8fb77c-fb9e-4499-b77b-f57bd5f706c6"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) SETUP & ENVIRONMENT\n",
    "# ============================================================\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=False)\n",
    "\n",
    "# GPU Check\n",
    "import torch\n",
    "print(\"üñ•Ô∏è Environment:\")\n",
    "print(f\"  GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"  Running on CPU (acceptable for retrieval)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306976,
     "status": "ok",
     "timestamp": 1766154040115,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "BaAPEGdY9lRz",
    "outputId": "17f2b689-ac4f-4e5c-c0d1-2e1d8c8ef3f1"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) INSTALL PACKAGES\n",
    "# ============================================================\n",
    "\n",
    "print(\"üì¶ Installing packages...\\n\")\n",
    "\n",
    "!pip install -q --upgrade sentence-transformers\n",
    "!pip install -q --upgrade transformers\n",
    "!pip install -q --upgrade torch\n",
    "!pip install -q faiss-cpu\n",
    "!pip install -q pillow\n",
    "!pip install -q scikit-learn\n",
    "\n",
    "print(\"\\n‚úÖ Packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55531,
     "status": "ok",
     "timestamp": 1766154095652,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "3DSrNJ_t9lRz",
    "outputId": "b8249b9b-b282-4292-d94f-cf5636cc5b8e"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Optional, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ML & Search\n",
    "import torch\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"\\nüìö Library versions:\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  FAISS: {faiss.__version__}\")\n",
    "print(f\"  NumPy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1766154096936,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "7687k5839lRz",
    "outputId": "a40bae9d-d7a3-49d5-f6f4-9f05a89c569c"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4) PROJECT PATHS & CONFIG\n",
    "# ============================================================\n",
    "\n",
    "PROJECT_ROOT = Path(\"/content/drive/MyDrive/ai_fashion_assistant_v2\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data/processed\"\n",
    "EMB_DIR = PROJECT_ROOT / \"embeddings\"\n",
    "INDEX_DIR = PROJECT_ROOT / \"indexes\"\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"docs/results\"\n",
    "\n",
    "# Create directories\n",
    "SRC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"üìÅ Project Structure:\")\n",
    "print(f\"  Root: {PROJECT_ROOT}\")\n",
    "print(f\"  Data: {DATA_DIR}\")\n",
    "print(f\"  Embeddings: {EMB_DIR}\")\n",
    "print(f\"  Indexes: {INDEX_DIR}\")\n",
    "print(f\"  Source: {SRC_DIR}\")\n",
    "print(f\"  Results: {RESULTS_DIR}\")\n",
    "print(f\"\\nüñ•Ô∏è Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1315,
     "status": "ok",
     "timestamp": 1766154098258,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "IcmFgw6J9lR0",
    "outputId": "a6ffc29a-eed5-4743-ab7d-49acd6d0cc69"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5) IMPORT SSOT SCHEMA\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìã Importing SSOT schema...\\n\")\n",
    "\n",
    "# Import schema module\n",
    "try:\n",
    "    from schema import normalize_text, Product, QueryRecord\n",
    "    print(\"‚úÖ SSOT schema imported successfully!\")\n",
    "    print(\"  Available functions:\")\n",
    "    print(\"    - normalize_text() : Text normalization\")\n",
    "    print(\"    - Product : Product data class\")\n",
    "    print(\"    - QueryRecord : Query data class\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Schema import failed: {e}\")\n",
    "    print(\"  Will use local normalization functions\")\n",
    "\n",
    "    # Fallback normalization\n",
    "    def normalize_text(text: str, mode: str = \"standard\") -> str:\n",
    "        \"\"\"Fallback normalization if schema not available\"\"\"\n",
    "        text = text.lower().strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text\n",
    "\n",
    "    print(\"  ‚úÖ Using fallback normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164910,
     "status": "ok",
     "timestamp": 1766154263170,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "3iAtXJaU9lR0",
    "outputId": "09044f6d-be7b-4d52-ae0c-a91473b0cf50"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6) LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìÇ LOADING DATA...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load product metadata (SSOT)\n",
    "print(\"Loading product metadata (SSOT)...\")\n",
    "df = pd.read_csv(DATA_DIR / \"meta_ssot.csv\")\n",
    "print(f\"‚úÖ Loaded {len(df):,} products\")\n",
    "print(f\"  Columns: {list(df.columns[:8])}...\")\n",
    "\n",
    "# Load model config\n",
    "print(\"\\nLoading model configuration...\")\n",
    "with open(EMB_DIR / \"configs/model_config.json\", 'r') as f:\n",
    "    MODEL_CONFIG = json.load(f)\n",
    "print(f\"‚úÖ Config loaded\")\n",
    "print(f\"  Text dim: {MODEL_CONFIG['text_combined_dim']}d\")\n",
    "print(f\"  Image dim: {MODEL_CONFIG['image_model_dim']}d\")\n",
    "print(f\"  Hybrid dim: {MODEL_CONFIG['hybrid_dim']}d\")\n",
    "\n",
    "# Find images directory\n",
    "print(\"\\nLocating images directory...\")\n",
    "OLD_PROJECT = Path(\"/content/drive/MyDrive/ai_fashion_assistant_v1\")\n",
    "possible_paths = [\n",
    "    OLD_PROJECT / \"data/raw/images\",\n",
    "    PROJECT_ROOT / \"data/raw/images\",\n",
    "]\n",
    "\n",
    "IMAGES_DIR = None\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        try:\n",
    "            import os\n",
    "            test_files = [f for f in os.listdir(path) if f.endswith('.jpg')][:3]\n",
    "            if test_files:\n",
    "                IMAGES_DIR = path\n",
    "                print(f\"‚úÖ Images found: {IMAGES_DIR}\")\n",
    "                break\n",
    "        except OSError:\n",
    "            continue\n",
    "\n",
    "if IMAGES_DIR is None:\n",
    "    print(\"‚ö†Ô∏è Images directory not found (image search will be disabled)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Data loading complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "086626f42358424ba12e0d6e3c6308a2",
      "0369f89670a34bbc86463cebe70dd1c8",
      "300c3c565abf45538970e7ed0fc2a052",
      "8ed3c236a79a4e649120959d9232c49c",
      "53b26c5230924646927204d434bab3ba",
      "59aa4e696c104b48a12a721e93036b4a",
      "1adcc41d9076452d910655b4aac0bdb5",
      "b2c24214120444d3af5557d68d5c419d",
      "8e1d4d9babd84c2e82a5b2484c3072d1",
      "5eaf53d8958b482b94c000ee04b58201",
      "ba6b95bca5f84dfc9dd2450af781ba92",
      "b94d06f278b843fa83ad29a60cd9c864",
      "617e5e06f4d84c9baeda77fc73f60bb4",
      "220414525a3e45a3831a9610154f3dd2",
      "6a7b21088bfe4e4ba60c08b1b274bb68",
      "8c80880b2c1b46b581a817e3a95eb535",
      "f62066093cb24599ba5dcce8da2fc501",
      "9e4a534cc3974cf9be583a10b4a573e3",
      "7445abc30c8e41ecbedae786181942ca",
      "fcb9ac9240764719875c557fbc65ad1a",
      "f772020ce2834423a1f717e8d1e7989c",
      "d980a15d7e864489a1acb16d7e193a43",
      "b8d50564a9b1406ba344b4933e60de25",
      "05e72cc3bfd34021810a1cf03ed8fa08",
      "4d393bac497d4a909fcf421d548e4886",
      "bf59c45dadee43e3924294134d629f02",
      "5a4a12bc6bd643d286a265391311d52a",
      "f71ecd59966c4dc69a1e5efed9095640",
      "4a0f145cf43440ab9c46738409cf675e",
      "d2ab93c4cb634645aa8d5db3e33dd984",
      "4383ea25b24e4da0ab5c878535bd0092",
      "8142ee2fe519416a89fc0c139b0dcd63",
      "11b1cfc0b730400780a39d2c39026eaf",
      "acb9c43fcefd4ff590c8b2a74d37f34b",
      "0cfd7ce934274d6a8d1d120e0132d5e3",
      "bce2e5f93f1d46569cffd5945b2c4ccc",
      "f573988fbab34f16972b6533a99bacec",
      "68e85476f94f495a959f1ced40efaeb9",
      "d2359b1bf03544949420515c62d71d23",
      "1eb6440a8c7e4334adb71a0919526338",
      "b8c94559d5b147e1b54074f5791325c3",
      "1b1f456cc52244fa82855c978e18261f",
      "8c0a8b8f798d427a8d3302a3e013afb3",
      "5a39e86fecf14fcf9cf4692d06bf930a",
      "b83bbd3192714f32a17b759dfdad38c2",
      "46df9f90121549c896e826f0d376e762",
      "9a3f0ff8ab5f4e03ad1fead9772a6376",
      "e041ccf90b0145d0bc1419b6d033ce49",
      "b2c30c420dc44e499627f2208b57421d",
      "87ade5c65fb04fc58fe5accda395dbee",
      "5dcd53e276874cdc96e837d64bb22ebc",
      "0a3d1016f0834c8da1c36f6be5dab5dc",
      "2dccd02ea87f4d18a677934497b6c751",
      "967d43e6a74b4532b37065147c9a9ceb",
      "be200427e44442259717ee93e3b3a55e",
      "f25de97341f44fcba16411392fed727c",
      "9b2c024b64fb4c9fb6adeb6a05fec041",
      "1c250ab94c4e4f669dd869d0dc59e6a7",
      "a410b48a184e4fdda76f101b2e8e89b0",
      "750604bab0d6498f9aabcdd6f7031737",
      "c90465aab0a84da09d32f0f382f4f5b7",
      "40be31102adb4c268ab8588161816d1f",
      "b0179767e0824b6485605c700d6e0661",
      "e814126a0bbb4f79aec622d98199910a",
      "21f612314cbc4906b2dc39b088036909",
      "9fc3214c3b5947128e7710d5947a575c",
      "9bc17611a6be430c89910956231a037f",
      "6e9ccebf7963421ab6c2e63f62e65d3e",
      "7a03198aa3f0419187b1e2da1b440933",
      "29a49d6f954140da959da91459c68ec2",
      "14c7f56148654457bcdf97bf26b5bdd9",
      "147bc285b3fa48ad982a258b0a4c3232",
      "0888c83a55a14c738d98392400a42232",
      "10a8df21da4e40bcbd136f83c4ae3ba1",
      "64646988f0f741d78939c12b972370da",
      "941d22c52bd747f4b2aec56419be1b12",
      "f749b7d55be346f9a634debbdd666795",
      "45097144b06b4825be78264a5242ed11",
      "fe029ca78a234179b04b150fe488aab9",
      "193afe0f63514becb7bcea3c23631a30",
      "520d321389a84bcba6d50851124d5397",
      "871b899d88b24502a463d8c3c63180fb",
      "0e578f56fe2149b1adcf7bc86c14bdfb",
      "e53534691be3425b8d56263146c93f0f",
      "74544eae3102471e8ebc929f0bd39941",
      "046e8a783b6549508a5a95eb8e28bdea",
      "a23d370d4f35490195518dfb79884e13",
      "e510742024524f51b0b98b6477556123",
      "365d933477364c1e831dcf5920f11b0b",
      "7da1b3ac7b464a5b9cc93560cb418276",
      "2b5b6286deb8414ea516e351a98f443c",
      "81b32773254b42b9bb89cac69309c48b",
      "baadee0f5be54a47a6ca15de68d120cc",
      "e2d7b9d703a741f4a5edb0421517bf1c",
      "92bccd93f8eb4225a3a58d616f83b9bc",
      "90130d4f36bd40af951e668a8c97df86",
      "fc30d57d28dc4321a92ca41998248e10",
      "bd43a9e87b8f4ff597848cf4544b5a4b",
      "221175a810294b4bba436d76add49a9b",
      "86750f832be140b38bb3d87113381844",
      "48c34134de4f4f43985b5d4de193a68b",
      "9182c10ae96a4fa59b7ea701977f3767",
      "994e972b56864f8eba0808fd9f7d6aad",
      "12ec133499ab49ce9e9445babb1ba5d5",
      "a126833669734509b2757c86a875e931",
      "a92b6c0c0b884519a49f5f52d30c4c99",
      "fdce244c52ca496d81be87534cd6180c",
      "a51553781a66486a89c7e0d34c599236",
      "e6ad979f9ff84174adcf3755e023b645",
      "f000453488dd47a0b32340fa036cb3ed",
      "828eee4b4e3745bc917edcacfaec78f2",
      "67f9d9deb6e44f33a666d518d488f470",
      "81b8be12ad914a09b3f3aec977019e59",
      "1b5d7ac17ccd447295f79104daafb235",
      "a3d9e620e2304de1a15e940cd1c43184",
      "b60fdb6770d44e1097379df9120fb021",
      "ad13f1a2e2ae4e6e881099477431ef54",
      "49b62b2b44c14184a37a162665eefe84",
      "43584cf6a4a145e889140cca9ae99175",
      "fda0e37c147d4fc7a95471dd56a14c19",
      "7e5a1c68836943b795f013a4a9e6d81a",
      "8bffd62d2528424297ce850090565696",
      "21a362597ad748f39b8efd511a02d992",
      "11221433a78345e39d973dd6313717b7",
      "dd193f61114747c39cc647c65d4f48ad",
      "6b777a709863497094834808a6bd93ef",
      "67d999bb582a4d5b8f319c5ce8217511",
      "2e9efdb5d6f5444791f4cf7a6006e962",
      "baebe2e90499416887abfb04d154015b",
      "6c214eeb3353447e8ae662573ae32d2a",
      "8b8f7a87693844bab1b0af95bc53b477",
      "34e40aaead2f4d2da5adbc744a6462b3",
      "3c66cf8247eb4e858349d91541ee149d",
      "16d7bf0321b74ccc8ab8879ff1a1bb79",
      "ac99f6dee42a4215a41018c62f8d3842",
      "285628d9a68447c08bf097daa1c8403e",
      "cd1f8c491c99403683925a3c361ce89c",
      "6c721b02d79740e68055762c72d03aee",
      "dd3a699335ed4f8a85b2a8a1b70f59d4",
      "882ad20e84704ce79b9c219ec446fa77",
      "fe502a3d0f95416d966ac3f0a2f1c2aa",
      "1130f5514b9a4d40b2ea121c31b08bc3",
      "ecc807eb47714380bab1f4a835cf4ef4",
      "adbe75c6b22d4360bcead2d98b56b21d",
      "9666fd9641cf42038a44921589c675e7",
      "adba409161994e448d62575ed3dd642d",
      "baeeb0693d8b4e488e4f23cbd652a1ef",
      "7261d30e5ca3476d8df1e19f34b8f814",
      "cb70e56c606b43ba9a080d4dda9023c5",
      "2a28eb6d61f24e4384500071f23c0a9c",
      "c42f238c7a114c609410f758d8770cc4",
      "0a1f2019ac6e49ed8cee5ee9a4ce2101",
      "e0d89e0de5b3474cba844171a70b1b41",
      "f78d7da786874014914eced701358695",
      "bb17152bc7be49a8ac2aec47e11ad56f",
      "75ca3d9181104193bae0431bae260d48",
      "a0b71669d1f24d2b91975ca722dc4208",
      "8e211cda61f446169861467a446b9972",
      "db1df5afc1634dbfa7584dc52dfeaef1",
      "4ac873debd2c429c8b2ed771b539983f",
      "8cf8de4c396a4df68e8beffcc5026b28",
      "3cc76af89e824f6eb9825510cec4351b",
      "e4d437a8614142b8a8004dea4aacda2d",
      "7423a531de604570be0d3d69a4f7ec4d",
      "b663b2d6397b4fb69c3231087dbf0bcd",
      "0409e9b329d143cf9adc4a82735cf401",
      "e2b3d6e59b9844c5ab8a9634ec386c0d",
      "fe41a60ae94242f0ab39e91438f1a043",
      "beebf724688c46f7ab66fe37a192d639",
      "ae8805471ef046bd8d4357f49ef71bb3",
      "94e32b7445694bae9ec119b0ae37a529",
      "12df0acf391146e0ae36c176d35df2d2",
      "92d3ef544e0b4763bbbc96ac0484ebc4",
      "6c34187a0c8a441b9b9e364092e0c36c",
      "448178d1b0244e6a9584700dd9dbd275",
      "600022b366704cdfa0a4e71ebade60f3",
      "cd3d411b7fd543a5b8d74cc887c5a8fa",
      "cee0b4ce10b245f0a2ded383b183fb4e",
      "2a09fce620ac43c4a609097d67ed7057",
      "2e5d855b058f4564b4223df52d5910d5",
      "174a1f7762ed49debccc68a9156ae481",
      "b910644db6b64238a3b9def1956c7744",
      "b4db3816312448828c747459d861c9cc",
      "e8d69f8e96c948638f1604d095d7794e",
      "af6dd54dfa6345f9a7f4b2bec4ef5943",
      "161009a923114f458e009e74be7d069e",
      "6d2d83cbd5394a1ea9b8dd93528881f4",
      "55e2f9a5edea4e3fa56faf861f8ff446",
      "46ccec758a984bd9a06a99e14a7e4d6a",
      "cd4f24b4bbe748a08d11a5229ba00579",
      "8c772d6263214a3bb1db9e589e57ff99",
      "00070181e67249ab8a5df01bfd1def1c",
      "194d2ff64aa9455ea01fe576340f7c88",
      "1348f54c8382456183436713ce6392ef",
      "3fd51b6b7fb04087b15a92bc90fe1a4f",
      "f14c9f4f25a94a7b94b7b47a9a0e4680",
      "6e903cd2444e46c78685423af6869bc7",
      "3e6029821ffb4741ba11a8c24d337b90",
      "d6cc01cf41c4453fbfe89a72c40e90a3",
      "8f7d42231e294a72abe2c48c5f69da36",
      "d2a075a43e0e48f995bb592f0bd20049",
      "2261e1b546d14f558e0428c0b56af7f2",
      "666aa31289114919ac8ad50e2160e603",
      "a33e78815bcb450caffc31536abe466c",
      "22a45f4f59c9449eae41307ce91dbdd0",
      "5e623091684744d5b0fcc9c7a6f53097",
      "03df017923664e6ba95446aa935f40c7",
      "fab0fec4d44e4af2a3a2cb81499717d5",
      "ca3b7784f40a4549844045d3e6707475"
     ]
    },
    "executionInfo": {
     "elapsed": 80907,
     "status": "ok",
     "timestamp": 1766154344079,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "YFxD9TjW9lR0",
    "outputId": "c28c6c3d-0fb6-4b13-c45b-c0f3583fa05d"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7) LOAD MODELS\n",
    "# ============================================================\n",
    "\n",
    "print(\"ü§ñ LOADING MODELS...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Text model (mpnet)\n",
    "print(\"\\n1Ô∏è‚É£ Loading text model (mpnet)...\")\n",
    "start_time = time.time()\n",
    "text_model = SentenceTransformer(MODEL_CONFIG[\"text_model_primary\"])\n",
    "text_model = text_model.to(device)\n",
    "print(f\"   ‚úÖ Loaded in {time.time() - start_time:.1f}s\")\n",
    "print(f\"   Model: {MODEL_CONFIG['text_model_primary']}\")\n",
    "print(f\"   Output: {MODEL_CONFIG['text_model_primary_dim']}d\")\n",
    "\n",
    "# CLIP model\n",
    "print(\"\\n2Ô∏è‚É£ Loading CLIP model (text + image)...\")\n",
    "start_time = time.time()\n",
    "clip_model = CLIPModel.from_pretrained(MODEL_CONFIG[\"image_model\"])\n",
    "clip_processor = CLIPProcessor.from_pretrained(MODEL_CONFIG[\"image_model\"])\n",
    "clip_model = clip_model.to(device)\n",
    "print(f\"   ‚úÖ Loaded in {time.time() - start_time:.1f}s\")\n",
    "print(f\"   Model: {MODEL_CONFIG['image_model']}\")\n",
    "print(f\"   Text output: {MODEL_CONFIG['text_model_secondary_dim']}d\")\n",
    "print(f\"   Image output: {MODEL_CONFIG['image_model_dim']}d\")\n",
    "\n",
    "# FAISS index\n",
    "print(\"\\n3Ô∏è‚É£ Loading FAISS index...\")\n",
    "start_time = time.time()\n",
    "index = faiss.read_index(str(INDEX_DIR / \"faiss_hybrid_hnsw.index\"))\n",
    "print(f\"   ‚úÖ Loaded in {time.time() - start_time:.1f}s\")\n",
    "print(f\"   Vectors: {index.ntotal:,}\")\n",
    "print(f\"   Index type: HNSW\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ All models loaded!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1766154344085,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "xRl1f6kh9lR1",
    "outputId": "868b7b92-0b5e-4425-b78b-7269c488a65b"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8) QUERY UNDERSTANDING MODULE\n",
    "# ============================================================\n",
    "\n",
    "print(\"üß† CREATING QUERY UNDERSTANDING MODULE...\\n\")\n",
    "\n",
    "@dataclass\n",
    "class QueryIntent:\n",
    "    \"\"\"Query intent classification\"\"\"\n",
    "    query_type: str  # 'text', 'image', 'hybrid'\n",
    "    search_mode: str  # 'exact', 'semantic', 'visual'\n",
    "    normalized_text: Optional[str] = None\n",
    "    has_filters: bool = False\n",
    "    filters: Dict = None\n",
    "\n",
    "\n",
    "class QueryUnderstanding:\n",
    "    \"\"\"\n",
    "    Query understanding and normalization using SSOT schema.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Fashion-specific keywords\n",
    "        self.category_keywords = {\n",
    "            'apparel': ['dress', 'shirt', 'tshirt', 't-shirt', 'jeans', 'pants', 'shorts'],\n",
    "            'accessories': ['watch', 'bag', 'wallet', 'belt', 'sunglasses'],\n",
    "            'footwear': ['shoes', 'sandals', 'heels', 'boots', 'sneakers']\n",
    "        }\n",
    "\n",
    "        self.color_keywords = [\n",
    "            'red', 'blue', 'green', 'yellow', 'black', 'white', 'grey', 'gray',\n",
    "            'pink', 'purple', 'brown', 'orange', 'navy', 'beige', 'maroon'\n",
    "        ]\n",
    "\n",
    "        self.gender_keywords = ['men', 'women', 'unisex', 'boys', 'girls', 'kids']\n",
    "\n",
    "    def understand_query(\n",
    "        self,\n",
    "        text: Optional[str] = None,\n",
    "        image: Optional[Image.Image] = None\n",
    "    ) -> QueryIntent:\n",
    "        \"\"\"Understand query intent and extract features\"\"\"\n",
    "\n",
    "        # Determine query type\n",
    "        if text and image:\n",
    "            query_type = 'hybrid'\n",
    "            search_mode = 'semantic'\n",
    "        elif text:\n",
    "            query_type = 'text'\n",
    "            search_mode = 'semantic'\n",
    "        elif image:\n",
    "            query_type = 'image'\n",
    "            search_mode = 'visual'\n",
    "        else:\n",
    "            raise ValueError(\"Must provide text or image!\")\n",
    "\n",
    "        # Normalize text if provided\n",
    "        normalized_text = None\n",
    "        filters = {}\n",
    "        has_filters = False\n",
    "\n",
    "        if text:\n",
    "            # Use SSOT normalization\n",
    "            normalized_text = normalize_text(text, mode=\"standard\")\n",
    "\n",
    "            # Extract filters (simple keyword matching)\n",
    "            text_lower = text.lower()\n",
    "\n",
    "            # Color filter\n",
    "            for color in self.color_keywords:\n",
    "                if color in text_lower:\n",
    "                    filters['color'] = color\n",
    "                    has_filters = True\n",
    "\n",
    "            # Gender filter\n",
    "            for gender in self.gender_keywords:\n",
    "                if gender in text_lower:\n",
    "                    filters['gender'] = gender\n",
    "                    has_filters = True\n",
    "\n",
    "        return QueryIntent(\n",
    "            query_type=query_type,\n",
    "            search_mode=search_mode,\n",
    "            normalized_text=normalized_text,\n",
    "            has_filters=has_filters,\n",
    "            filters=filters\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize\n",
    "query_understander = QueryUnderstanding()\n",
    "\n",
    "print(\"‚úÖ Query understanding module created!\")\n",
    "\n",
    "# Test\n",
    "test_intent = query_understander.understand_query(text=\"red dress for women\")\n",
    "print(f\"\\nüìù Test query understanding:\")\n",
    "print(f\"  Query: 'red dress for women'\")\n",
    "print(f\"  Type: {test_intent.query_type}\")\n",
    "print(f\"  Normalized: '{test_intent.normalized_text}'\")\n",
    "print(f\"  Filters: {test_intent.filters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1766154344097,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "oCxO9gEG9lR1",
    "outputId": "b4b3b59f-27c8-4573-8e0c-027fb29aaea2"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 9) SEARCH ENGINE CLASS\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîç CREATING SEARCH ENGINE...\\n\")\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"Search result with ranking information\"\"\"\n",
    "    rank: int\n",
    "    product_id: int\n",
    "    product_name: str\n",
    "    category: str\n",
    "    gender: str\n",
    "    color: str\n",
    "    distance: float\n",
    "    similarity: float\n",
    "    score: float  # Final ranking score\n",
    "\n",
    "\n",
    "class FashionSearchEngine:\n",
    "    \"\"\"\n",
    "    Production-grade fashion search engine.\n",
    "    Supports text, image, and hybrid retrieval with baseline ranking.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        index: faiss.Index,\n",
    "        products_df: pd.DataFrame,\n",
    "        text_model: SentenceTransformer,\n",
    "        clip_model: CLIPModel,\n",
    "        clip_processor: CLIPProcessor,\n",
    "        query_understander: QueryUnderstanding,\n",
    "        device: str = \"cpu\"\n",
    "    ):\n",
    "        self.index = index\n",
    "        self.df = products_df\n",
    "        self.text_model = text_model\n",
    "        self.clip_model = clip_model\n",
    "        self.clip_processor = clip_processor\n",
    "        self.query_understander = query_understander\n",
    "        self.device = device\n",
    "\n",
    "        # Cache for performance\n",
    "        self._embedding_cache = {}\n",
    "\n",
    "    def encode_text(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Encode text to combined embedding (mpnet + CLIP text)\"\"\"\n",
    "        # Check cache\n",
    "        if text in self._embedding_cache:\n",
    "            return self._embedding_cache[text]\n",
    "\n",
    "        # mpnet\n",
    "        mpnet_emb = self.text_model.encode([text], convert_to_numpy=True)[0]\n",
    "\n",
    "        # CLIP text\n",
    "        inputs = self.clip_processor(text=[text], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            clip_text_emb = self.clip_model.get_text_features(**inputs)\n",
    "            clip_text_emb = clip_text_emb.cpu().numpy()[0]\n",
    "\n",
    "        # Combine\n",
    "        combined = np.concatenate([mpnet_emb, clip_text_emb])\n",
    "\n",
    "        # Cache\n",
    "        self._embedding_cache[text] = combined\n",
    "\n",
    "        return combined\n",
    "\n",
    "    def encode_image(self, image: Image.Image) -> np.ndarray:\n",
    "        \"\"\"Encode image to CLIP embedding\"\"\"\n",
    "        inputs = self.clip_processor(images=image, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            image_emb = self.clip_model.get_image_features(**inputs)\n",
    "            image_emb = image_emb.cpu().numpy()[0]\n",
    "        return image_emb\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        text: Optional[str] = None,\n",
    "        image: Optional[Image.Image] = None,\n",
    "        k: int = 50,\n",
    "        text_weight: float = 0.7,\n",
    "        apply_filters: bool = True\n",
    "    ) -> List[SearchResult]:\n",
    "        \"\"\"Unified search interface\"\"\"\n",
    "\n",
    "        # Understand query\n",
    "        intent = self.query_understander.understand_query(text=text, image=image)\n",
    "\n",
    "        # Normalize text if needed\n",
    "        if text:\n",
    "            text = intent.normalized_text\n",
    "\n",
    "        # Create hybrid embedding\n",
    "        if text and image:\n",
    "            # Hybrid\n",
    "            text_emb = self.encode_text(text) * text_weight\n",
    "            image_emb = self.encode_image(image) * (1 - text_weight)\n",
    "            hybrid_emb = np.concatenate([text_emb, image_emb])\n",
    "        elif text:\n",
    "            # Text only\n",
    "            text_emb = self.encode_text(text)\n",
    "            zero_image = np.zeros(768)\n",
    "            hybrid_emb = np.concatenate([text_emb, zero_image])\n",
    "        elif image:\n",
    "            # Image only\n",
    "            image_emb = self.encode_image(image)\n",
    "            zero_text = np.zeros(1536)\n",
    "            hybrid_emb = np.concatenate([zero_text, image_emb])\n",
    "        else:\n",
    "            raise ValueError(\"Must provide text or image!\")\n",
    "\n",
    "        # Normalize\n",
    "        hybrid_emb = hybrid_emb / np.linalg.norm(hybrid_emb)\n",
    "\n",
    "        # Search FAISS\n",
    "        query_vec = hybrid_emb.astype('float32').reshape(1, -1)\n",
    "\n",
    "        # Retrieve more candidates if filtering\n",
    "        retrieve_k = k * 3 if apply_filters and intent.has_filters else k\n",
    "        distances, indices = self.index.search(query_vec, retrieve_k)\n",
    "\n",
    "        # Create results\n",
    "        results = []\n",
    "        for idx, dist in zip(indices[0], distances[0]):\n",
    "            product = self.df.iloc[idx]\n",
    "\n",
    "            # Apply filters if needed\n",
    "            if apply_filters and intent.has_filters:\n",
    "                # Color filter\n",
    "                if 'color' in intent.filters:\n",
    "                    product_color = str(product.get('baseColour', '')).lower()\n",
    "                    if intent.filters['color'] not in product_color:\n",
    "                        continue\n",
    "\n",
    "                # Gender filter\n",
    "                if 'gender' in intent.filters:\n",
    "                    product_gender = str(product.get('gender', '')).lower()\n",
    "                    if intent.filters['gender'] not in product_gender:\n",
    "                        continue\n",
    "\n",
    "            similarity = 1 - dist\n",
    "\n",
    "            results.append(SearchResult(\n",
    "                rank=len(results) + 1,\n",
    "                product_id=int(product['id']),\n",
    "                product_name=product['productDisplayName'],\n",
    "                category=product.get('masterCategory', 'Unknown'),\n",
    "                gender=product.get('gender', 'Unknown'),\n",
    "                color=product.get('baseColour', 'Unknown'),\n",
    "                distance=float(dist),\n",
    "                similarity=float(similarity),\n",
    "                score=float(similarity)  # Baseline: score = similarity\n",
    "            ))\n",
    "\n",
    "            # Stop when we have k results\n",
    "            if len(results) >= k:\n",
    "                break\n",
    "\n",
    "        return results\n",
    "\n",
    "    def search_text(self, query: str, k: int = 10) -> List[SearchResult]:\n",
    "        \"\"\"Text-only search (convenience wrapper)\"\"\"\n",
    "        return self.search(text=query, k=k)\n",
    "\n",
    "    def search_image(self, image: Image.Image, k: int = 10) -> List[SearchResult]:\n",
    "        \"\"\"Image-only search (convenience wrapper)\"\"\"\n",
    "        return self.search(image=image, k=k)\n",
    "\n",
    "    def search_hybrid(\n",
    "        self, query: str, image: Image.Image, k: int = 10, text_weight: float = 0.7\n",
    "    ) -> List[SearchResult]:\n",
    "        \"\"\"Hybrid search (convenience wrapper)\"\"\"\n",
    "        return self.search(text=query, image=image, k=k, text_weight=text_weight)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Search engine class created!\")\n",
    "print(\"\\nüìã Available methods:\")\n",
    "print(\"  - search() : Unified search interface\")\n",
    "print(\"  - search_text() : Text-only search\")\n",
    "print(\"  - search_image() : Image-only search\")\n",
    "print(\"  - search_hybrid() : Combined text + image search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1766154344120,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "CSq8a0kQ9lR2",
    "outputId": "efc29040-8e3c-4ae0-e8d2-f1b930ef72e9"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10) INITIALIZE SEARCH ENGINE\n",
    "# ============================================================\n",
    "\n",
    "print(\"üöÄ INITIALIZING SEARCH ENGINE...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "search_engine = FashionSearchEngine(\n",
    "    index=index,\n",
    "    products_df=df,\n",
    "    text_model=text_model,\n",
    "    clip_model=clip_model,\n",
    "    clip_processor=clip_processor,\n",
    "    query_understander=query_understander,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Search engine initialized!\")\n",
    "print(\"\\nüìä Configuration:\")\n",
    "print(f\"  Products: {len(df):,}\")\n",
    "print(f\"  Index vectors: {index.ntotal:,}\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  Text model: {MODEL_CONFIG['text_model_primary']}\")\n",
    "print(f\"  Image model: {MODEL_CONFIG['image_model']}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Ready for search!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2640,
     "status": "ok",
     "timestamp": 1766154346764,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "0GjSpUkf9lR2",
    "outputId": "35d6b516-5940-45be-f340-f5dad480bcbd"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 11) TEST TEXT SEARCH\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîç TESTING TEXT SEARCH...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"red dress for women\",\n",
    "    \"blue jeans men\",\n",
    "    \"black leather shoes\",\n",
    "    \"winter jacket\",\n",
    "    \"casual t-shirt\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüìù Query: '{query}'\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Search\n",
    "    start_time = time.time()\n",
    "    results = search_engine.search_text(query, k=5)\n",
    "    search_time = (time.time() - start_time) * 1000\n",
    "\n",
    "    print(f\"‚è±Ô∏è Search time: {search_time:.2f}ms\")\n",
    "    print(f\"üìä Results: {len(results)}\\n\")\n",
    "\n",
    "    # Display results\n",
    "    for result in results:\n",
    "        print(f\"{result.rank}. {result.product_name}\")\n",
    "        print(f\"   Category: {result.category} | Gender: {result.gender} | Color: {result.color}\")\n",
    "        print(f\"   Similarity: {result.similarity:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Text search working correctly!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8541,
     "status": "ok",
     "timestamp": 1766154355321,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "kWwV0Z7e9lR2",
    "outputId": "b7a04ec2-38b6-4684-8df6-d721cc9fa11e"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 12) TEST IMAGE SEARCH\n",
    "# ============================================================\n",
    "\n",
    "print(\"üñºÔ∏è TESTING IMAGE SEARCH...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if IMAGES_DIR:\n",
    "    # Test with random products\n",
    "    test_ids = [1163, 1525, 2133, 5432, 7891]\n",
    "\n",
    "    for product_id in test_ids:\n",
    "        img_path = IMAGES_DIR / f\"{product_id}.jpg\"\n",
    "\n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "\n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Get product info\n",
    "        product_info = df[df['id'] == product_id]\n",
    "        if len(product_info) == 0:\n",
    "            continue\n",
    "        product_info = product_info.iloc[0]\n",
    "\n",
    "        print(f\"\\nüñºÔ∏è Query Image: {product_info['productDisplayName']}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        # Search\n",
    "        start_time = time.time()\n",
    "        results = search_engine.search_image(image, k=5)\n",
    "        search_time = (time.time() - start_time) * 1000\n",
    "\n",
    "        print(f\"‚è±Ô∏è Search time: {search_time:.2f}ms\")\n",
    "        print(f\"üìä Results: {len(results)}\\n\")\n",
    "\n",
    "        # Display results\n",
    "        for result in results:\n",
    "            marker = \"üéØ\" if result.product_id == product_id else \"  \"\n",
    "            print(f\"{marker} {result.rank}. {result.product_name}\")\n",
    "            print(f\"   Category: {result.category} | Gender: {result.gender}\")\n",
    "            print(f\"   Similarity: {result.similarity:.4f}\")\n",
    "\n",
    "        # Only test 2 images\n",
    "        if test_ids.index(product_id) >= 1:\n",
    "            break\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ Image search working correctly!\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Images directory not found - skipping image search tests\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1766154355565,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "WMa-VYmM9lR2",
    "outputId": "05bea018-2342-4971-ccfa-034693002465"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 13) TEST FILTER FUNCTIONALITY\n",
    "# ============================================================\n",
    "\n",
    "print(\"üéØ TESTING FILTER FUNCTIONALITY...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Queries with filters\n",
    "filter_queries = [\n",
    "    \"red dress for women\",\n",
    "    \"blue jeans for men\",\n",
    "    \"black shoes\"\n",
    "]\n",
    "\n",
    "for query in filter_queries:\n",
    "    print(f\"\\nüìù Query: '{query}'\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Understand query\n",
    "    intent = query_understander.understand_query(text=query)\n",
    "    print(f\"Detected filters: {intent.filters}\")\n",
    "\n",
    "    # Search with filters\n",
    "    results = search_engine.search_text(query, k=5)\n",
    "\n",
    "    print(f\"\\nüìä Results (top 5):\\n\")\n",
    "    for result in results:\n",
    "        print(f\"{result.rank}. {result.product_name}\")\n",
    "        print(f\"   Gender: {result.gender} | Color: {result.color}\")\n",
    "\n",
    "        # Verify filter match\n",
    "        matches = []\n",
    "        if 'gender' in intent.filters:\n",
    "            if intent.filters['gender'] in result.gender.lower():\n",
    "                matches.append(\"‚úì Gender\")\n",
    "        if 'color' in intent.filters:\n",
    "            if intent.filters['color'] in result.color.lower():\n",
    "                matches.append(\"‚úì Color\")\n",
    "\n",
    "        if matches:\n",
    "            print(f\"   Filters: {', '.join(matches)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Filter functionality working!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500,
     "referenced_widgets": [
      "4e54a4b33dd44d8ebb7eea52643a8098",
      "0dc0f2061cf2462d9291ff4b81442a0b",
      "0036b6afb01d41d096c6daf244c14935",
      "3ce98d60b8864ea7b38e6e909dc9c164",
      "ba53ca83add644c7ade9de92b7f4fd41",
      "c51c1a432d0f4fd18bf9656b0e34bed4",
      "ac3314748e284f7ab511907bdaf2ca12",
      "9649c8a09b6c4efb8f93e8d5508f873d",
      "4dafa412799e49008e6809f4b7013ec7",
      "5b00ea6c6c5d494a818d8b428fb3147c",
      "1cca4af396ba46ac83d0b2ab8013113d"
     ]
    },
    "executionInfo": {
     "elapsed": 1636,
     "status": "ok",
     "timestamp": 1766154357214,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "YDr67wRd9lR2",
    "outputId": "96cf7d72-70d2-45bd-9ef4-fc526258d431"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 14) PERFORMANCE BENCHMARK\n",
    "# ============================================================\n",
    "\n",
    "print(\"‚ö° PERFORMANCE BENCHMARK...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Benchmark setup\n",
    "n_queries = 100\n",
    "k = 10\n",
    "\n",
    "# Test queries (repeated)\n",
    "benchmark_queries = [\n",
    "    \"red dress\", \"blue jeans\", \"black shoes\", \"white shirt\", \"winter jacket\",\n",
    "    \"summer dress\", \"casual tshirt\", \"formal shoes\", \"sports shoes\", \"handbag\"\n",
    "] * 10\n",
    "\n",
    "print(f\"Running {n_queries} queries...\")\n",
    "print(f\"Retrieving top-{k} for each\\n\")\n",
    "\n",
    "# Warm-up\n",
    "_ = search_engine.search_text(\"test query\", k=5)\n",
    "\n",
    "# Benchmark\n",
    "times = []\n",
    "for query in tqdm(benchmark_queries, desc=\"Benchmarking\"):\n",
    "    start = time.time()\n",
    "    _ = search_engine.search_text(query, k=k)\n",
    "    elapsed = (time.time() - start) * 1000  # ms\n",
    "    times.append(elapsed)\n",
    "\n",
    "# Statistics\n",
    "times = np.array(times)\n",
    "mean_time = times.mean()\n",
    "median_time = np.median(times)\n",
    "p95_time = np.percentile(times, 95)\n",
    "p99_time = np.percentile(times, 99)\n",
    "qps = 1000 / mean_time\n",
    "\n",
    "print(\"\\nüìä PERFORMANCE RESULTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Queries: {n_queries}\")\n",
    "print(f\"\\nLatency:\")\n",
    "print(f\"  Mean:   {mean_time:.2f}ms\")\n",
    "print(f\"  Median: {median_time:.2f}ms\")\n",
    "print(f\"  P95:    {p95_time:.2f}ms\")\n",
    "print(f\"  P99:    {p99_time:.2f}ms\")\n",
    "print(f\"\\nThroughput:\")\n",
    "print(f\"  QPS: {qps:.1f} queries/second\")\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nüéØ Performance Evaluation:\")\n",
    "if mean_time < 30:\n",
    "    print(\"  ‚úÖ Excellent! (<30ms average)\")\n",
    "elif mean_time < 50:\n",
    "    print(\"  ‚úÖ Good! (30-50ms average)\")\n",
    "elif mean_time < 100:\n",
    "    print(\"  ‚ö†Ô∏è Acceptable (50-100ms average)\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è Slow! (>100ms average)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Performance benchmark complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1766154357288,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "4GM7wIxa9lR3",
    "outputId": "21b0bdb3-c7d8-4ac0-b993-ae67def95ef0"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 15) SAVE SEARCH ENGINE MODULE\n",
    "# ============================================================\n",
    "\n",
    "print(\"üíæ SAVING SEARCH ENGINE MODULE...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create complete module\n",
    "module_code = '''\"\"\"\\nBaseline Fashion Search Engine\\n\\nProduction-grade search engine supporting:\\n- Text search (mpnet + CLIP text)\\n- Image search (CLIP image)\\n- Hybrid search (text + image)\\n- Query understanding and filtering\\n- FAISS-based retrieval\\n\"\"\"\\n\\nimport numpy as np\\nimport pandas as pd\\nimport faiss\\nimport torch\\nfrom typing import List, Dict, Optional, Tuple, Union\\nfrom dataclasses import dataclass\\nfrom sentence_transformers import SentenceTransformer\\nfrom transformers import CLIPModel, CLIPProcessor\\nfrom PIL import Image\\nimport re\\n\\ntry:\\n    from schema import normalize_text\\nexcept ImportError:\\n    def normalize_text(text: str, mode: str = \"standard\") -> str:\\n        text = text.lower().strip()\\n        text = re.sub(r\\'\\\\s+\\', \\' \\', text)\\n        return text\\n\\n\\n@dataclass\\nclass QueryIntent:\\n    \"\"\"Query intent classification\"\"\"\\n    query_type: str\\n    search_mode: str\\n    normalized_text: Optional[str] = None\\n    has_filters: bool = False\\n    filters: Dict = None\\n\\n\\n@dataclass\\nclass SearchResult:\\n    \"\"\"Search result with ranking information\"\"\"\\n    rank: int\\n    product_id: int\\n    product_name: str\\n    category: str\\n    gender: str\\n    color: str\\n    distance: float\\n    similarity: float\\n    score: float\\n\\n\\nclass QueryUnderstanding:\\n    \"\"\"Query understanding and normalization\"\"\"\\n    \\n    def __init__(self):\\n        self.category_keywords = {\\n            \\'apparel\\': [\\'dress\\', \\'shirt\\', \\'tshirt\\', \\'jeans\\', \\'pants\\'],\\n            \\'accessories\\': [\\'watch\\', \\'bag\\', \\'wallet\\', \\'belt\\'],\\n            \\'footwear\\': [\\'shoes\\', \\'sandals\\', \\'heels\\', \\'boots\\']\\n        }\\n        self.color_keywords = [\\n            \\'red\\', \\'blue\\', \\'green\\', \\'yellow\\', \\'black\\', \\'white\\',\\n            \\'grey\\', \\'pink\\', \\'purple\\', \\'brown\\', \\'orange\\'\\n        ]\\n        self.gender_keywords = [\\'men\\', \\'women\\', \\'unisex\\', \\'boys\\', \\'girls\\']\\n    \\n    def understand_query(self, text: Optional[str] = None, image: Optional[Image.Image] = None) -> QueryIntent:\\n        if text and image:\\n            query_type, search_mode = \\'hybrid\\', \\'semantic\\'\\n        elif text:\\n            query_type, search_mode = \\'text\\', \\'semantic\\'\\n        elif image:\\n            query_type, search_mode = \\'image\\', \\'visual\\'\\n        else:\\n            raise ValueError(\"Must provide text or image!\")\\n        \\n        normalized_text = None\\n        filters = {}\\n        has_filters = False\\n        \\n        if text:\\n            normalized_text = normalize_text(text, mode=\"standard\")\\n            text_lower = text.lower()\\n            \\n            for color in self.color_keywords:\\n                if color in text_lower:\\n                    filters[\\'color\\'] = color\\n                    has_filters = True\\n            \\n            for gender in self.gender_keywords:\\n                if gender in text_lower:\\n                    filters[\\'gender\\'] = gender\\n                    has_filters = True\\n        \\n        return QueryIntent(\\n            query_type=query_type,\\n            search_mode=search_mode,\\n            normalized_text=normalized_text,\\n            has_filters=has_filters,\\n            filters=filters\\n        )\\n\\n\\nclass FashionSearchEngine:\\n    \"\"\"Production-grade fashion search engine\"\"\"\\n    \\n    def __init__(self, index, products_df, text_model, clip_model, clip_processor, query_understander, device=\"cpu\"):\\n        self.index = index\\n        self.df = products_df\\n        self.text_model = text_model\\n        self.clip_model = clip_model\\n        self.clip_processor = clip_processor\\n        self.query_understander = query_understander\\n        self.device = device\\n        self._embedding_cache = {}\\n    \\n    def encode_text(self, text: str) -> np.ndarray:\\n        if text in self._embedding_cache:\\n            return self._embedding_cache[text]\\n        \\n        mpnet_emb = self.text_model.encode([text], convert_to_numpy=True)[0]\\n        inputs = self.clip_processor(text=[text], return_tensors=\"pt\", padding=True, truncation=True)\\n        inputs = {k: v.to(self.device) for k, v in inputs.items()}\\n        with torch.no_grad():\\n            clip_text_emb = self.clip_model.get_text_features(**inputs).cpu().numpy()[0]\\n        \\n        combined = np.concatenate([mpnet_emb, clip_text_emb])\\n        self._embedding_cache[text] = combined\\n        return combined\\n    \\n    def encode_image(self, image: Image.Image) -> np.ndarray:\\n        inputs = self.clip_processor(images=image, return_tensors=\"pt\")\\n        inputs = {k: v.to(self.device) for k, v in inputs.items()}\\n        with torch.no_grad():\\n            return self.clip_model.get_image_features(**inputs).cpu().numpy()[0]\\n    \\n    def search(self, text=None, image=None, k=50, text_weight=0.7, apply_filters=True) -> List[SearchResult]:\\n        intent = self.query_understander.understand_query(text=text, image=image)\\n        \\n        if text:\\n            text = intent.normalized_text\\n        \\n        if text and image:\\n            text_emb = self.encode_text(text) * text_weight\\n            image_emb = self.encode_image(image) * (1 - text_weight)\\n            hybrid_emb = np.concatenate([text_emb, image_emb])\\n        elif text:\\n            text_emb = self.encode_text(text)\\n            hybrid_emb = np.concatenate([text_emb, np.zeros(768)])\\n        elif image:\\n            image_emb = self.encode_image(image)\\n            hybrid_emb = np.concatenate([np.zeros(1536), image_emb])\\n        else:\\n            raise ValueError(\"Must provide text or image!\")\\n        \\n        hybrid_emb = hybrid_emb / np.linalg.norm(hybrid_emb)\\n        query_vec = hybrid_emb.astype(\\'float32\\').reshape(1, -1)\\n        \\n        retrieve_k = k * 3 if apply_filters and intent.has_filters else k\\n        distances, indices = self.index.search(query_vec, retrieve_k)\\n        \\n        results = []\\n        for idx, dist in zip(indices[0], distances[0]):\\n            product = self.df.iloc[idx]\\n            \\n            if apply_filters and intent.has_filters:\\n                if \\'color\\' in intent.filters:\\n                    if intent.filters[\\'color\\'] not in str(product.get(\\'baseColour\\', \\'\\')').lower():\\n                        continue\\n                if \\'gender\\' in intent.filters:\\n                    if intent.filters[\\'gender\\'] not in str(product.get(\\'gender\\', \\'\\')').lower():\\n                        continue\\n            \\n            similarity = 1 - dist\\n            results.append(SearchResult(\\n                rank=len(results) + 1,\\n                product_id=int(product[\\'id\\']),\\n                product_name=product[\\'productDisplayName\\'],\\n                category=product.get(\\'masterCategory\\', \\'Unknown\\'),\\n                gender=product.get(\\'gender\\', \\'Unknown\\'),\\n                color=product.get(\\'baseColour\\', \\'Unknown\\'),\\n                distance=float(dist),\\n                similarity=float(similarity),\\n                score=float(similarity)\\n            ))\\n            \\n            if len(results) >= k:\\n                break\\n        \\n        return results\\n    \\n    def search_text(self, query: str, k: int = 10) -> List[SearchResult]:\\n        return self.search(text=query, k=k)\\n    \\n    def search_image(self, image: Image.Image, k: int = 10) -> List[SearchResult]:\\n        return self.search(image=image, k=k)\\n    \\n    def search_hybrid(self, query: str, image: Image.Image, k: int = 10, text_weight: float = 0.7) -> List[SearchResult]:\\n        return self.search(text=query, image=image, k=k, text_weight=text_weight)\\n'''\n",
    "\n",
    "# Save module\n",
    "output_path = SRC_DIR / \"search_engine.py\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(module_code)\n",
    "\n",
    "print(f\"‚úÖ Module saved: {output_path}\")\n",
    "print(f\"  Size: {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Test import\n",
    "print(\"\\nüß™ Testing module import...\")\n",
    "try:\n",
    "    import importlib\n",
    "    if 'search_engine' in sys.modules:\n",
    "        importlib.reload(sys.modules['search_engine'])\n",
    "    else:\n",
    "        import search_engine\n",
    "    print(\"‚úÖ Module imports successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Import test failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Search engine module saved!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1766154357316,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "Zoz_5xe_9lR3",
    "outputId": "18a45214-0f32-43f7-bfb8-3d1da594060e"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 16) SAVE PERFORMANCE REPORT\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìä SAVING PERFORMANCE REPORT...\\n\")\n",
    "\n",
    "# Create report\n",
    "report = {\n",
    "    \"baseline_search_performance\": {\n",
    "        \"version\": \"1.0\",\n",
    "        \"date\": pd.Timestamp.now().isoformat(),\n",
    "        \"configuration\": {\n",
    "            \"text_model\": MODEL_CONFIG['text_model_primary'],\n",
    "            \"image_model\": MODEL_CONFIG['image_model'],\n",
    "            \"index_type\": \"FAISS HNSW\",\n",
    "            \"index_vectors\": int(index.ntotal),\n",
    "            \"device\": device\n",
    "        },\n",
    "        \"performance\": {\n",
    "            \"mean_latency_ms\": float(mean_time),\n",
    "            \"median_latency_ms\": float(median_time),\n",
    "            \"p95_latency_ms\": float(p95_time),\n",
    "            \"p99_latency_ms\": float(p99_time),\n",
    "            \"qps\": float(qps)\n",
    "        },\n",
    "        \"features\": {\n",
    "            \"text_search\": True,\n",
    "            \"image_search\": IMAGES_DIR is not None,\n",
    "            \"hybrid_search\": True,\n",
    "            \"query_understanding\": True,\n",
    "            \"filters\": [\"color\", \"gender\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save\n",
    "report_path = RESULTS_DIR / \"baseline_search_performance.json\"\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Report saved: {report_path}\")\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"  Mean latency: {mean_time:.2f}ms\")\n",
    "print(f\"  QPS: {qps:.1f}\")\n",
    "print(f\"  Text search: ‚úÖ\")\n",
    "print(f\"  Image search: {'‚úÖ' if IMAGES_DIR else '‚ö†Ô∏è'}\")\n",
    "print(f\"  Hybrid search: ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1766154357342,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "VnMnlaZI9lR3",
    "outputId": "efacf24d-aa28-4352-8cee-41c003ee8c6f"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 17) QUALITY GATES VALIDATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüéØ QUALITY GATES VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "gates_passed = True\n",
    "\n",
    "# Gate 1: Query normalization consistent\n",
    "test_text = \"Red Dress For Women\"\n",
    "normalized = normalize_text(test_text, mode=\"standard\")\n",
    "if normalized == test_text.lower().strip():\n",
    "    print(\"‚úÖ Gate 1: Query normalization working (SSOT consistent)\")\n",
    "else:\n",
    "    print(\"‚ùå Gate 1: Normalization inconsistent!\")\n",
    "    gates_passed = False\n",
    "\n",
    "# Gate 2: All search modes functional\n",
    "try:\n",
    "    text_results = search_engine.search_text(\"test query\", k=5)\n",
    "    if len(text_results) == 5:\n",
    "        print(\"‚úÖ Gate 2: Text search working (returns k results)\")\n",
    "    else:\n",
    "        print(\"‚ùå Gate 2: Text search returns wrong count\")\n",
    "        gates_passed = False\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Gate 2: Text search failed ({e})\")\n",
    "    gates_passed = False\n",
    "\n",
    "# Gate 3: Results ranked by relevance\n",
    "results = search_engine.search_text(\"red dress\", k=10)\n",
    "similarities = [r.similarity for r in results]\n",
    "if similarities == sorted(similarities, reverse=True):\n",
    "    print(\"‚úÖ Gate 3: Results properly ranked by similarity\")\n",
    "else:\n",
    "    print(\"‚ùå Gate 3: Results not properly ranked!\")\n",
    "    gates_passed = False\n",
    "\n",
    "# Gate 4: Performance acceptable\n",
    "if mean_time < 50:\n",
    "    print(f\"‚úÖ Gate 4: Performance excellent ({mean_time:.2f}ms < 50ms)\")\n",
    "elif mean_time < 100:\n",
    "    print(f\"‚ö†Ô∏è Gate 4: Performance acceptable ({mean_time:.2f}ms < 100ms)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Gate 4: Performance slow ({mean_time:.2f}ms > 100ms)\")\n",
    "\n",
    "# Gate 5: Module saved\n",
    "if (SRC_DIR / \"search_engine.py\").exists():\n",
    "    print(\"‚úÖ Gate 5: Search engine module saved for production\")\n",
    "else:\n",
    "    print(\"‚ùå Gate 5: Module not saved!\")\n",
    "    gates_passed = False\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if gates_passed:\n",
    "    print(\"\\nüéâ ALL QUALITY GATES PASSED!\")\n",
    "    print(\"‚úÖ Baseline search engine is production-ready!\")\n",
    "    print(\"\\nüìç Next Steps:\")\n",
    "    print(\"  1. Commit search_engine.py to GitHub\")\n",
    "    print(\"  2. Phase 3, Notebook 2: Learned Fusion (Phase G integration)\")\n",
    "    print(\"  3. Phase 4: Evaluation & Optimization\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è SOME QUALITY GATES FAILED!\")\n",
    "    print(\"   Please review and fix before proceeding.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéä PHASE 3, NOTEBOOK 1 COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTnK8qvV9lR3"
   },
   "source": [
    "---\n",
    "\n",
    "## üìã Summary\n",
    "\n",
    "**Baseline Search Engine Complete!** ‚úÖ\n",
    "\n",
    "### Features Implemented:\n",
    "\n",
    "1. **Query Understanding:**\n",
    "   - Text normalization (SSOT consistent)\n",
    "   - Intent detection\n",
    "   - Filter extraction (color, gender)\n",
    "\n",
    "2. **Multi-Modal Retrieval:**\n",
    "   - Text search (mpnet + CLIP text)\n",
    "   - Image search (CLIP image)\n",
    "   - Hybrid search (weighted combination)\n",
    "\n",
    "3. **Baseline Ranking:**\n",
    "   - Distance-based scoring\n",
    "   - Filter application\n",
    "   - Similarity ranking\n",
    "\n",
    "4. **Production Module:**\n",
    "   - Reusable `search_engine.py`\n",
    "   - Embedding caching\n",
    "   - Performance optimized\n",
    "\n",
    "### Performance:\n",
    "\n",
    "- **Latency:** ~20-50ms per query\n",
    "- **QPS:** 20-50 queries/second\n",
    "- **Accuracy:** Distance-based (baseline)\n",
    "\n",
    "### Files Created:\n",
    "\n",
    "- `src/search_engine.py` - Production search module\n",
    "- `docs/results/baseline_search_performance.json` - Performance report\n",
    "\n",
    "### Next Phase:\n",
    "\n",
    "**Phase G Integration:** Learned Fusion for improved ranking\n",
    "- Use your existing Phase G trained fusion weights\n",
    "- Integrate with baseline search\n",
    "- Improve ranking accuracy\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

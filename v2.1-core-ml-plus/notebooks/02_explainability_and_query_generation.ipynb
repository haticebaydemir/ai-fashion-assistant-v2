{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M48IAPhRJ9HC"
   },
   "source": [
    "# Explainability System & Comprehensive Query Generation\n",
    "\n",
    "**Project:** AI Fashion Assistant - T√úBƒ∞TAK 2209-A Research Project  \n",
    "**Date:** January 1, 2025  \n",
    "**Version:** v2.1-core-ml-plus\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements two critical components for production-ready fashion search:\n",
    "\n",
    "1. **Explainability System**: Generate human-readable explanations for search results\n",
    "2. **Comprehensive Query Generation**: Create 100+ diverse test queries using LLM\n",
    "\n",
    "### Objectives\n",
    "\n",
    "**Explainability:**\n",
    "- Explain why each result was retrieved\n",
    "- Highlight matching attributes (pattern, color, style, etc.)\n",
    "- Show confidence scores and fusion contributions\n",
    "- Enable user trust and search refinement\n",
    "\n",
    "**Query Generation:**\n",
    "- Generate 100+ diverse, realistic queries\n",
    "- Cover multiple difficulty levels (simple ‚Üí complex)\n",
    "- Include attribute-specific queries\n",
    "- Support bilingual (Turkish/English) scenarios\n",
    "\n",
    "### Methodology\n",
    "\n",
    "**Explainability:**\n",
    "- Attribute matching analysis\n",
    "- Text-image fusion score decomposition\n",
    "- Template-based natural language generation\n",
    "- LLM-enhanced contextual explanations\n",
    "\n",
    "**Query Generation:**\n",
    "- LLM-based query synthesis (GROQ Llama-3.3-70B)\n",
    "- Stratified sampling across query types\n",
    "- Attribute-aware query construction\n",
    "- Quality validation and deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2qQJX4qJ9HF"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "### Part 1: Explainability System\n",
    "1. [Setup & Data Loading](#1-setup)\n",
    "2. [Search Engine with Fusion](#2-search-engine)\n",
    "3. [Explainability Framework](#3-explainability)\n",
    "4. [Example Explanations](#4-examples)\n",
    "\n",
    "### Part 2: Query Generation\n",
    "5. [LLM Setup (GROQ)](#5-llm-setup)\n",
    "6. [Query Categories & Templates](#6-query-categories)\n",
    "7. [LLM-Based Generation](#7-generation)\n",
    "8. [Query Validation & Export](#8-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW4_r1e8J9HF"
   },
   "source": [
    "---\n",
    "# Part 1: Explainability System\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su-NoW3xJ9HG"
   },
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1356,
     "status": "ok",
     "timestamp": 1767281122201,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "ODpMornLJ9HH",
    "outputId": "b2e5861d-6d45-4f09-88c6-c5a65184a1b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "‚úÖ Working directory: /content/drive/MyDrive/ai_fashion_assistant_v2\n"
     ]
    }
   ],
   "source": [
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "os.chdir('/content/drive/MyDrive/ai_fashion_assistant_v2')\n",
    "\n",
    "print(f'‚úÖ Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6260,
     "status": "ok",
     "timestamp": 1767281120800,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "yO_MXR9dKbbI",
    "outputId": "984a7049-3e53-41ee-cc2e-dbb5c5eead28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.13.2\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1767281120833,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "PK6W0uSvJ9HH",
    "outputId": "8473bcb4-954d-4280-d5f9-05a9702e1d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports complete\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('‚úÖ Imports complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1767281122221,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "svS1NZ0hJ9HI",
    "outputId": "8d04f155-0e03-422d-be4d-af79f5fe45d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config loaded\n",
      "   Device: cpu\n",
      "   Fusion Œ±: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Paths\n",
    "    V20_EMBEDDINGS = 'v2.0-baseline/embeddings'\n",
    "    V21_RESULTS = 'v2.1-core-ml-plus/evaluation/results'\n",
    "    METADATA_PATH = 'data/processed/meta_ssot.csv'\n",
    "\n",
    "    # Models\n",
    "    TEXT_ENCODER = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n",
    "\n",
    "    # Fusion parameters\n",
    "    ALPHA = 0.7  # Text weight (from Day 1-2 optimization)\n",
    "\n",
    "    # Search parameters\n",
    "    TOP_K = 10\n",
    "\n",
    "    # Device\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Config()\n",
    "print('‚úÖ Config loaded')\n",
    "print(f'   Device: {config.DEVICE}')\n",
    "print(f'   Fusion Œ±: {config.ALPHA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16807,
     "status": "ok",
     "timestamp": 1767281139041,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "flpnZyyjJ9HI",
    "outputId": "3f58c687-3109-4917-a647-fcdbf6d18c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "‚úÖ Data loaded\n",
      "   Products: 44,417\n",
      "   Text embeddings: (44417, 768)\n",
      "   Image embeddings: (44417, 768)\n",
      "   Attributes: 307,720 total\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print('Loading data...')\n",
    "\n",
    "# Embeddings\n",
    "text_emb = np.load(f'{config.V20_EMBEDDINGS}/text/mpnet_768d.npy')\n",
    "image_emb = np.load(f'{config.V20_EMBEDDINGS}/image/clip_image_768d_normalized.npy')\n",
    "\n",
    "# Metadata\n",
    "metadata = pd.read_csv(config.METADATA_PATH)\n",
    "\n",
    "# Enhanced products (with attributes)\n",
    "enhanced = pd.read_csv(f'{config.V21_RESULTS}/enhanced_products.csv')\n",
    "\n",
    "# Attributes (long format)\n",
    "attributes = pd.read_csv(f'{config.V21_RESULTS}/product_attributes.csv')\n",
    "\n",
    "print(f'‚úÖ Data loaded')\n",
    "print(f'   Products: {len(metadata):,}')\n",
    "print(f'   Text embeddings: {text_emb.shape}')\n",
    "print(f'   Image embeddings: {image_emb.shape}')\n",
    "print(f'   Attributes: {len(attributes):,} total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo1i96r6J9HI"
   },
   "source": [
    "## 2. Search Engine with Learned Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438,
     "referenced_widgets": [
      "3fc67f2a3869430b8ccda5c544fb35f2",
      "ea9e2feb851247ebac29710265d96f52",
      "88bf8ac1f8ce4a0187912baf59034eec",
      "d44e0f029d5340a2a8c00a3974eb936f",
      "d446da1043cb42ca9f07b7b9b93a7246",
      "c5ed9fc7a9c04fa88c79aeeb8bd0ebc6",
      "220cc86e068d468bb0215a651a9f9176",
      "ec6b6042ec954b6fb5868a36239e2257",
      "4de0e77c0baf423d9446d624c0caf0bb",
      "7c0a8e9ba5c14700bad10fd997da5578",
      "46505fced51b4cb2ae6ef37617de85e8",
      "78407ac6754243c793142db80bf931fb",
      "4ed190107e5b4b4e987808dab8dcf43c",
      "c82402bd777a4563b3301572793bdd24",
      "e59bde1d5e2e47299b7ff400bc7c982a",
      "1a6674522eb84fdabdd72bb17d344413",
      "bdb2e58eeb6b4beca6f301eef43e9d1c",
      "8808ec76ba884148bff17b117388300a",
      "5728896edffd42dc8f59e61580de3380",
      "b5a4dba89f744dd684c8c68c2a85f649",
      "602c9410e46d48b093e97b50eadf7592",
      "c9f0a33bd128425184661382c22c1b80",
      "98721dfc09c4477db973bb637f2883e3",
      "4cfd0210ac6c4f0d867fb93573677009",
      "64f6bb3df91c4a9087b47b7cfb0ca354",
      "783a619691694d62b06e3f463c67c709",
      "11d965fd2177436fa6dbcc2e1c104717",
      "0e577bd4f9e24458b74ebf37328e8c51",
      "a4bcc000548c4ba18c7a3544089af1ad",
      "bf2d21a598b9476e8ae3462bd7301833",
      "a20af12f5e2d4f39853ae510c724985c",
      "e45f2323dcf1442c852292155d8c6d63",
      "bfd06b8250464198bd05dd257bca7153",
      "1ca4b11cc2bf4d6398147272d599f3b0",
      "e1274331e02e45e381544d818b1e302f",
      "2b247b9dfa954183b34bf65c9a03dd7f",
      "0ba755013fb34c06ada1b09e23821b3c",
      "d9e5d64a44764b698a6005b83c771066",
      "b6e2f8e829e44d56a6f7979736d9797f",
      "ae928904e9a74ff7ace8294c57feb444",
      "7ce736e9d75b434483333438bf9e8eec",
      "83cf3f7cd9bd4382be2f4899eb9fd6d0",
      "846654f08f5540bb99c7b491bfe0b1bf",
      "bde5e3fae3f549ce9b63bd1a99edef04",
      "aa094ee918b5491f9642a6b1d08c4774",
      "f76d3c2f8b6149c4a484575477c1267e",
      "38e6d2c69e894f23b7d71b2f91dd2c31",
      "4d690549c0bc4efe823d666b1e6006aa",
      "279376d267eb4b8ea48890d50c60469c",
      "418d674fe4af4521a17191966ed394bc",
      "ecf0dd35417744baacdb4a3e13ad7897",
      "958a6be30abe4b12b644b68b4ce544b0",
      "7da8582345d44c1baa2aa0b8354ab768",
      "080c1d215dba4ecd9bbb4d32459c0228",
      "6d0e49aa382a43bea62397a799d649bf",
      "28fcdf89c50e4021be7e8ce6128f11b5",
      "ad6bc5d543354fec8e4a77c9ebae044b",
      "10762d6095ae4110bf3b991c443d0dcb",
      "aa72cafd719f415d91571766d029754b",
      "dda479168f264f3b9d78fd45b82a0fac",
      "0513a4cd444048d2a2c7d7248925a5ce",
      "fedf9a6a9b1a4ae8b4529256fd5299fd",
      "9d2e6fa68211498d88469dc6e589fdc2",
      "7745c1f310364145923eb26171c81f65",
      "8b80264ee25d40549a51f381ab2de9e3",
      "833aced88aaa4fd1a59c6cfefecc7cb3",
      "e77e680e90ad4e67a04c682c8743059e",
      "304146f6a7e54aa682e264870c15e1e5",
      "4da1f3966073445796f2ca6ad5b86378",
      "eb0dc967441d4e0f8678690c3a277728",
      "3f04f7ee5c3041c0b2c84306d005fa95",
      "5725755f3cb4420da96e37ae0085d413",
      "1e09f3032365452bb9d25d902bafc8ae",
      "0aeda0552a4f42ff80252adef535aaba",
      "7441400f568147f6bf51611b1b337df5",
      "669c5b72ed7e4069bbc3bfce10dfe863",
      "a71605cb49b54a12bc3bfa1d489731e9",
      "de54afde5bee4de4a0621ded1cabeb21",
      "0d95eb2c439c4990b49b1c4a56be21df",
      "eefb27774af54072b18d403f18c6a6d1",
      "6bc0a3f43d204a96a5bbc7b2e1459332",
      "ed3704d0eb2c459e931db0218b736ab4",
      "fd7bcab816144e259bf35c6b8aeac1b3",
      "5b5a3111fe21425fa161142ee37f11a3",
      "e12459db99f84027819df2701d67b7ae",
      "1270cb5897f1414e80e2a72dfcfbf018",
      "e3c1ef2418a148edaa1d98da4c1d24cc",
      "ebc44cbc24844559900cffb52ba3ac16",
      "7bfb27ebd5c74bb4aab9ce455ceea1b1",
      "d7379d5a2b714266bf4fbda896b5d742",
      "4827ef56610549a1b7db55179b4899ae",
      "c4d7a1d0dbfb4d0aa40951d6f3368e29",
      "fa977b45e279439aa6fb7c2cc0762ff7",
      "24f0b55f870d4e8d841ee7a80071b042",
      "b92314faaefc4a35a0daefb376684a76",
      "7d6c6e9eaff2433db794611d01bbe06b",
      "fea30f6b89d545379281f5e75137d0d9",
      "463ba4adb4ec4bb38e5350b835ba7529",
      "6f811c0c5bbc4dd3a6e4ac01407bb062",
      "39f3041a9e7045359886f191657078b2",
      "ea8a58804feb48a98f2712231474ef00",
      "6cdf6493c6254eaf973fa0d416ad7f76",
      "0e12a101bc8743f3a613aacebe4465ce",
      "f12a84bf8bf64adfadf8c876534cb76f",
      "6aa1ac39b71d476282d02e105742d609",
      "53edcee4a94c44118da9f79cbe34cb8f",
      "6ccd7c2c11c143fb8ada72cf238cb48c",
      "1d99cd5185f04a848a61a112d25785fd",
      "9bd389f799a74367849c6f935ec8432f",
      "5edf0048aca249d5a286cbefb856f1cc",
      "a6d8880d210242c8bf08a41900f93563",
      "aa84d90e84884e48891f9e9dab6069d7",
      "bf2a675f34f84c18ab5eb5c598d6d455",
      "8291d2a7b4914dabb551be7cad424b26",
      "110cee23ceae4e788ea038db5b233d20",
      "ceabe8671bab483e94dc7ae2a2955ed9",
      "aeec35da58e7492bb25f54ccb7d89702",
      "98dbe0bf7e8a4f9fb858882f19508c7c",
      "2ab00d34253c4845957942395bcb22cd",
      "b601f2a6cd62456fbe8a37d249ab9f24",
      "a79ba400f75a42d4b67abc0162183a67"
     ]
    },
    "executionInfo": {
     "elapsed": 30383,
     "status": "ok",
     "timestamp": 1767281169426,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "HXRzx0TxJ9HI",
    "outputId": "d5471ed7-dcaa-4ced-f795-6451a06a61f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing search engine...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc67f2a3869430b8ccda5c544fb35f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78407ac6754243c793142db80bf931fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98721dfc09c4477db973bb637f2883e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca4b11cc2bf4d6398147272d599f3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa094ee918b5491f9642a6b1d08c4774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fcdf89c50e4021be7e8ce6128f11b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77e680e90ad4e67a04c682c8743059e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de54afde5bee4de4a0621ded1cabeb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfb27ebd5c74bb4aab9ce455ceea1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f3041a9e7045359886f191657078b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d8880d210242c8bf08a41900f93563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Search engine ready\n",
      "   Index size: 44,417\n",
      "   Fusion Œ±: 0.7\n"
     ]
    }
   ],
   "source": [
    "class FashionSearchEngine:\n",
    "    \"\"\"Multimodal fashion search with explainability\"\"\"\n",
    "\n",
    "    def __init__(self, text_emb, image_emb, metadata, attributes, alpha=0.7):\n",
    "        self.text_emb = text_emb\n",
    "        self.image_emb = image_emb\n",
    "        self.metadata = metadata\n",
    "        self.attributes = attributes\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Load text encoder\n",
    "        self.encoder = SentenceTransformer(config.TEXT_ENCODER)\n",
    "\n",
    "        # Create fusion embeddings\n",
    "        self.fusion_emb = self._create_fusion()\n",
    "\n",
    "        # Build FAISS index\n",
    "        self.index = self._build_index()\n",
    "\n",
    "        # Build attribute lookup\n",
    "        self.attr_lookup = self._build_attr_lookup()\n",
    "\n",
    "    def _create_fusion(self):\n",
    "        \"\"\"Create fused embeddings\"\"\"\n",
    "        fused = self.alpha * self.text_emb + (1 - self.alpha) * self.image_emb\n",
    "        # Normalize\n",
    "        fused = fused / np.linalg.norm(fused, axis=1, keepdims=True)\n",
    "        return fused\n",
    "\n",
    "    def _build_index(self):\n",
    "        \"\"\"Build FAISS index\"\"\"\n",
    "        dimension = self.fusion_emb.shape[1]\n",
    "        index = faiss.IndexFlatIP(dimension)  # Inner product = cosine similarity\n",
    "        index.add(self.fusion_emb.astype('float32'))\n",
    "        return index\n",
    "\n",
    "    def _build_attr_lookup(self):\n",
    "        \"\"\"Build fast attribute lookup dict\"\"\"\n",
    "        lookup = {}\n",
    "        for _, row in self.attributes.iterrows():\n",
    "            pid = row['product_id']\n",
    "            if pid not in lookup:\n",
    "                lookup[pid] = {}\n",
    "            lookup[pid][row['category']] = {\n",
    "                'value': row['value'],\n",
    "                'confidence': row['confidence']\n",
    "            }\n",
    "        return lookup\n",
    "\n",
    "    def search(self, query: str, k: int = 10) -> Dict:\n",
    "        \"\"\"Search with full explainability data\"\"\"\n",
    "        # Encode query\n",
    "        query_emb = self.encoder.encode([query])[0]\n",
    "        query_emb = query_emb / np.linalg.norm(query_emb)\n",
    "\n",
    "        # Search\n",
    "        scores, indices = self.index.search(\n",
    "            query_emb.reshape(1, -1).astype('float32'),\n",
    "            k\n",
    "        )\n",
    "\n",
    "        # Collect results with explanation data\n",
    "        results = []\n",
    "        for rank, (idx, score) in enumerate(zip(indices[0], scores[0])):\n",
    "            # Compute individual scores\n",
    "            text_score = np.dot(query_emb, self.text_emb[idx])\n",
    "            image_score = np.dot(query_emb, self.image_emb[idx])\n",
    "\n",
    "            # Get product info\n",
    "            product = self.metadata.iloc[idx]\n",
    "            attrs = self.attr_lookup.get(idx, {})\n",
    "\n",
    "            results.append({\n",
    "                'rank': rank + 1,\n",
    "                'product_id': int(idx),\n",
    "                'name': product['productDisplayName'],\n",
    "                'category': product.get('masterCategory', 'Unknown'),\n",
    "                'fusion_score': float(score),\n",
    "                'text_score': float(text_score),\n",
    "                'image_score': float(image_score),\n",
    "                'text_contribution': float(self.alpha * text_score),\n",
    "                'image_contribution': float((1 - self.alpha) * image_score),\n",
    "                'attributes': attrs\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            'query': query,\n",
    "            'results': results,\n",
    "            'alpha': self.alpha\n",
    "        }\n",
    "\n",
    "# Initialize search engine\n",
    "print('Initializing search engine...')\n",
    "search_engine = FashionSearchEngine(\n",
    "    text_emb,\n",
    "    image_emb,\n",
    "    metadata,\n",
    "    attributes,\n",
    "    alpha=config.ALPHA\n",
    ")\n",
    "\n",
    "print('‚úÖ Search engine ready')\n",
    "print(f'   Index size: {search_engine.index.ntotal:,}')\n",
    "print(f'   Fusion Œ±: {search_engine.alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GchFqbCJ9HJ"
   },
   "source": [
    "## 3. Explainability Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1767281169466,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "GCtYb7pFJ9HJ",
    "outputId": "8451f087-22e9-4382-e252-a92f80626f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Explainability generator ready\n"
     ]
    }
   ],
   "source": [
    "class ExplainabilityGenerator:\n",
    "    \"\"\"Generate human-readable search explanations\"\"\"\n",
    "\n",
    "    def __init__(self, alpha: float = 0.7):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def explain_result(self, result: Dict, query: str) -> str:\n",
    "        \"\"\"Generate explanation for a single result\"\"\"\n",
    "        explanation_parts = []\n",
    "\n",
    "        # 1. Overall match score\n",
    "        score_pct = result['fusion_score'] * 100\n",
    "        explanation_parts.append(\n",
    "            f\"**Match Score: {score_pct:.1f}%**\"\n",
    "        )\n",
    "\n",
    "        # 2. Text vs Image contribution\n",
    "        text_contrib = result['text_contribution'] / result['fusion_score'] * 100\n",
    "        image_contrib = result['image_contribution'] / result['fusion_score'] * 100\n",
    "\n",
    "        explanation_parts.append(\n",
    "            f\"- Text match: {text_contrib:.1f}% (description similarity)\"\n",
    "        )\n",
    "        explanation_parts.append(\n",
    "            f\"- Visual match: {image_contrib:.1f}% (appearance similarity)\"\n",
    "        )\n",
    "\n",
    "        # 3. Matching attributes\n",
    "        attrs = result['attributes']\n",
    "        if attrs:\n",
    "            attr_strs = []\n",
    "            for cat, info in attrs.items():\n",
    "                conf_pct = info['confidence'] * 100\n",
    "                attr_strs.append(f\"{info['value']} ({conf_pct:.0f}%)\")\n",
    "\n",
    "            if attr_strs:\n",
    "                explanation_parts.append(\n",
    "                    f\"- Detected attributes: {', '.join(attr_strs[:5])}\"\n",
    "                )\n",
    "\n",
    "        # 4. Why this result?\n",
    "        if result['text_score'] > result['image_score']:\n",
    "            reason = \"Strong textual match - product description aligns with query\"\n",
    "        else:\n",
    "            reason = \"Strong visual similarity - appearance matches query intent\"\n",
    "\n",
    "        explanation_parts.append(f\"- Reason: {reason}\")\n",
    "\n",
    "        return \"\\n\".join(explanation_parts)\n",
    "\n",
    "    def explain_search(self, search_result: Dict) -> str:\n",
    "        \"\"\"Generate full search explanation\"\"\"\n",
    "        query = search_result['query']\n",
    "        results = search_result['results']\n",
    "\n",
    "        explanation = f\"# Search Explanation: '{query}'\\n\\n\"\n",
    "        explanation += f\"Found {len(results)} results using multimodal fusion (Œ±={self.alpha})\\n\\n\"\n",
    "\n",
    "        for result in results[:5]:  # Top 5\n",
    "            explanation += f\"## Rank {result['rank']}: {result['name']}\\n\"\n",
    "            explanation += self.explain_result(result, query)\n",
    "            explanation += \"\\n\\n\"\n",
    "\n",
    "        return explanation\n",
    "\n",
    "# Initialize explainer\n",
    "explainer = ExplainabilityGenerator(alpha=config.ALPHA)\n",
    "print('‚úÖ Explainability generator ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVwapi1gJ9HJ"
   },
   "source": [
    "## 4. Example Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1767281169983,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "yN67EQJZJ9HJ",
    "outputId": "3233af16-3859-4ef7-cd7d-a1810eb6888a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç EXAMPLE SEARCH EXPLANATIONS\n",
      "\n",
      "======================================================================\n",
      "\n",
      "# Search Explanation: 'kƒ±rmƒ±zƒ± elbise'\n",
      "\n",
      "Found 5 results using multimodal fusion (Œ±=0.7)\n",
      "\n",
      "## Rank 1: Remanika Women Red Dress\n",
      "**Match Score: 79.5%**\n",
      "- Text match: 214.5% (description similarity)\n",
      "- Visual match: 0.4% (appearance similarity)\n",
      "- Detected attributes: geometric pattern (20%), loose fitting (20%), short length (20%), v-neck (19%), sleeveless (21%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 2: AND Women Red Dress\n",
      "**Match Score: 78.4%**\n",
      "- Text match: 221.5% (description similarity)\n",
      "- Visual match: 0.2% (appearance similarity)\n",
      "- Detected attributes: geometric pattern (20%), loose fitting (20%), cropped (20%), v-neck (20%), sleeveless (22%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 3: Elle Women Red Dress\n",
      "**Match Score: 77.1%**\n",
      "- Text match: 214.9% (description similarity)\n",
      "- Visual match: 0.8% (appearance similarity)\n",
      "- Detected attributes: geometric pattern (19%), loose fitting (19%), short length (19%), v-neck (21%), sleeveless (20%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 4: Arrow Woman Rima Red Dress\n",
      "**Match Score: 76.3%**\n",
      "- Text match: 208.0% (description similarity)\n",
      "- Visual match: 0.6% (appearance similarity)\n",
      "- Detected attributes: floral print (21%), loose fitting (20%), long length (21%), v-neck (18%), three-quarter sleeve (18%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 5: AND by Anita Dongre Women Printed Red Dresses\n",
      "**Match Score: 76.1%**\n",
      "- Text match: 217.2% (description similarity)\n",
      "- Visual match: 0.5% (appearance similarity)\n",
      "- Detected attributes: floral print (20%), loose fitting (17%), long length (18%), high neck (18%), sleeveless (19%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "# Search Explanation: 'casual summer outfit'\n",
      "\n",
      "Found 5 results using multimodal fusion (Œ±=0.7)\n",
      "\n",
      "## Rank 1: Avirate Magenta Boyshort Brief\n",
      "**Match Score: 77.7%**\n",
      "- Text match: 188.8% (description similarity)\n",
      "- Visual match: -0.2% (appearance similarity)\n",
      "- Detected attributes: polka dot (17%), short length (17%), silk-like (16%), elegant style (19%), party wear (17%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 2: Avirate Black & White  Brief\n",
      "**Match Score: 76.8%**\n",
      "- Text match: 198.8% (description similarity)\n",
      "- Visual match: 0.0% (appearance similarity)\n",
      "- Detected attributes: loose fitting (15%), ankle length (18%), leather-like (18%), elegant style (18%), party wear (18%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 3: Avirate Black & White  Brief\n",
      "**Match Score: 76.7%**\n",
      "- Text match: 202.1% (description similarity)\n",
      "- Visual match: 0.5% (appearance similarity)\n",
      "- Detected attributes: geometric pattern (17%), loose fitting (16%), short length (19%), high neck (16%), silk-like (17%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 4: Avirate Magenta Hi-Leg Brief\n",
      "**Match Score: 76.7%**\n",
      "- Text match: 188.5% (description similarity)\n",
      "- Visual match: -0.4% (appearance similarity)\n",
      "- Detected attributes: polka dot (17%), cropped (16%), silk-like (16%), elegant style (17%), party wear (17%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 5: Jockey Beige Camisole\n",
      "**Match Score: 76.3%**\n",
      "- Text match: 199.3% (description similarity)\n",
      "- Visual match: -0.2% (appearance similarity)\n",
      "- Detected attributes: solid color (19%), loose fitting (19%), medium length (18%), scoop neck (21%), sleeveless (22%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "\n",
      "======================================================================\n",
      "\n",
      "# Search Explanation: 'formal office wear'\n",
      "\n",
      "Found 5 results using multimodal fusion (Œ±=0.7)\n",
      "\n",
      "## Rank 1: Status Quo Men Solid Grey Jackets\n",
      "**Match Score: 53.7%**\n",
      "- Text match: 206.6% (description similarity)\n",
      "- Visual match: -2.3% (appearance similarity)\n",
      "- Detected attributes: solid color (17%), regular fit (18%), short length (18%), round neck (18%), long sleeve (16%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 2: Avirate Black Formal Dress\n",
      "**Match Score: 53.7%**\n",
      "- Text match: 207.5% (description similarity)\n",
      "- Visual match: -0.4% (appearance similarity)\n",
      "- Detected attributes: polka dot (19%), loose fitting (18%), long length (20%), v-neck (19%), sleeveless (20%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 3: AND Women Solid Grey and Black Dress\n",
      "**Match Score: 51.9%**\n",
      "- Text match: 211.4% (description similarity)\n",
      "- Visual match: -0.3% (appearance similarity)\n",
      "- Detected attributes: geometric pattern (18%), loose fitting (18%), ankle length (19%), v-neck (21%), three-quarter sleeve (19%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 4: Avirate Brown & Grey Check Dress\n",
      "**Match Score: 51.6%**\n",
      "- Text match: 202.8% (description similarity)\n",
      "- Visual match: -1.7% (appearance similarity)\n",
      "- Detected attributes: checkered (22%), loose fitting (19%), long length (22%), high neck (21%), sleeveless (21%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "## Rank 5: Proline Grey Striped Sweater\n",
      "**Match Score: 51.0%**\n",
      "- Text match: 202.1% (description similarity)\n",
      "- Visual match: -1.6% (appearance similarity)\n",
      "- Detected attributes: striped (22%), loose fitting (20%), medium length (19%), v-neck (22%), long sleeve (19%)\n",
      "- Reason: Strong textual match - product description aligns with query\n",
      "\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    \"kƒ±rmƒ±zƒ± elbise\",\n",
    "    \"casual summer outfit\",\n",
    "    \"formal office wear\"\n",
    "]\n",
    "\n",
    "print(\"üîç EXAMPLE SEARCH EXPLANATIONS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for query in test_queries:\n",
    "    # Search\n",
    "    result = search_engine.search(query, k=5)\n",
    "\n",
    "    # Explain\n",
    "    explanation = explainer.explain_search(result)\n",
    "\n",
    "    print(f\"\\n{explanation}\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttJ2rIIVJ9HK"
   },
   "source": [
    "---\n",
    "# Part 2: Comprehensive Query Generation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dYOoLFUJ9HK"
   },
   "source": [
    "## 5. LLM Setup (GROQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7907,
     "status": "ok",
     "timestamp": 1767281242719,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "BJIzVnP5J9HK",
    "outputId": "e824beeb-ee98-4e62-b640-f74210f03a65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GROQ client initialized\n",
      "   Model: llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "# Install GROQ\n",
    "!pip install -q groq\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "# Initialize (you'll need to add your API key)\n",
    "# Get free key from: https://console.groq.com\n",
    "GROQ_API_KEY = \"YOUR_GROQ_API_KEY_HERE\"  # Replace with your key\n",
    "\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "print('‚úÖ GROQ client initialized')\n",
    "print('   Model: llama-3.3-70b-versatile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niYP5bhIJ9HK"
   },
   "source": [
    "## 6. Query Categories & Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1767281242749,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "wZ1FmDzdJ9HK",
    "outputId": "9ac3da0f-faf5-482f-80c9-a82764992489"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Query Taxonomy\n",
      "   Total categories: 7\n",
      "   Total queries to generate: 105\n",
      "\n",
      "   Distribution:\n",
      "   - simple_item: 15 queries\n",
      "   - attribute_specific: 20 queries\n",
      "   - occasion_based: 15 queries\n",
      "   - style_based: 15 queries\n",
      "   - complex_multi_attr: 20 queries\n",
      "   - seasonal: 10 queries\n",
      "   - budget_conscious: 10 queries\n"
     ]
    }
   ],
   "source": [
    "# Query taxonomy\n",
    "QUERY_TAXONOMY = {\n",
    "    'simple_item': {\n",
    "        'description': 'Basic product name queries',\n",
    "        'count': 15,\n",
    "        'examples': ['kƒ±rmƒ±zƒ± elbise', 'siyah ayakkabƒ±', 'blue jeans']\n",
    "    },\n",
    "    'attribute_specific': {\n",
    "        'description': 'Queries with specific attributes',\n",
    "        'count': 20,\n",
    "        'examples': ['striped shirt', 'loose fitting pants', 'v-neck summer dress']\n",
    "    },\n",
    "    'occasion_based': {\n",
    "        'description': 'Queries for specific occasions',\n",
    "        'count': 15,\n",
    "        'examples': ['office wear', 'party outfit', 'd√ºƒü√ºn kƒ±yafeti']\n",
    "    },\n",
    "    'style_based': {\n",
    "        'description': 'Style-focused queries',\n",
    "        'count': 15,\n",
    "        'examples': ['vintage style', 'modern casual', 'minimalist look']\n",
    "    },\n",
    "    'complex_multi_attr': {\n",
    "        'description': 'Queries combining multiple attributes',\n",
    "        'count': 20,\n",
    "        'examples': ['casual striped long sleeve shirt', 'elegant formal black dress']\n",
    "    },\n",
    "    'seasonal': {\n",
    "        'description': 'Season-specific queries',\n",
    "        'count': 10,\n",
    "        'examples': ['summer outfit', 'winter coat', 'spring dress']\n",
    "    },\n",
    "    'budget_conscious': {\n",
    "        'description': 'Queries implying price sensitivity',\n",
    "        'count': 10,\n",
    "        'examples': ['affordable casual wear', 'budget friendly shoes']\n",
    "    }\n",
    "}\n",
    "\n",
    "total_queries = sum(cat['count'] for cat in QUERY_TAXONOMY.values())\n",
    "\n",
    "print('üìä Query Taxonomy')\n",
    "print(f'   Total categories: {len(QUERY_TAXONOMY)}')\n",
    "print(f'   Total queries to generate: {total_queries}')\n",
    "print(f'\\n   Distribution:')\n",
    "for name, info in QUERY_TAXONOMY.items():\n",
    "    print(f'   - {name}: {info[\"count\"]} queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf4vUdx7J9HK"
   },
   "source": [
    "## 7. LLM-Based Query Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1767281242755,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "8O2v2jx7J9HK",
    "outputId": "8a631adc-3ddf-4cb4-ef0e-e65656e726f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query generation function ready\n"
     ]
    }
   ],
   "source": [
    "def generate_queries_for_category(category_name: str,\n",
    "                                 category_info: Dict,\n",
    "                                 client: Groq) -> List[str]:\n",
    "    \"\"\"Generate queries for a specific category using LLM\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"You are a fashion e-commerce expert. Generate {category_info['count']} diverse search queries.\n",
    "\n",
    "Category: {category_name}\n",
    "Description: {category_info['description']}\n",
    "Examples: {', '.join(category_info['examples'])}\n",
    "\n",
    "Requirements:\n",
    "- Mix of Turkish and English queries (50-50)\n",
    "- Realistic user search behavior\n",
    "- Diverse product types (clothing, shoes, accessories)\n",
    "- Natural language (as real users would type)\n",
    "- One query per line\n",
    "- No numbering or bullets\n",
    "\n",
    "Generate exactly {category_info['count']} queries:\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.8,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Parse queries\n",
    "    queries = response.choices[0].message.content.strip().split('\\n')\n",
    "    queries = [q.strip() for q in queries if q.strip()]\n",
    "\n",
    "    # Remove numbering if present\n",
    "    queries = [q.split('. ', 1)[-1] if '. ' in q else q for q in queries]\n",
    "\n",
    "    return queries[:category_info['count']]  # Ensure exact count\n",
    "\n",
    "print('‚úÖ Query generation function ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4696,
     "status": "ok",
     "timestamp": 1767281248039,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "JosgT4TeJ9HL",
    "outputId": "d81721b4-1ac0-4ea9-8ebe-a684c0f52a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Generating 105 queries using GROQ Llama-3.3-70B...\n",
      "‚è±Ô∏è  Estimated time: 2-3 minutes\n",
      "\n",
      "Generating 15 queries for: simple_item...\n",
      "  ‚úÖ Generated 15 queries\n",
      "\n",
      "Generating 20 queries for: attribute_specific...\n",
      "  ‚úÖ Generated 20 queries\n",
      "\n",
      "Generating 15 queries for: occasion_based...\n",
      "  ‚úÖ Generated 15 queries\n",
      "\n",
      "Generating 15 queries for: style_based...\n",
      "  ‚úÖ Generated 15 queries\n",
      "\n",
      "Generating 20 queries for: complex_multi_attr...\n",
      "  ‚úÖ Generated 20 queries\n",
      "\n",
      "Generating 10 queries for: seasonal...\n",
      "  ‚úÖ Generated 10 queries\n",
      "\n",
      "Generating 10 queries for: budget_conscious...\n",
      "  ‚úÖ Generated 10 queries\n",
      "\n",
      "\n",
      "‚úÖ GENERATION COMPLETE!\n",
      "   Total queries: 105\n",
      "   Categories: 7\n"
     ]
    }
   ],
   "source": [
    "# GENERATE ALL QUERIES\n",
    "print('üî• Generating 105 queries using GROQ Llama-3.3-70B...')\n",
    "print('‚è±Ô∏è  Estimated time: 2-3 minutes\\n')\n",
    "\n",
    "all_generated_queries = {}\n",
    "\n",
    "for category_name, category_info in QUERY_TAXONOMY.items():\n",
    "    print(f'Generating {category_info[\"count\"]} queries for: {category_name}...')\n",
    "\n",
    "    queries = generate_queries_for_category(\n",
    "        category_name,\n",
    "        category_info,\n",
    "        client\n",
    "    )\n",
    "\n",
    "    all_generated_queries[category_name] = queries\n",
    "    print(f'  ‚úÖ Generated {len(queries)} queries\\n')\n",
    "\n",
    "# Flatten all queries\n",
    "all_queries = []\n",
    "for category, queries in all_generated_queries.items():\n",
    "    for query in queries:\n",
    "        all_queries.append({\n",
    "            'query': query,\n",
    "            'category': category\n",
    "        })\n",
    "\n",
    "print(f'\\n‚úÖ GENERATION COMPLETE!')\n",
    "print(f'   Total queries: {len(all_queries)}')\n",
    "print(f'   Categories: {len(QUERY_TAXONOMY)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJ29RGELJ9HL"
   },
   "source": [
    "## 8. Query Validation & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1767281249566,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "LV_2TzvVJ9HL",
    "outputId": "18f58e6b-bf3e-4ab7-d68f-01545a1a4ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä QUERY STATISTICS:\n",
      "\n",
      "   Total queries: 104\n",
      "   Duplicates removed: 1\n",
      "   Unique queries: 104\n",
      "\n",
      "   Per category:\n",
      "category\n",
      "attribute_specific    20\n",
      "budget_conscious      10\n",
      "complex_multi_attr    20\n",
      "occasion_based        15\n",
      "seasonal              10\n",
      "simple_item           15\n",
      "style_based           14\n",
      "dtype: int64\n",
      "\n",
      "   Language distribution:\n",
      "language\n",
      "English    59\n",
      "Turkish    45\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   Query length (words):\n",
      "count    104.000000\n",
      "mean       3.634615\n",
      "std        1.191048\n",
      "min        2.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        4.250000\n",
      "max        7.000000\n",
      "Name: word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "queries_df = pd.DataFrame(all_queries)\n",
    "\n",
    "# Validation\n",
    "print('üìä QUERY STATISTICS:\\n')\n",
    "\n",
    "# Deduplication\n",
    "original_count = len(queries_df)\n",
    "queries_df = queries_df.drop_duplicates(subset=['query'])\n",
    "duplicates_removed = original_count - len(queries_df)\n",
    "\n",
    "print(f'   Total queries: {len(queries_df)}')\n",
    "print(f'   Duplicates removed: {duplicates_removed}')\n",
    "print(f'   Unique queries: {queries_df[\"query\"].nunique()}')\n",
    "\n",
    "# Category distribution\n",
    "print(f'\\n   Per category:')\n",
    "print(queries_df.groupby('category').size())\n",
    "\n",
    "# Language detection (simple heuristic)\n",
    "def detect_language(query):\n",
    "    turkish_chars = set('√ßƒüƒ±√∂≈ü√º')\n",
    "    return 'Turkish' if any(c in query.lower() for c in turkish_chars) else 'English'\n",
    "\n",
    "queries_df['language'] = queries_df['query'].apply(detect_language)\n",
    "\n",
    "print(f'\\n   Language distribution:')\n",
    "print(queries_df['language'].value_counts())\n",
    "\n",
    "# Length statistics\n",
    "queries_df['word_count'] = queries_df['query'].str.split().str.len()\n",
    "\n",
    "print(f'\\n   Query length (words):')\n",
    "print(queries_df['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1767281252285,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "dBnQAalCJ9HL",
    "outputId": "6f8c05b7-6cee-491c-8e8d-47afcfae9bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù SAMPLE QUERIES (10 random):\n",
      "\n",
      "   [budget_conscious    ] affordable winter coats\n",
      "   [attribute_specific  ] erkek i√ßin geni≈ü ayakkabilar\n",
      "   [complex_multi_attr  ] √ßocuk i√ßin renkli spor ayakkabƒ±\n",
      "   [budget_conscious    ] cheap and trendy accessories for women\n",
      "   [complex_multi_attr  ] sƒ±cak kahverengi kazak\n",
      "   [attribute_specific  ] red scarf for women\n",
      "   [seasonal            ] yaz i√ßin ≈üƒ±k elbise\n",
      "   [attribute_specific  ] high heel sandals for summer\n",
      "   [seasonal            ] ilkbahar i√ßinappropriate ayakkabƒ±\n",
      "   [simple_item         ] siyah √ßanta\n"
     ]
    }
   ],
   "source": [
    "# Sample queries\n",
    "print('\\nüìù SAMPLE QUERIES (10 random):\\n')\n",
    "sample = queries_df.sample(10)\n",
    "for idx, row in sample.iterrows():\n",
    "    print(f\"   [{row['category']:20s}] {row['query']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1767281254256,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "VNqPbxk3J9HL",
    "outputId": "87c6989f-f964-4355-af9d-6210b7556119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Queries saved:\n",
      "   evaluation_queries_100plus.csv (104 queries)\n",
      "   queries_by_category.json (categorized)\n"
     ]
    }
   ],
   "source": [
    "# Export\n",
    "output_dir = Path(config.V21_RESULTS)\n",
    "\n",
    "# Save queries\n",
    "queries_path = output_dir / 'evaluation_queries_100plus.csv'\n",
    "queries_df.to_csv(queries_path, index=False)\n",
    "\n",
    "# Save by category\n",
    "categorized = {}\n",
    "for category in QUERY_TAXONOMY.keys():\n",
    "    categorized[category] = queries_df[queries_df['category'] == category]['query'].tolist()\n",
    "\n",
    "categorized_path = output_dir / 'queries_by_category.json'\n",
    "with open(categorized_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(categorized, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f'‚úÖ Queries saved:')\n",
    "print(f'   {queries_path.name} ({len(queries_df)} queries)')\n",
    "print(f'   {categorized_path.name} (categorized)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1767281255794,
     "user": {
      "displayName": "Hatice Baydemir",
      "userId": "09255724962739063380"
     },
     "user_tz": -180
    },
    "id": "1XjZI046J9HL",
    "outputId": "97702c45-f91d-4a41-d4fd-05b6f0a0fe81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPLAINABILITY & QUERY GENERATION - COMPLETE\n",
      "======================================================================\n",
      "\n",
      "üìä EXPLAINABILITY SYSTEM:\n",
      "   ‚úÖ Multimodal fusion score decomposition\n",
      "   ‚úÖ Attribute-based matching explanations\n",
      "   ‚úÖ Text vs Visual contribution analysis\n",
      "   ‚úÖ Natural language explanation generation\n",
      "\n",
      "üìä QUERY GENERATION:\n",
      "   Total queries: 104\n",
      "   Categories: 7\n",
      "   Languages: {'English': 59, 'Turkish': 45}\n",
      "   Avg length: 3.6 words\n",
      "\n",
      "üìÅ OUTPUT FILES:\n",
      "   1. evaluation_queries_100plus.csv\n",
      "   2. queries_by_category.json\n",
      "\n",
      "‚è≠Ô∏è  NEXT STEPS:\n",
      "   - Run 7 baseline comparisons\n",
      "   - Compute NDCG@10 for all methods\n",
      "   - Statistical validation (p<0.05)\n",
      "   - Generate evaluation report\n",
      "\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Summary saved: v2.1-core-ml-plus/evaluation/results/explainability_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "summary = f\"\"\"\n",
    "{'='*70}\n",
    "EXPLAINABILITY & QUERY GENERATION - COMPLETE\n",
    "{'='*70}\n",
    "\n",
    "üìä EXPLAINABILITY SYSTEM:\n",
    "   ‚úÖ Multimodal fusion score decomposition\n",
    "   ‚úÖ Attribute-based matching explanations\n",
    "   ‚úÖ Text vs Visual contribution analysis\n",
    "   ‚úÖ Natural language explanation generation\n",
    "\n",
    "üìä QUERY GENERATION:\n",
    "   Total queries: {len(queries_df)}\n",
    "   Categories: {len(QUERY_TAXONOMY)}\n",
    "   Languages: {queries_df['language'].value_counts().to_dict()}\n",
    "   Avg length: {queries_df['word_count'].mean():.1f} words\n",
    "\n",
    "üìÅ OUTPUT FILES:\n",
    "   1. evaluation_queries_100plus.csv\n",
    "   2. queries_by_category.json\n",
    "\n",
    "‚è≠Ô∏è  NEXT STEPS:\n",
    "   - Run 7 baseline comparisons\n",
    "   - Compute NDCG@10 for all methods\n",
    "   - Statistical validation (p<0.05)\n",
    "   - Generate evaluation report\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary\n",
    "summary_path = output_dir / 'explainability_summary.txt'\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f'‚úÖ Summary saved: {summary_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFwgsGAtMWX_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

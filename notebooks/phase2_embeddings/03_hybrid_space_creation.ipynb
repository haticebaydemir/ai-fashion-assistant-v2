{"cells":[{"cell_type":"markdown","metadata":{"id":"kOTa3o2g4edu"},"source":["# üåê AI Fashion Assistant v2.0 - Hybrid Space Creation\n","\n","**Phase 2, Notebook 3/3** - Final notebook of Phase 2\n","\n","---\n","\n","## üéØ Objectives\n","\n","1. Load text and image embeddings\n","2. Create hybrid space (text + image concatenation)\n","3. Build FAISS index for fast retrieval\n","4. Validate index quality\n","5. Test search functionality\n","\n","---\n","\n","## üìä Input Files\n","\n","```\n","embeddings/\n","‚îú‚îÄ‚îÄ text/\n","‚îÇ   ‚îî‚îÄ‚îÄ combined_1536d_normalized.npy\n","‚îî‚îÄ‚îÄ image/\n","    ‚îî‚îÄ‚îÄ clip_image_768d_normalized.npy\n","```\n","\n","---\n","\n","## üéØ Output\n","\n","```\n","embeddings/\n","‚îî‚îÄ‚îÄ hybrid/\n","    ‚îú‚îÄ‚îÄ hybrid_2304d.npy          (44,417 x 2304)\n","    ‚îî‚îÄ‚îÄ hybrid_2304d_normalized.npy\n","\n","indexes/\n","‚îî‚îÄ‚îÄ faiss_hybrid_hnsw.index       (~500 MB)\n","```\n","\n","---\n","\n","## üìã Quality Gates\n","\n","- ‚úì Hybrid embeddings: 2304d (1536 + 768)\n","- ‚úì FAISS index built successfully\n","- ‚úì Index size reasonable (~500 MB)\n","- ‚úì Search returns results\n","\n","---"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klrUuO184edy","executionInfo":{"status":"ok","timestamp":1766152362210,"user_tz":-180,"elapsed":19760,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"f1993b47-88b8-4d0f-96f7-39fa4293fe02"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","GPU available: True\n","GPU: NVIDIA A100-SXM4-40GB\n"]}],"source":["# ============================================================\n","# 1) SETUP\n","# ============================================================\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=False)\n","\n","# Check GPU (optional for this notebook)\n","import torch\n","print(f\"GPU available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuloijpx4ed0","executionInfo":{"status":"ok","timestamp":1766152368049,"user_tz":-180,"elapsed":5836,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"19c727ee-9b28-417a-f68c-8f730054b9f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Installing FAISS...\n","\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\n","‚úÖ FAISS installed!\n"]}],"source":["# ============================================================\n","# 2) INSTALL FAISS\n","# ============================================================\n","\n","print(\"üì¶ Installing FAISS...\\n\")\n","\n","# Install faiss-cpu (faiss-gpu for GPU support)\n","!pip install -q faiss-cpu\n","# For GPU: !pip install -q faiss-gpu\n","\n","print(\"\\n‚úÖ FAISS installed!\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHK63m-_4ed1","executionInfo":{"status":"ok","timestamp":1766152368504,"user_tz":-180,"elapsed":453,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"1800edb1-ab5d-4ff4-b3e1-8e0d75008ee8"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ All imports successful!\n","   FAISS version: 1.13.1\n"]}],"source":["# ============================================================\n","# 3) IMPORTS\n","# ============================================================\n","\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import json\n","import time\n","import faiss\n","from typing import List, Tuple\n","from tqdm.auto import tqdm\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"‚úÖ All imports successful!\")\n","print(f\"   FAISS version: {faiss.__version__}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoC4EGN34ed1","executionInfo":{"status":"ok","timestamp":1766152369523,"user_tz":-180,"elapsed":1018,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"32a1eabe-0c12-4ece-9467-3bdd2c43d31f"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìÅ Directories:\n","   Embeddings: /content/drive/MyDrive/ai_fashion_assistant_v2/embeddings\n","   Hybrid: /content/drive/MyDrive/ai_fashion_assistant_v2/embeddings/hybrid\n","   Indexes: /content/drive/MyDrive/ai_fashion_assistant_v2/indexes\n"]}],"source":["# ============================================================\n","# 4) PATHS & CONFIG\n","# ============================================================\n","\n","PROJECT_ROOT = Path(\"/content/drive/MyDrive/ai_fashion_assistant_v2\")\n","EMB_DIR = PROJECT_ROOT / \"embeddings\"\n","EMB_TEXT_DIR = EMB_DIR / \"text\"\n","EMB_IMAGE_DIR = EMB_DIR / \"image\"\n","EMB_HYBRID_DIR = EMB_DIR / \"hybrid\"\n","INDEX_DIR = PROJECT_ROOT / \"indexes\"\n","\n","# Create directories\n","EMB_HYBRID_DIR.mkdir(parents=True, exist_ok=True)\n","INDEX_DIR.mkdir(parents=True, exist_ok=True)\n","\n","print(\"üìÅ Directories:\")\n","print(f\"   Embeddings: {EMB_DIR}\")\n","print(f\"   Hybrid: {EMB_HYBRID_DIR}\")\n","print(f\"   Indexes: {INDEX_DIR}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NYaZ4cCD4ed1","executionInfo":{"status":"ok","timestamp":1766152377325,"user_tz":-180,"elapsed":7797,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"b327713b-0f34-4508-8b1d-236e47729623"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìÇ LOADING EMBEDDINGS...\n","\n","================================================================================\n","Loading text embeddings...\n","‚úÖ Text embeddings loaded\n","   Path: combined_1280d_normalized.npy\n","   Shape: (44417, 1536)\n","   Size: 260.3 MB\n","\n","Loading image embeddings...\n","‚úÖ Image embeddings loaded\n","   Path: clip_image_768d_normalized.npy\n","   Shape: (44417, 768)\n","   Size: 130.1 MB\n","\n","================================================================================\n","‚úÖ All embeddings loaded!\n","   Total products: 44,417\n"]}],"source":["# ============================================================\n","# 5) LOAD EMBEDDINGS\n","# ============================================================\n","\n","print(\"üìÇ LOADING EMBEDDINGS...\\n\")\n","print(\"=\" * 80)\n","\n","# Load text embeddings (normalized)\n","print(\"Loading text embeddings...\")\n","text_emb_path = EMB_TEXT_DIR / \"combined_1280d_normalized.npy\"\n","if not text_emb_path.exists():\n","    # Try non-normalized\n","    text_emb_path = EMB_TEXT_DIR / \"combined_1536d.npy\"\n","    print(f\"  Using non-normalized version\")\n","\n","text_embeddings = np.load(text_emb_path)\n","print(f\"‚úÖ Text embeddings loaded\")\n","print(f\"   Path: {text_emb_path.name}\")\n","print(f\"   Shape: {text_embeddings.shape}\")\n","print(f\"   Size: {text_emb_path.stat().st_size / 1024**2:.1f} MB\")\n","\n","# Load image embeddings (normalized)\n","print(\"\\nLoading image embeddings...\")\n","image_emb_path = EMB_IMAGE_DIR / \"clip_image_768d_normalized.npy\"\n","image_embeddings = np.load(image_emb_path)\n","print(f\"‚úÖ Image embeddings loaded\")\n","print(f\"   Path: {image_emb_path.name}\")\n","print(f\"   Shape: {image_embeddings.shape}\")\n","print(f\"   Size: {image_emb_path.stat().st_size / 1024**2:.1f} MB\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(f\"‚úÖ All embeddings loaded!\")\n","print(f\"   Total products: {len(text_embeddings):,}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tg9pnLHj4ed2","executionInfo":{"status":"ok","timestamp":1766152378006,"user_tz":-180,"elapsed":678,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"8aeae7ca-e874-4275-af54-8e3da453ebdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîó CREATING HYBRID EMBEDDINGS...\n","\n","================================================================================\n","Text shape: (44417, 1536)\n","Image shape: (44417, 768)\n","\n","Concatenating...\n","\n","‚úÖ Hybrid embeddings created!\n","   Shape: (44417, 2304)\n","   Expected: (44417, 2304)\n","   Dimension: 2304d\n","\n","‚úÖ No NaN values\n","\n","Saving hybrid embeddings...\n","‚úÖ Saved: /content/drive/MyDrive/ai_fashion_assistant_v2/embeddings/hybrid/hybrid_2304d.npy\n","   Size: 390.4 MB\n"]}],"source":["# ============================================================\n","# 6) CREATE HYBRID EMBEDDINGS\n","# ============================================================\n","\n","print(\"üîó CREATING HYBRID EMBEDDINGS...\\n\")\n","print(\"=\" * 80)\n","\n","# Validate shapes match\n","assert len(text_embeddings) == len(image_embeddings), \\\n","    f\"Shape mismatch! Text: {len(text_embeddings)}, Image: {len(image_embeddings)}\"\n","\n","print(f\"Text shape: {text_embeddings.shape}\")\n","print(f\"Image shape: {image_embeddings.shape}\")\n","\n","# Concatenate\n","print(\"\\nConcatenating...\")\n","hybrid_embeddings = np.concatenate([text_embeddings, image_embeddings], axis=1)\n","\n","print(f\"\\n‚úÖ Hybrid embeddings created!\")\n","print(f\"   Shape: {hybrid_embeddings.shape}\")\n","print(f\"   Expected: ({len(text_embeddings)}, {text_embeddings.shape[1] + image_embeddings.shape[1]})\")\n","print(f\"   Dimension: {hybrid_embeddings.shape[1]}d\")\n","\n","# Check for NaN\n","has_nan = np.isnan(hybrid_embeddings).any()\n","if has_nan:\n","    print(\"\\n‚ö†Ô∏è WARNING: NaN values detected!\")\n","    nan_count = np.isnan(hybrid_embeddings).sum()\n","    print(f\"   NaN count: {nan_count}\")\n","else:\n","    print(\"\\n‚úÖ No NaN values\")\n","\n","# Save\n","print(\"\\nSaving hybrid embeddings...\")\n","output_path = EMB_HYBRID_DIR / \"hybrid_2304d.npy\"\n","np.save(output_path, hybrid_embeddings)\n","print(f\"‚úÖ Saved: {output_path}\")\n","print(f\"   Size: {output_path.stat().st_size / 1024**2:.1f} MB\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40nOg56-4ed2","executionInfo":{"status":"ok","timestamp":1766152379678,"user_tz":-180,"elapsed":1671,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"c6c83789-3d8c-4dfb-aa0a-ab1aa3015e60"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìê NORMALIZING HYBRID EMBEDDINGS...\n","\n","‚úÖ Normalized hybrid embeddings\n","   Shape: (44417, 2304)\n","   Mean norm: 1.0000\n","\n","‚úÖ Saved: /content/drive/MyDrive/ai_fashion_assistant_v2/embeddings/hybrid/hybrid_2304d_normalized.npy\n","   Size: 390.4 MB\n"]}],"source":["# ============================================================\n","# 7) NORMALIZE HYBRID EMBEDDINGS\n","# ============================================================\n","\n","print(\"üìê NORMALIZING HYBRID EMBEDDINGS...\\n\")\n","\n","from sklearn.preprocessing import normalize\n","\n","# Normalize\n","hybrid_normalized = normalize(hybrid_embeddings, norm='l2')\n","\n","print(f\"‚úÖ Normalized hybrid embeddings\")\n","print(f\"   Shape: {hybrid_normalized.shape}\")\n","print(f\"   Mean norm: {np.linalg.norm(hybrid_normalized, axis=1).mean():.4f}\")\n","\n","# Save\n","output_path = EMB_HYBRID_DIR / \"hybrid_2304d_normalized.npy\"\n","np.save(output_path, hybrid_normalized)\n","print(f\"\\n‚úÖ Saved: {output_path}\")\n","print(f\"   Size: {output_path.stat().st_size / 1024**2:.1f} MB\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCh9i02n4ed3","executionInfo":{"status":"ok","timestamp":1766152390616,"user_tz":-180,"elapsed":10927,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"2df55651-547e-48ec-b69e-29390c0941db"},"outputs":[{"output_type":"stream","name":"stdout","text":["üèóÔ∏è BUILDING FAISS INDEX...\n","\n","================================================================================\n","Index parameters:\n","   Dimension: 2304\n","   Vectors: 44,417\n","   Index type: HNSW (Hierarchical Navigable Small World)\n","\n","HNSW parameters:\n","   M: 32\n","   ef_construction: 200\n","   ef_search: 100\n","\n","Building index...\n","Adding vectors...\n","\n","‚úÖ Index built successfully!\n","   Time: 10.8 seconds\n","   Total vectors: 44,417\n","   Is trained: True\n"]}],"source":["# ============================================================\n","# 8) BUILD FAISS INDEX (HNSW)\n","# ============================================================\n","\n","print(\"üèóÔ∏è BUILDING FAISS INDEX...\\n\")\n","print(\"=\" * 80)\n","\n","# Use normalized embeddings for cosine similarity\n","embeddings_for_index = hybrid_normalized.astype('float32')\n","\n","dimension = embeddings_for_index.shape[1]\n","n_vectors = embeddings_for_index.shape[0]\n","\n","print(f\"Index parameters:\")\n","print(f\"   Dimension: {dimension}\")\n","print(f\"   Vectors: {n_vectors:,}\")\n","print(f\"   Index type: HNSW (Hierarchical Navigable Small World)\")\n","\n","# HNSW parameters\n","M = 32  # Number of connections per layer\n","ef_construction = 200  # Build quality\n","ef_search = 100  # Search quality\n","\n","print(f\"\\nHNSW parameters:\")\n","print(f\"   M: {M}\")\n","print(f\"   ef_construction: {ef_construction}\")\n","print(f\"   ef_search: {ef_search}\")\n","\n","# Create index\n","print(\"\\nBuilding index...\")\n","start_time = time.time()\n","\n","index = faiss.IndexHNSWFlat(dimension, M)\n","index.hnsw.efConstruction = ef_construction\n","index.hnsw.efSearch = ef_search\n","\n","# Add vectors\n","print(\"Adding vectors...\")\n","index.add(embeddings_for_index)\n","\n","elapsed = time.time() - start_time\n","\n","print(f\"\\n‚úÖ Index built successfully!\")\n","print(f\"   Time: {elapsed:.1f} seconds\")\n","print(f\"   Total vectors: {index.ntotal:,}\")\n","print(f\"   Is trained: {index.is_trained}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pj_3YILX4ed3","executionInfo":{"status":"ok","timestamp":1766152391138,"user_tz":-180,"elapsed":502,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"d41e85f5-f973-4997-fd80-ffdfc0ab4677"},"outputs":[{"output_type":"stream","name":"stdout","text":["üíæ SAVING FAISS INDEX...\n","\n","‚úÖ Index saved: /content/drive/MyDrive/ai_fashion_assistant_v2/indexes/faiss_hybrid_hnsw.index\n","   Size: 401.9 MB\n"]}],"source":["# ============================================================\n","# 9) SAVE FAISS INDEX\n","# ============================================================\n","\n","print(\"üíæ SAVING FAISS INDEX...\\n\")\n","\n","index_path = INDEX_DIR / \"faiss_hybrid_hnsw.index\"\n","\n","# Save\n","faiss.write_index(index, str(index_path))\n","\n","print(f\"‚úÖ Index saved: {index_path}\")\n","print(f\"   Size: {index_path.stat().st_size / 1024**2:.1f} MB\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHoZgkCk4ed3","executionInfo":{"status":"ok","timestamp":1766152391164,"user_tz":-180,"elapsed":15,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"7637f591-de32-4106-dbdc-a066757362bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç TESTING SEARCH FUNCTIONALITY...\n","\n","================================================================================\n","Test query: Vector #42\n","\n","Searching for top-10 results...\n","\n","‚úÖ Search completed!\n","   Time: 0.93ms\n","\n","Top-10 results:\n","Rank   Index      Distance    \n","------------------------------\n","1      42         1.000000\n","2      28309      0.849985\n","3      42489      0.849597\n","4      7172       0.838907\n","5      3458       0.835715\n","6      1312       0.829875\n","7      39427      0.827966\n","8      24913      0.820948\n","9      24524      0.818811\n","10     40176      0.813978\n","\n","‚úÖ Validation:\n","   First result is query itself: True\n","   Similarity ~1.0: True\n"]}],"source":["# ============================================================\n","# 10) TEST SEARCH FUNCTIONALITY\n","# ============================================================\n","\n","print(\"üîç TESTING SEARCH FUNCTIONALITY...\\n\")\n","print(\"=\" * 80)\n","\n","# Test with random query\n","test_idx = 42\n","test_query = hybrid_normalized[test_idx:test_idx+1].astype('float32')\n","\n","print(f\"Test query: Vector #{test_idx}\")\n","\n","# Search\n","k = 10\n","print(f\"\\nSearching for top-{k} results...\")\n","\n","start_time = time.time()\n","distances, indices = index.search(test_query, k)\n","search_time = (time.time() - start_time) * 1000  # ms\n","\n","print(f\"\\n‚úÖ Search completed!\")\n","print(f\"   Time: {search_time:.2f}ms\")\n","\n","print(f\"\\nTop-{k} results:\")\n","print(f\"{'Rank':<6} {'Index':<10} {'Distance':<12}\")\n","print(\"-\" * 30)\n","for i, (idx, dist) in enumerate(zip(indices[0], distances[0]), 1):\n","    similarity = 1 - dist  # Convert distance to similarity\n","    print(f\"{i:<6} {idx:<10} {similarity:.6f}\")\n","\n","# Validate\n","print(\"\\n‚úÖ Validation:\")\n","print(f\"   First result is query itself: {indices[0][0] == test_idx}\")\n","print(f\"   Similarity ~1.0: {1 - distances[0][0] > 0.99}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HyFynODR4ed4","executionInfo":{"status":"ok","timestamp":1766152391193,"user_tz":-180,"elapsed":27,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"2cc56d3f-f8b6-4ae3-efe9-2e426dcd0426"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚ö° BENCHMARKING SEARCH PERFORMANCE...\n","\n","================================================================================\n","Testing 100 random queries...\n","Retrieving top-10 for each\n","\n","‚úÖ Benchmark results:\n","   Total time: 0.02s\n","   Average per query: 0.17ms\n","   Throughput: 5955.8 queries/sec\n","\n","üìä Performance metrics:\n","   QPS (Queries Per Second): 5955.8\n","   Latency (p50): ~0.17ms\n","\n","üöÄ Excellent! Sub-10ms latency\n"]}],"source":["# ============================================================\n","# 11) BENCHMARK SEARCH PERFORMANCE\n","# ============================================================\n","\n","print(\"‚ö° BENCHMARKING SEARCH PERFORMANCE...\\n\")\n","print(\"=\" * 80)\n","\n","# Test with multiple queries\n","n_test_queries = 100\n","k = 10\n","\n","print(f\"Testing {n_test_queries} random queries...\")\n","print(f\"Retrieving top-{k} for each\\n\")\n","\n","# Random queries\n","test_indices = np.random.randint(0, len(hybrid_normalized), n_test_queries)\n","test_queries = hybrid_normalized[test_indices].astype('float32')\n","\n","# Benchmark\n","start_time = time.time()\n","distances, indices = index.search(test_queries, k)\n","elapsed = time.time() - start_time\n","\n","avg_time_ms = (elapsed / n_test_queries) * 1000\n","\n","print(f\"‚úÖ Benchmark results:\")\n","print(f\"   Total time: {elapsed:.2f}s\")\n","print(f\"   Average per query: {avg_time_ms:.2f}ms\")\n","print(f\"   Throughput: {n_test_queries / elapsed:.1f} queries/sec\")\n","\n","# QPS estimation\n","qps = 1000 / avg_time_ms\n","print(f\"\\nüìä Performance metrics:\")\n","print(f\"   QPS (Queries Per Second): {qps:.1f}\")\n","print(f\"   Latency (p50): ~{avg_time_ms:.2f}ms\")\n","\n","if avg_time_ms < 10:\n","    print(f\"\\nüöÄ Excellent! Sub-10ms latency\")\n","elif avg_time_ms < 50:\n","    print(f\"\\n‚úÖ Good! Acceptable latency for production\")\n","else:\n","    print(f\"\\n‚ö†Ô∏è Slow! Consider optimizing index parameters\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7M9aQjI34ed4","executionInfo":{"status":"ok","timestamp":1766152391199,"user_tz":-180,"elapsed":5,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"2dcc1679-336f-496c-b4e0-079a380481d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìä GENERATING INDEX STATISTICS...\n","\n","================================================================================\n","‚úÖ Stats saved: /content/drive/MyDrive/ai_fashion_assistant_v2/indexes/index_stats.json\n","\n","üìä INDEX SUMMARY:\n","================================================================================\n","Index type: HNSW\n","Dimension: 2304d\n","Total vectors: 44,417\n","\n","Performance:\n","  Avg query time: 0.17ms\n","  QPS: 5955.8\n","================================================================================\n"]}],"source":["# ============================================================\n","# 12) GENERATE INDEX STATISTICS\n","# ============================================================\n","\n","print(\"üìä GENERATING INDEX STATISTICS...\\n\")\n","print(\"=\" * 80)\n","\n","# Statistics\n","stats = {\n","    \"index_type\": \"HNSW\",\n","    \"dimension\": int(dimension),\n","    \"total_vectors\": int(index.ntotal),\n","    \"parameters\": {\n","        \"M\": M,\n","        \"ef_construction\": ef_construction,\n","        \"ef_search\": ef_search\n","    },\n","    \"performance\": {\n","        \"avg_query_time_ms\": float(avg_time_ms),\n","        \"qps\": float(qps)\n","    },\n","    \"files\": {\n","        \"index\": \"faiss_hybrid_hnsw.index\",\n","        \"embeddings\": \"hybrid_2304d_normalized.npy\"\n","    }\n","}\n","\n","# Save stats\n","stats_path = INDEX_DIR / \"index_stats.json\"\n","with open(stats_path, 'w') as f:\n","    json.dump(stats, f, indent=2)\n","\n","print(f\"‚úÖ Stats saved: {stats_path}\")\n","\n","# Print summary\n","print(\"\\nüìä INDEX SUMMARY:\")\n","print(\"=\" * 80)\n","print(f\"Index type: {stats['index_type']}\")\n","print(f\"Dimension: {stats['dimension']}d\")\n","print(f\"Total vectors: {stats['total_vectors']:,}\")\n","print(f\"\\nPerformance:\")\n","print(f\"  Avg query time: {stats['performance']['avg_query_time_ms']:.2f}ms\")\n","print(f\"  QPS: {stats['performance']['qps']:.1f}\")\n","print(\"=\" * 80)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndX-tH5-4ed4","executionInfo":{"status":"ok","timestamp":1766152391216,"user_tz":-180,"elapsed":14,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"e9c33163-51a8-4b32-ba45-89153727bda7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üéØ QUALITY GATES VALIDATION\n","================================================================================\n","‚úÖ Gate 1: Hybrid dimension correct (2304d)\n","‚úÖ Gate 2: FAISS index built (44,417 vectors)\n","‚úÖ Gate 3: Index file saved (401.9 MB)\n","‚ö†Ô∏è Gate 4: Search results may be inaccurate\n","‚úÖ Gate 5: Search performance acceptable (0.17ms)\n","================================================================================\n","\n","üéâ ALL QUALITY GATES PASSED!\n","‚úÖ Hybrid space created successfully!\n","‚úÖ FAISS index ready for retrieval!\n","\n","üéä PHASE 2 COMPLETE!\n","\n","üìç Next: Phase 3 - Retrieval & Baseline Search\n"]}],"source":["# ============================================================\n","# 13) QUALITY GATES VALIDATION\n","# ============================================================\n","\n","print(\"\\nüéØ QUALITY GATES VALIDATION\")\n","print(\"=\" * 80)\n","\n","gates_passed = True\n","\n","# Gate 1: Hybrid dimension correct\n","expected_dim = text_embeddings.shape[1] + image_embeddings.shape[1]\n","if hybrid_embeddings.shape[1] == expected_dim:\n","    print(f\"‚úÖ Gate 1: Hybrid dimension correct ({expected_dim}d)\")\n","else:\n","    print(f\"‚ùå Gate 1: Dimension mismatch! Expected {expected_dim}, got {hybrid_embeddings.shape[1]}\")\n","    gates_passed = False\n","\n","# Gate 2: FAISS index built\n","if index.ntotal == len(hybrid_embeddings):\n","    print(f\"‚úÖ Gate 2: FAISS index built ({index.ntotal:,} vectors)\")\n","else:\n","    print(f\"‚ùå Gate 2: Index vector count mismatch!\")\n","    gates_passed = False\n","\n","# Gate 3: Index file saved\n","if index_path.exists():\n","    size_mb = index_path.stat().st_size / 1024**2\n","    print(f\"‚úÖ Gate 3: Index file saved ({size_mb:.1f} MB)\")\n","else:\n","    print(f\"‚ùå Gate 3: Index file not found!\")\n","    gates_passed = False\n","\n","# Gate 4: Search returns results\n","if indices[0][0] == test_idx and (1 - distances[0][0]) > 0.99:\n","    print(f\"‚úÖ Gate 4: Search returns correct results\")\n","else:\n","    print(f\"‚ö†Ô∏è Gate 4: Search results may be inaccurate\")\n","\n","# Gate 5: Performance acceptable\n","if avg_time_ms < 50:\n","    print(f\"‚úÖ Gate 5: Search performance acceptable ({avg_time_ms:.2f}ms)\")\n","else:\n","    print(f\"‚ö†Ô∏è Gate 5: Search slower than ideal ({avg_time_ms:.2f}ms)\")\n","\n","print(\"=\" * 80)\n","\n","if gates_passed:\n","    print(\"\\nüéâ ALL QUALITY GATES PASSED!\")\n","    print(\"‚úÖ Hybrid space created successfully!\")\n","    print(\"‚úÖ FAISS index ready for retrieval!\")\n","    print(\"\\nüéä PHASE 2 COMPLETE!\")\n","    print(\"\\nüìç Next: Phase 3 - Retrieval & Baseline Search\")\n","else:\n","    print(\"\\n‚ö†Ô∏è SOME QUALITY GATES FAILED!\")\n","    print(\"   Please review and fix before proceeding.\")"]},{"cell_type":"markdown","metadata":{"id":"kc7ieQIz4ed4"},"source":["---\n","\n","## üìã Summary\n","\n","**Phase 2 Complete!** üéä\n","\n","**Files Created:**\n","- ‚úÖ `embeddings/hybrid/hybrid_2304d.npy`\n","- ‚úÖ `embeddings/hybrid/hybrid_2304d_normalized.npy`\n","- ‚úÖ `indexes/faiss_hybrid_hnsw.index`\n","- ‚úÖ `indexes/index_stats.json`\n","\n","**Index Stats:**\n","- Type: HNSW\n","- Dimension: 2304d (1536 text + 768 image)\n","- Vectors: 44,417\n","- Performance: ~5-20ms per query\n","- Size: ~500 MB\n","\n","**Next Phase:** Phase 3 - Retrieval\n","- Baseline search implementation\n","- Query processing\n","- Result ranking\n","\n","---"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","colab":{"provenance":[],"gpuType":"A100"}},"nbformat":4,"nbformat_minor":0}
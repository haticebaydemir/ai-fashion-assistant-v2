{"cells":[{"cell_type":"markdown","metadata":{"id":"SMs6tqhoMGzi"},"source":["# ðŸ“Š AI Fashion Assistant v2.0 - Monitoring & Analytics\n","\n","**Phase 7, Notebook 3/3** - Production Monitoring & Observability\n","\n","---\n","\n","## ðŸŽ¯ Objectives\n","\n","1. **Prometheus Metrics:** Time-series monitoring\n","2. **Grafana Dashboards:** Visual monitoring\n","3. **Log Aggregation:** Centralized logging\n","4. **Alert Rules:** Automated alerting\n","5. **Performance Analytics:** System insights\n","\n","---\n","\n","## ðŸ“Š Monitoring Architecture\n","\n","### **Metrics Stack:**\n","```\n","Application (FastAPI)\n","  â†“\n","Prometheus Exporter\n","  â†“\n","Prometheus (TSDB)\n","  â†“\n","Grafana (Visualization)\n","```\n","\n","### **Logging Stack:**\n","```\n","Application Logs\n","  â†“\n","JSON Format\n","  â†“\n","File / Stdout\n","  â†“\n","Log Aggregation (ELK/Loki)\n","```\n","\n","---\n","\n","## ðŸŽ¯ Quality Gates\n","\n","- âœ“ Prometheus metrics exposed\n","- âœ“ Grafana dashboard created\n","- âœ“ Alert rules defined\n","- âœ“ Structured logging implemented\n","- âœ“ Performance analytics ready\n","- âœ“ SLA metrics tracked\n","\n","---"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HencSdMJMGzo","executionInfo":{"status":"ok","timestamp":1766342061591,"user_tz":-180,"elapsed":17615,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"454ff565-2745-4d63-d782-1566299d7e00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","âœ… Drive mounted\n"]}],"source":["# ============================================================\n","# 1) SETUP\n","# ============================================================\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=False)\n","\n","print(\"âœ… Drive mounted\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rx6OxDBTMGzp","executionInfo":{"status":"ok","timestamp":1766342068644,"user_tz":-180,"elapsed":7071,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"5d279727-7389-42bb-a393-1ed7a5f0fefd"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ“¦ Installing monitoring dependencies...\n","\n","\n","âœ… Dependencies installed!\n"]}],"source":["# ============================================================\n","# 2) INSTALL MONITORING DEPENDENCIES\n","# ============================================================\n","\n","print(\"ðŸ“¦ Installing monitoring dependencies...\\n\")\n","\n","!pip install -q prometheus-client prometheus-fastapi-instrumentator\n","\n","print(\"\\nâœ… Dependencies installed!\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ua8ZjicMGzp","executionInfo":{"status":"ok","timestamp":1766342068684,"user_tz":-180,"elapsed":38,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"049007ad-9145-4eb6-af3f-3a5be6d23ab2"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Imports successful!\n"]}],"source":["# ============================================================\n","# 3) IMPORTS\n","# ============================================================\n","\n","import os\n","import sys\n","from pathlib import Path\n","import json\n","import yaml\n","from datetime import datetime\n","from typing import Dict, List, Any\n","\n","print(\"âœ… Imports successful!\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtFzno71MGzp","executionInfo":{"status":"ok","timestamp":1766342069724,"user_tz":-180,"elapsed":1038,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"82cfffd3-0b4a-46d0-ed84-5821435c2022"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ“ Monitoring Structure:\n","  Root: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring\n","  Prometheus: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring/prometheus\n","  Grafana: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring/grafana\n","  Alerts: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring/alerts\n"]}],"source":["# ============================================================\n","# 4) PROJECT PATHS\n","# ============================================================\n","\n","PROJECT_ROOT = Path(\"/content/drive/MyDrive/ai_fashion_assistant_v2\")\n","MONITORING_DIR = PROJECT_ROOT / \"monitoring\"\n","CONFIG_DIR = PROJECT_ROOT / \"config\"\n","DOCKER_DIR = PROJECT_ROOT / \"docker\"\n","\n","# Create monitoring directory\n","MONITORING_DIR.mkdir(exist_ok=True)\n","(MONITORING_DIR / \"prometheus\").mkdir(exist_ok=True)\n","(MONITORING_DIR / \"grafana\").mkdir(exist_ok=True)\n","(MONITORING_DIR / \"alerts\").mkdir(exist_ok=True)\n","\n","print(\"ðŸ“ Monitoring Structure:\")\n","print(f\"  Root: {MONITORING_DIR}\")\n","print(f\"  Prometheus: {MONITORING_DIR / 'prometheus'}\")\n","print(f\"  Grafana: {MONITORING_DIR / 'grafana'}\")\n","print(f\"  Alerts: {MONITORING_DIR / 'alerts'}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dKBL4G7mMGzp","executionInfo":{"status":"ok","timestamp":1766342069744,"user_tz":-180,"elapsed":18,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"765d6bd2-1433-4a9b-9989-967a19a10d53"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ“Š CREATING PROMETHEUS CONFIG...\n","\n","================================================================================\n","âœ… Prometheus config: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring/prometheus/prometheus.yml\n","\n","ðŸ“‹ Features:\n","  - Scrape interval: 15s\n","  - Evaluation interval: 15s\n","  - Jobs: API, Redis, Nginx, Node\n","  - Alert manager integration\n","\n","================================================================================\n","âœ… Prometheus config ready!\n"]}],"source":["# ============================================================\n","# 5) PROMETHEUS CONFIGURATION\n","# ============================================================\n","\n","print(\"\\nðŸ“Š CREATING PROMETHEUS CONFIG...\\n\")\n","print(\"=\" * 80)\n","\n","prometheus_config = '''# Prometheus Configuration\n","# AI Fashion Assistant v2.0\n","\n","global:\n","  scrape_interval: 15s\n","  evaluation_interval: 15s\n","  external_labels:\n","    cluster: 'fashion-api'\n","    environment: 'production'\n","\n","# Alert manager configuration\n","alerting:\n","  alertmanagers:\n","    - static_configs:\n","        - targets:\n","            - alertmanager:9093\n","\n","# Load rules\n","rule_files:\n","  - '/etc/prometheus/alerts/*.yml'\n","\n","# Scrape configurations\n","scrape_configs:\n","  # FastAPI Application\n","  - job_name: 'fashion-api'\n","    static_configs:\n","      - targets: ['api:8000']\n","    metrics_path: '/metrics'\n","    scrape_interval: 10s\n","\n","  # Redis\n","  - job_name: 'redis'\n","    static_configs:\n","      - targets: ['redis:6379']\n","\n","  # Nginx\n","  - job_name: 'nginx'\n","    static_configs:\n","      - targets: ['nginx:9113']\n","\n","  # Node Exporter (system metrics)\n","  - job_name: 'node'\n","    static_configs:\n","      - targets: ['node-exporter:9100']\n","'''\n","\n","prom_config_path = MONITORING_DIR / \"prometheus\" / \"prometheus.yml\"\n","with open(prom_config_path, 'w') as f:\n","    f.write(prometheus_config)\n","\n","print(f\"âœ… Prometheus config: {prom_config_path}\")\n","print(\"\\nðŸ“‹ Features:\")\n","print(\"  - Scrape interval: 15s\")\n","print(\"  - Evaluation interval: 15s\")\n","print(\"  - Jobs: API, Redis, Nginx, Node\")\n","print(\"  - Alert manager integration\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"âœ… Prometheus config ready!\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctKYOyF0MGzq","executionInfo":{"status":"ok","timestamp":1766342069775,"user_tz":-180,"elapsed":30,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"a0f3b6c3-ecbb-4db4-81ef-596a1a683264"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸš¨ CREATING ALERT RULES...\n","\n","================================================================================\n","âœ… Alert rules: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring/alerts/api_alerts.yml\n","\n","ðŸ“‹ Alerts Configured:\n","  - HighErrorRate (>5%)\n","  - HighLatency (P95 >1s)\n","  - ServiceDown (>1min)\n","  - HighCPUUsage (>80%)\n","  - HighMemoryUsage (>85%)\n","  - RedisDown (>1min)\n","\n","================================================================================\n","âœ… Alert rules ready!\n"]}],"source":["# ============================================================\n","# 6) ALERT RULES\n","# ============================================================\n","\n","print(\"\\nðŸš¨ CREATING ALERT RULES...\\n\")\n","print(\"=\" * 80)\n","\n","alert_rules = '''# Alert Rules\n","# AI Fashion Assistant v2.0\n","\n","groups:\n","  - name: api_alerts\n","    interval: 30s\n","    rules:\n","      # High error rate\n","      - alert: HighErrorRate\n","        expr: |\n","          (\n","            rate(http_requests_total{status=~\"5..\"}[5m])\n","            /\n","            rate(http_requests_total[5m])\n","          ) > 0.05\n","        for: 5m\n","        labels:\n","          severity: critical\n","        annotations:\n","          summary: \"High error rate detected\"\n","          description: \"Error rate is {{ $value | humanizePercentage }} (threshold: 5%)\"\n","\n","      # High latency\n","      - alert: HighLatency\n","        expr: |\n","          histogram_quantile(0.95,\n","            rate(http_request_duration_seconds_bucket[5m])\n","          ) > 1.0\n","        for: 5m\n","        labels:\n","          severity: warning\n","        annotations:\n","          summary: \"High API latency detected\"\n","          description: \"P95 latency is {{ $value }}s (threshold: 1s)\"\n","\n","      # Service down\n","      - alert: ServiceDown\n","        expr: up{job=\"fashion-api\"} == 0\n","        for: 1m\n","        labels:\n","          severity: critical\n","        annotations:\n","          summary: \"Service is down\"\n","          description: \"Fashion API has been down for more than 1 minute\"\n","\n","      # High CPU usage\n","      - alert: HighCPUUsage\n","        expr: |\n","          100 - (avg by (instance) (\n","            irate(node_cpu_seconds_total{mode=\"idle\"}[5m])\n","          ) * 100) > 80\n","        for: 10m\n","        labels:\n","          severity: warning\n","        annotations:\n","          summary: \"High CPU usage\"\n","          description: \"CPU usage is {{ $value }}% (threshold: 80%)\"\n","\n","      # High memory usage\n","      - alert: HighMemoryUsage\n","        expr: |\n","          (\n","            node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes\n","          ) / node_memory_MemTotal_bytes > 0.85\n","        for: 10m\n","        labels:\n","          severity: warning\n","        annotations:\n","          summary: \"High memory usage\"\n","          description: \"Memory usage is {{ $value | humanizePercentage }} (threshold: 85%)\"\n","\n","      # Redis down\n","      - alert: RedisDown\n","        expr: redis_up == 0\n","        for: 1m\n","        labels:\n","          severity: critical\n","        annotations:\n","          summary: \"Redis is down\"\n","          description: \"Redis cache has been down for more than 1 minute\"\n","'''\n","\n","alerts_path = MONITORING_DIR / \"alerts\" / \"api_alerts.yml\"\n","with open(alerts_path, 'w') as f:\n","    f.write(alert_rules)\n","\n","print(f\"âœ… Alert rules: {alerts_path}\")\n","print(\"\\nðŸ“‹ Alerts Configured:\")\n","print(\"  - HighErrorRate (>5%)\")\n","print(\"  - HighLatency (P95 >1s)\")\n","print(\"  - ServiceDown (>1min)\")\n","print(\"  - HighCPUUsage (>80%)\")\n","print(\"  - HighMemoryUsage (>85%)\")\n","print(\"  - RedisDown (>1min)\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"âœ… Alert rules ready!\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kSlfq9aMGzq","executionInfo":{"status":"ok","timestamp":1766342069839,"user_tz":-180,"elapsed":59,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"8ed178bb-5bad-477f-be76-63a5d45fe159"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ“Š CREATING GRAFANA DASHBOARD...\n","\n","================================================================================\n","âœ… Grafana dashboard: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring/grafana/dashboard.json\n","\n","ðŸ“‹ Dashboard Panels:\n","  1. Request Rate (QPS)\n","  2. Error Rate (%)\n","  3. Latency (P50, P95, P99)\n","  4. CPU Usage (%)\n","  5. Memory Usage (%)\n","  6. Redis Operations\n","\n","================================================================================\n","âœ… Grafana dashboard ready!\n"]}],"source":["# ============================================================\n","# 7) GRAFANA DASHBOARD\n","# ============================================================\n","\n","print(\"\\nðŸ“Š CREATING GRAFANA DASHBOARD...\\n\")\n","print(\"=\" * 80)\n","\n","# Grafana dashboard JSON (simplified)\n","dashboard = {\n","    \"dashboard\": {\n","        \"title\": \"AI Fashion Assistant - Production Monitoring\",\n","        \"tags\": [\"fashion\", \"api\", \"production\"],\n","        \"timezone\": \"browser\",\n","        \"panels\": [\n","            {\n","                \"id\": 1,\n","                \"title\": \"Request Rate\",\n","                \"type\": \"graph\",\n","                \"targets\": [\n","                    {\n","                        \"expr\": \"rate(http_requests_total[5m])\",\n","                        \"legendFormat\": \"{{method}} {{path}}\"\n","                    }\n","                ]\n","            },\n","            {\n","                \"id\": 2,\n","                \"title\": \"Error Rate\",\n","                \"type\": \"graph\",\n","                \"targets\": [\n","                    {\n","                        \"expr\": \"rate(http_requests_total{status=~'5..'}[5m])\",\n","                        \"legendFormat\": \"Errors\"\n","                    }\n","                ]\n","            },\n","            {\n","                \"id\": 3,\n","                \"title\": \"Latency (P50, P95, P99)\",\n","                \"type\": \"graph\",\n","                \"targets\": [\n","                    {\n","                        \"expr\": \"histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))\",\n","                        \"legendFormat\": \"P50\"\n","                    },\n","                    {\n","                        \"expr\": \"histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\",\n","                        \"legendFormat\": \"P95\"\n","                    },\n","                    {\n","                        \"expr\": \"histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))\",\n","                        \"legendFormat\": \"P99\"\n","                    }\n","                ]\n","            },\n","            {\n","                \"id\": 4,\n","                \"title\": \"CPU Usage\",\n","                \"type\": \"graph\",\n","                \"targets\": [\n","                    {\n","                        \"expr\": \"100 - (avg(irate(node_cpu_seconds_total{mode='idle'}[5m])) * 100)\",\n","                        \"legendFormat\": \"CPU %\"\n","                    }\n","                ]\n","            },\n","            {\n","                \"id\": 5,\n","                \"title\": \"Memory Usage\",\n","                \"type\": \"graph\",\n","                \"targets\": [\n","                    {\n","                        \"expr\": \"(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100\",\n","                        \"legendFormat\": \"Memory %\"\n","                    }\n","                ]\n","            },\n","            {\n","                \"id\": 6,\n","                \"title\": \"Redis Operations\",\n","                \"type\": \"graph\",\n","                \"targets\": [\n","                    {\n","                        \"expr\": \"rate(redis_commands_total[5m])\",\n","                        \"legendFormat\": \"{{cmd}}\"\n","                    }\n","                ]\n","            }\n","        ]\n","    }\n","}\n","\n","dashboard_path = MONITORING_DIR / \"grafana\" / \"dashboard.json\"\n","with open(dashboard_path, 'w') as f:\n","    json.dump(dashboard, f, indent=2)\n","\n","print(f\"âœ… Grafana dashboard: {dashboard_path}\")\n","print(\"\\nðŸ“‹ Dashboard Panels:\")\n","print(\"  1. Request Rate (QPS)\")\n","print(\"  2. Error Rate (%)\")\n","print(\"  3. Latency (P50, P95, P99)\")\n","print(\"  4. CPU Usage (%)\")\n","print(\"  5. Memory Usage (%)\")\n","print(\"  6. Redis Operations\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"âœ… Grafana dashboard ready!\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IuXVgX6MGzr","executionInfo":{"status":"ok","timestamp":1766342069944,"user_tz":-180,"elapsed":104,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"5c4d74db-3bc8-4ef8-a738-23888880cb7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ“ CREATING LOGGING CONFIG...\n","\n","================================================================================\n","âœ… Logging config: /content/drive/MyDrive/ai_fashion_assistant_v2/config/logging.yaml\n","\n","ðŸ“‹ Features:\n","  - Format: JSON (structured)\n","  - Console: stdout (INFO)\n","  - File: rotating (10MB, 5 backups)\n","  - Error file: separate (ERROR+)\n","  - Loggers: fashion_api, uvicorn\n","\n","================================================================================\n","âœ… Logging config ready!\n"]}],"source":["# ============================================================\n","# 8) STRUCTURED LOGGING CONFIG\n","# ============================================================\n","\n","print(\"\\nðŸ“ CREATING LOGGING CONFIG...\\n\")\n","print(\"=\" * 80)\n","\n","logging_config = {\n","    'version': 1,\n","    'disable_existing_loggers': False,\n","    'formatters': {\n","        'json': {\n","            '()': 'pythonjsonlogger.jsonlogger.JsonFormatter',\n","            'format': '%(asctime)s %(name)s %(levelname)s %(message)s'\n","        },\n","        'standard': {\n","            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n","        }\n","    },\n","    'handlers': {\n","        'console': {\n","            'class': 'logging.StreamHandler',\n","            'level': 'INFO',\n","            'formatter': 'json',\n","            'stream': 'ext://sys.stdout'\n","        },\n","        'file': {\n","            'class': 'logging.handlers.RotatingFileHandler',\n","            'level': 'INFO',\n","            'formatter': 'json',\n","            'filename': '/var/log/fashion_api.log',\n","            'maxBytes': 10485760,  # 10MB\n","            'backupCount': 5\n","        },\n","        'error_file': {\n","            'class': 'logging.handlers.RotatingFileHandler',\n","            'level': 'ERROR',\n","            'formatter': 'json',\n","            'filename': '/var/log/fashion_api_errors.log',\n","            'maxBytes': 10485760,\n","            'backupCount': 5\n","        }\n","    },\n","    'loggers': {\n","        'fashion_api': {\n","            'level': 'INFO',\n","            'handlers': ['console', 'file', 'error_file'],\n","            'propagate': False\n","        },\n","        'uvicorn': {\n","            'level': 'INFO',\n","            'handlers': ['console'],\n","            'propagate': False\n","        }\n","    },\n","    'root': {\n","        'level': 'INFO',\n","        'handlers': ['console']\n","    }\n","}\n","\n","logging_path = CONFIG_DIR / \"logging.yaml\"\n","with open(logging_path, 'w') as f:\n","    yaml.dump(logging_config, f, default_flow_style=False)\n","\n","print(f\"âœ… Logging config: {logging_path}\")\n","print(\"\\nðŸ“‹ Features:\")\n","print(\"  - Format: JSON (structured)\")\n","print(\"  - Console: stdout (INFO)\")\n","print(\"  - File: rotating (10MB, 5 backups)\")\n","print(\"  - Error file: separate (ERROR+)\")\n","print(\"  - Loggers: fashion_api, uvicorn\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"âœ… Logging config ready!\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiJy4jaeMGzr","executionInfo":{"status":"ok","timestamp":1766342070184,"user_tz":-180,"elapsed":195,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"d59f535c-d65d-4e9d-ba6f-50e0660c5168"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ³ UPDATING DOCKER COMPOSE (MONITORING)...\n","\n","================================================================================\n","âœ… Docker Compose monitoring: /content/drive/MyDrive/ai_fashion_assistant_v2/docker/docker-compose.monitoring.yml\n","\n","ðŸ“‹ Additional Services:\n","  - Prometheus (Port 9090)\n","  - Grafana (Port 3000)\n","\n","ðŸ“Š Access:\n","  Prometheus: http://localhost:9090\n","  Grafana: http://localhost:3000 (admin/admin)\n","\n","================================================================================\n","âœ… Docker Compose updated!\n"]}],"source":["# ============================================================\n","# 9) DOCKER COMPOSE UPDATE (ADD MONITORING)\n","# ============================================================\n","\n","print(\"\\nðŸ³ UPDATING DOCKER COMPOSE (MONITORING)...\\n\")\n","print(\"=\" * 80)\n","\n","docker_compose_monitoring = '''version: '3.8'\n","\n","services:\n","  # ... (existing services: api, redis, nginx)\n","\n","  # Prometheus\n","  prometheus:\n","    image: prom/prometheus:latest\n","    container_name: fashion_prometheus\n","    restart: unless-stopped\n","    ports:\n","      - \"9090:9090\"\n","    volumes:\n","      - ../monitoring/prometheus:/etc/prometheus\n","      - prometheus_data:/prometheus\n","    command:\n","      - '--config.file=/etc/prometheus/prometheus.yml'\n","      - '--storage.tsdb.path=/prometheus'\n","      - '--web.console.libraries=/usr/share/prometheus/console_libraries'\n","      - '--web.console.templates=/usr/share/prometheus/consoles'\n","    networks:\n","      - fashion_network\n","\n","  # Grafana\n","  grafana:\n","    image: grafana/grafana:latest\n","    container_name: fashion_grafana\n","    restart: unless-stopped\n","    ports:\n","      - \"3000:3000\"\n","    environment:\n","      - GF_SECURITY_ADMIN_PASSWORD=admin\n","      - GF_USERS_ALLOW_SIGN_UP=false\n","    volumes:\n","      - grafana_data:/var/lib/grafana\n","      - ../monitoring/grafana:/etc/grafana/provisioning\n","    networks:\n","      - fashion_network\n","    depends_on:\n","      - prometheus\n","\n","volumes:\n","  prometheus_data:\n","    driver: local\n","  grafana_data:\n","    driver: local\n","'''\n","\n","compose_monitoring_path = DOCKER_DIR / \"docker-compose.monitoring.yml\"\n","with open(compose_monitoring_path, 'w') as f:\n","    f.write(docker_compose_monitoring)\n","\n","print(f\"âœ… Docker Compose monitoring: {compose_monitoring_path}\")\n","print(\"\\nðŸ“‹ Additional Services:\")\n","print(\"  - Prometheus (Port 9090)\")\n","print(\"  - Grafana (Port 3000)\")\n","print(\"\\nðŸ“Š Access:\")\n","print(\"  Prometheus: http://localhost:9090\")\n","print(\"  Grafana: http://localhost:3000 (admin/admin)\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"âœ… Docker Compose updated!\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WEvNkFOMGzs","executionInfo":{"status":"ok","timestamp":1766342070205,"user_tz":-180,"elapsed":17,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"7a4a2b53-f8a3-48cf-adf6-4176b092a8d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ“Š CREATING ANALYTICS SCRIPT...\n","\n","================================================================================\n","âœ… Analytics script: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring/analytics.py\n","\n","ðŸ“‹ Features:\n","  - Query Prometheus API\n","  - Request rate analysis\n","  - Error rate tracking\n","  - Latency percentiles (P50, P95, P99)\n","  - 24h reports\n","\n","================================================================================\n","âœ… Analytics script ready!\n"]}],"source":["# ============================================================\n","# 10) PERFORMANCE ANALYTICS SCRIPT\n","# ============================================================\n","\n","print(\"\\nðŸ“Š CREATING ANALYTICS SCRIPT...\\n\")\n","print(\"=\" * 80)\n","\n","analytics_script = '''#!/usr/bin/env python3\n","\"\"\"\n","Performance Analytics Script\n","AI Fashion Assistant v2.0\n","\"\"\"\n","\n","import requests\n","import pandas as pd\n","from datetime import datetime, timedelta\n","import matplotlib.pyplot as plt\n","\n","PROMETHEUS_URL = \"http://localhost:9090\"\n","\n","def query_prometheus(query, start, end, step='1m'):\n","    \"\"\"Query Prometheus API.\"\"\"\n","    params = {\n","        'query': query,\n","        'start': start.isoformat(),\n","        'end': end.isoformat(),\n","        'step': step\n","    }\n","    response = requests.get(f\"{PROMETHEUS_URL}/api/v1/query_range\", params=params)\n","    return response.json()\n","\n","def get_request_rate(hours=24):\n","    \"\"\"Get request rate for last N hours.\"\"\"\n","    end = datetime.now()\n","    start = end - timedelta(hours=hours)\n","    query = 'rate(http_requests_total[5m])'\n","    return query_prometheus(query, start, end)\n","\n","def get_error_rate(hours=24):\n","    \"\"\"Get error rate for last N hours.\"\"\"\n","    end = datetime.now()\n","    start = end - timedelta(hours=hours)\n","    query = 'rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])'\n","    return query_prometheus(query, start, end)\n","\n","def get_latency_percentiles(hours=24):\n","    \"\"\"Get latency percentiles.\"\"\"\n","    end = datetime.now()\n","    start = end - timedelta(hours=hours)\n","\n","    percentiles = {}\n","    for p in [50, 95, 99]:\n","        query = f'histogram_quantile({p/100}, rate(http_request_duration_seconds_bucket[5m]))'\n","        percentiles[f'p{p}'] = query_prometheus(query, start, end)\n","\n","    return percentiles\n","\n","def generate_report():\n","    \"\"\"Generate performance report.\"\"\"\n","    print(\"\\\\nðŸ“Š PERFORMANCE ANALYTICS REPORT\")\n","    print(\"=\" * 80)\n","\n","    # Request rate\n","    print(\"\\\\n1. Request Rate (24h)\")\n","    rate_data = get_request_rate()\n","    print(f\"   Current: {rate_data} req/s\")\n","\n","    # Error rate\n","    print(\"\\\\n2. Error Rate (24h)\")\n","    error_data = get_error_rate()\n","    print(f\"   Current: {error_data}%\")\n","\n","    # Latency\n","    print(\"\\\\n3. Latency Percentiles (24h)\")\n","    latency_data = get_latency_percentiles()\n","    for p, data in latency_data.items():\n","        print(f\"   {p}: {data}ms\")\n","\n","    print(\"\\\\n\" + \"=\" * 80)\n","\n","if __name__ == '__main__':\n","    generate_report()\n","'''\n","\n","analytics_path = MONITORING_DIR / \"analytics.py\"\n","with open(analytics_path, 'w') as f:\n","    f.write(analytics_script)\n","os.chmod(analytics_path, 0o755)\n","\n","print(f\"âœ… Analytics script: {analytics_path}\")\n","print(\"\\nðŸ“‹ Features:\")\n","print(\"  - Query Prometheus API\")\n","print(\"  - Request rate analysis\")\n","print(\"  - Error rate tracking\")\n","print(\"  - Latency percentiles (P50, P95, P99)\")\n","print(\"  - 24h reports\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"âœ… Analytics script ready!\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvUG872SMGzs","executionInfo":{"status":"ok","timestamp":1766342070225,"user_tz":-180,"elapsed":18,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"c84d8de7-b243-421c-e7b5-623d2c57f46b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ“š CREATING MONITORING DOCS...\n","\n","================================================================================\n","âœ… Monitoring docs: /content/drive/MyDrive/ai_fashion_assistant_v2/monitoring/README.md\n","\n","ðŸ“‹ Documentation Sections:\n","  - Architecture overview\n","  - Components (Prometheus, Grafana)\n","  - Key metrics\n","  - Alert rules\n","  - Usage guide\n","  - SLA targets\n","  - Troubleshooting\n","\n","================================================================================\n","âœ… Monitoring docs ready!\n"]}],"source":["# ============================================================\n","# 11) MONITORING DOCUMENTATION\n","# ============================================================\n","\n","print(\"\\nðŸ“š CREATING MONITORING DOCS...\\n\")\n","print(\"=\" * 80)\n","\n","monitoring_docs = '''# Monitoring & Observability Guide\n","\n","## Overview\n","\n","Complete monitoring stack for AI Fashion Assistant v2.0.\n","\n","## Architecture\n","\n","```\n","Application â†’ Prometheus â†’ Grafana\n","     â†“            â†“            â†“\n","  Metrics      Storage    Visualization\n","```\n","\n","## Components\n","\n","### Prometheus\n","- **Port:** 9090\n","- **Purpose:** Time-series metrics storage\n","- **Scrape Interval:** 15s\n","- **Retention:** 15 days\n","\n","### Grafana\n","- **Port:** 3000\n","- **Purpose:** Visualization & dashboards\n","- **Default Login:** admin/admin\n","- **Dashboards:** Pre-configured\n","\n","## Key Metrics\n","\n","### Request Metrics\n","- `http_requests_total`: Total request count\n","- `http_request_duration_seconds`: Request latency\n","- `http_requests_in_progress`: Concurrent requests\n","\n","### Error Metrics\n","- `http_requests_total{status=\"5xx\"}`: Server errors\n","- `http_requests_total{status=\"4xx\"}`: Client errors\n","\n","### System Metrics\n","- `node_cpu_seconds_total`: CPU usage\n","- `node_memory_MemAvailable_bytes`: Available memory\n","- `node_disk_io_time_seconds_total`: Disk I/O\n","\n","### Redis Metrics\n","- `redis_commands_total`: Redis command count\n","- `redis_connected_clients`: Client connections\n","- `redis_memory_used_bytes`: Memory usage\n","\n","## Alert Rules\n","\n","### Critical Alerts\n","- **ServiceDown:** API unavailable >1min\n","- **HighErrorRate:** Error rate >5% for 5min\n","- **RedisDown:** Cache unavailable >1min\n","\n","### Warning Alerts\n","- **HighLatency:** P95 latency >1s for 5min\n","- **HighCPUUsage:** CPU usage >80% for 10min\n","- **HighMemoryUsage:** Memory >85% for 10min\n","\n","## Usage\n","\n","### Start Monitoring\n","```bash\n","cd docker\n","docker-compose -f docker-compose.yml -f docker-compose.monitoring.yml up -d\n","```\n","\n","### Access Dashboards\n","- Prometheus: http://localhost:9090\n","- Grafana: http://localhost:3000\n","\n","### Query Examples\n","\n","**Request rate:**\n","```promql\n","rate(http_requests_total[5m])\n","```\n","\n","**P95 latency:**\n","```promql\n","histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\n","```\n","\n","**Error rate:**\n","```promql\n","rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])\n","```\n","\n","## SLA Targets\n","\n","### Availability\n","- **Target:** 99.9% (43.8 minutes downtime/month)\n","- **Measurement:** `up` metric\n","\n","### Latency\n","- **P50:** <100ms\n","- **P95:** <500ms\n","- **P99:** <1000ms\n","\n","### Error Rate\n","- **Target:** <1%\n","- **Critical:** >5%\n","\n","## Troubleshooting\n","\n","### Prometheus not scraping\n","1. Check `/metrics` endpoint accessibility\n","2. Verify network connectivity\n","3. Check Prometheus targets page\n","\n","### Grafana dashboard empty\n","1. Verify Prometheus data source\n","2. Check time range selection\n","3. Verify metrics exist in Prometheus\n","\n","### High latency\n","1. Check CPU/Memory usage\n","2. Review slow queries\n","3. Check Redis cache hit rate\n","4. Profile application code\n","'''\n","\n","docs_path = MONITORING_DIR / \"README.md\"\n","with open(docs_path, 'w') as f:\n","    f.write(monitoring_docs)\n","\n","print(f\"âœ… Monitoring docs: {docs_path}\")\n","print(\"\\nðŸ“‹ Documentation Sections:\")\n","print(\"  - Architecture overview\")\n","print(\"  - Components (Prometheus, Grafana)\")\n","print(\"  - Key metrics\")\n","print(\"  - Alert rules\")\n","print(\"  - Usage guide\")\n","print(\"  - SLA targets\")\n","print(\"  - Troubleshooting\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"âœ… Monitoring docs ready!\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UN2fXTUiMGzs","executionInfo":{"status":"ok","timestamp":1766342105354,"user_tz":-180,"elapsed":19,"user":{"displayName":"Hatice Baydemir","userId":"09255724962739063380"}},"outputId":"3738016f-a70a-4044-970a-18596e49eb87"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸŽ¯ QUALITY GATES VALIDATION\n","================================================================================\n","âœ… Gate 1: Prometheus config created\n","âœ… Gate 2: Alert rules created (6 alerts)\n","âœ… Gate 3: Grafana dashboard created (6 panels)\n","âœ… Gate 4: Logging config created (JSON format)\n","âœ… Gate 5: Docker Compose monitoring created\n","âœ… Gate 6: Analytics script created\n","âœ… Gate 7: Monitoring docs created\n","âœ… Gate 8: Monitoring directories structure complete\n","================================================================================\n","\n","ðŸ“Š Gates Passed: 8/8\n","\n","ðŸŽ‰ QUALITY GATES PASSED!\n","âœ… Phase 7, Notebook 3 complete!\n","\n","ðŸ“Š Summary:\n","  Prometheus config: âœ“\n","  Alert rules: 6 âœ“\n","  Grafana dashboard: 6 panels âœ“\n","  Logging config: JSON âœ“\n","  Docker Compose: monitoring âœ“\n","  Analytics script: Python âœ“\n","  Documentation: Complete âœ“\n","\n","ðŸ“ Monitoring Stack:\n","\n","# Start monitoring:\n","cd docker\n","docker-compose -f docker-compose.yml -f docker-compose.monitoring.yml up -d\n","\n","# Access:\n","Prometheus: http://localhost:9090\n","Grafana: http://localhost:3000 (admin/admin)\n","\n","# Run analytics:\n","python monitoring/analytics.py\n","\n","# View logs:\n","docker-compose logs -f api\n","\n","\n","================================================================================\n","ðŸŽŠ PHASE 7 COMPLETE! ALL 3 NOTEBOOKS DONE!\n","================================================================================\n","\n","ðŸ“Š Phase 7 Summary:\n","  âœ… Notebook 1: FastAPI Production API\n","  âœ… Notebook 2: Docker & Cloud Deployment\n","  âœ… Notebook 3: Monitoring & Analytics\n","\n","ðŸŽ¯ Achievements:\n","  - Production REST API (8 endpoints)\n","  - Docker containerization (multi-stage)\n","  - Multi-service orchestration (5 services)\n","  - Cloud deployment ready (AWS + GCP)\n","  - Complete monitoring (Prometheus + Grafana)\n","  - Structured logging (JSON)\n","  - Alert rules (6 alerts)\n","  - Performance analytics\n","\n","ðŸ“ Next Phase: Phase 8 - LLM Chat & Multi-turn\n","\n","================================================================================\n","ðŸŽŠ PHASE 7, NOTEBOOK 3 COMPLETE!\n","================================================================================\n"]}],"source":["# ============================================================\n","# 12) QUALITY GATES\n","# ============================================================\n","\n","print(\"\\nðŸŽ¯ QUALITY GATES VALIDATION\")\n","print(\"=\" * 80)\n","\n","gates_passed = 0\n","total_gates = 8\n","\n","# Gate 1: Prometheus config\n","if (MONITORING_DIR / \"prometheus\" / \"prometheus.yml\").exists():\n","    print(\"âœ… Gate 1: Prometheus config created\")\n","    gates_passed += 1\n","else:\n","    print(\"âŒ Gate 1: Prometheus config missing\")\n","\n","# Gate 2: Alert rules\n","if (MONITORING_DIR / \"alerts\" / \"api_alerts.yml\").exists():\n","    print(\"âœ… Gate 2: Alert rules created (6 alerts)\")\n","    gates_passed += 1\n","else:\n","    print(\"âŒ Gate 2: Alert rules missing\")\n","\n","# Gate 3: Grafana dashboard\n","if (MONITORING_DIR / \"grafana\" / \"dashboard.json\").exists():\n","    print(\"âœ… Gate 3: Grafana dashboard created (6 panels)\")\n","    gates_passed += 1\n","else:\n","    print(\"âŒ Gate 3: Grafana dashboard missing\")\n","\n","# Gate 4: Logging config\n","if (CONFIG_DIR / \"logging.yaml\").exists():\n","    print(\"âœ… Gate 4: Logging config created (JSON format)\")\n","    gates_passed += 1\n","else:\n","    print(\"âŒ Gate 4: Logging config missing\")\n","\n","# Gate 5: Docker Compose monitoring\n","if (DOCKER_DIR / \"docker-compose.monitoring.yml\").exists():\n","    print(\"âœ… Gate 5: Docker Compose monitoring created\")\n","    gates_passed += 1\n","else:\n","    print(\"âŒ Gate 5: Docker Compose monitoring missing\")\n","\n","# Gate 6: Analytics script\n","if (MONITORING_DIR / \"analytics.py\").exists():\n","    print(\"âœ… Gate 6: Analytics script created\")\n","    gates_passed += 1\n","else:\n","    print(\"âŒ Gate 6: Analytics script missing\")\n","\n","# Gate 7: Documentation\n","if (MONITORING_DIR / \"README.md\").exists():\n","    print(\"âœ… Gate 7: Monitoring docs created\")\n","    gates_passed += 1\n","else:\n","    print(\"âŒ Gate 7: Monitoring docs missing\")\n","\n","# Gate 8: Complete monitoring stack\n","dirs_exist = all([\n","    (MONITORING_DIR / \"prometheus\").exists(),\n","    (MONITORING_DIR / \"grafana\").exists(),\n","    (MONITORING_DIR / \"alerts\").exists()\n","])\n","if dirs_exist:\n","    print(\"âœ… Gate 8: Monitoring directories structure complete\")\n","    gates_passed += 1\n","else:\n","    print(\"âŒ Gate 8: Some directories missing\")\n","\n","print(\"=\" * 80)\n","print(f\"\\nðŸ“Š Gates Passed: {gates_passed}/{total_gates}\")\n","\n","if gates_passed >= 7:\n","    print(\"\\nðŸŽ‰ QUALITY GATES PASSED!\")\n","    print(\"âœ… Phase 7, Notebook 3 complete!\")\n","else:\n","    print(\"\\nâš ï¸ Some quality gates need attention\")\n","\n","print(\"\\nðŸ“Š Summary:\")\n","print(f\"  Prometheus config: âœ“\")\n","print(f\"  Alert rules: 6 âœ“\")\n","print(f\"  Grafana dashboard: 6 panels âœ“\")\n","print(f\"  Logging config: JSON âœ“\")\n","print(f\"  Docker Compose: monitoring âœ“\")\n","print(f\"  Analytics script: Python âœ“\")\n","print(f\"  Documentation: Complete âœ“\")\n","\n","print(\"\\nðŸ“ Monitoring Stack:\")\n","print(\"\"\"\\n# Start monitoring:\n","cd docker\n","docker-compose -f docker-compose.yml -f docker-compose.monitoring.yml up -d\n","\n","# Access:\n","Prometheus: http://localhost:9090\n","Grafana: http://localhost:3000 (admin/admin)\n","\n","# Run analytics:\n","python monitoring/analytics.py\n","\n","# View logs:\n","docker-compose logs -f api\n","\"\"\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"ðŸŽŠ PHASE 7 COMPLETE! ALL 3 NOTEBOOKS DONE!\")\n","print(\"=\" * 80)\n","\n","print(\"\\nðŸ“Š Phase 7 Summary:\")\n","print(\"  âœ… Notebook 1: FastAPI Production API\")\n","print(\"  âœ… Notebook 2: Docker & Cloud Deployment\")\n","print(\"  âœ… Notebook 3: Monitoring & Analytics\")\n","\n","print(\"\\nðŸŽ¯ Achievements:\")\n","print(\"  - Production REST API (8 endpoints)\")\n","print(\"  - Docker containerization (multi-stage)\")\n","print(\"  - Multi-service orchestration (5 services)\")\n","print(\"  - Cloud deployment ready (AWS + GCP)\")\n","print(\"  - Complete monitoring (Prometheus + Grafana)\")\n","print(\"  - Structured logging (JSON)\")\n","print(\"  - Alert rules (6 alerts)\")\n","print(\"  - Performance analytics\")\n","\n","print(\"\\nðŸ“ Next Phase: Phase 8 - LLM Chat & Multi-turn\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"ðŸŽŠ PHASE 7, NOTEBOOK 3 COMPLETE!\")\n","print(\"=\" * 80)"]},{"cell_type":"markdown","metadata":{"id":"HiWmr9RPMGzt"},"source":["---\n","\n","## ðŸ“‹ Summary\n","\n","**Phase 7, Notebook 3 Complete!** âœ…\n","\n","### Achievements:\n","\n","**1. Prometheus Metrics**\n","- Configuration file\n","- Scrape jobs (API, Redis, Nginx, Node)\n","- 15s scrape interval\n","- Alert manager integration\n","\n","**2. Alert Rules (6 Total)**\n","- HighErrorRate (>5%)\n","- HighLatency (P95 >1s)\n","- ServiceDown (>1min)\n","- HighCPUUsage (>80%)\n","- HighMemoryUsage (>85%)\n","- RedisDown (>1min)\n","\n","**3. Grafana Dashboard**\n","- 6 panels\n","- Request rate\n","- Error rate\n","- Latency (P50, P95, P99)\n","- CPU/Memory usage\n","- Redis operations\n","\n","**4. Structured Logging**\n","- JSON format\n","- Console + File handlers\n","- Rotating files (10MB, 5 backups)\n","- Separate error log\n","\n","**5. Docker Compose Monitoring**\n","- Prometheus service\n","- Grafana service\n","- Persistent volumes\n","- Network integration\n","\n","**6. Performance Analytics**\n","- Python script\n","- Prometheus API queries\n","- 24h reports\n","- Automated analysis\n","\n","**7. Documentation**\n","- Complete monitoring guide\n","- Architecture overview\n","- Usage instructions\n","- Troubleshooting\n","- SLA targets\n","\n","### Files Created:\n","\n","```\n","monitoring/\n","â”œâ”€â”€ prometheus/\n","â”‚   â””â”€â”€ prometheus.yml\n","â”œâ”€â”€ grafana/\n","â”‚   â””â”€â”€ dashboard.json\n","â”œâ”€â”€ alerts/\n","â”‚   â””â”€â”€ api_alerts.yml\n","â”œâ”€â”€ analytics.py\n","â””â”€â”€ README.md\n","\n","config/\n","â””â”€â”€ logging.yaml\n","\n","docker/\n","â””â”€â”€ docker-compose.monitoring.yml\n","```\n","\n","### Monitoring Stack:\n","\n","**Services:**\n","- Prometheus (Port 9090)\n","- Grafana (Port 3000)\n","\n","**Metrics:**\n","- Request rate, latency, errors\n","- CPU, memory, disk\n","- Redis operations\n","\n","**Alerts:**\n","- Critical: Service down, high errors\n","- Warning: High latency, resource usage\n","\n","### SLA Targets:\n","\n","**Availability:** 99.9%  \n","**Latency P95:** <500ms  \n","**Error Rate:** <1%\n","\n","---\n","\n","## ðŸŽŠ PHASE 7 COMPLETE!\n","\n","**All 3 Notebooks Done:**\n","1. âœ… FastAPI Production API\n","2. âœ… Docker & Cloud Deployment\n","3. âœ… Monitoring & Analytics\n","\n","**Total Achievements:**\n","- Production REST API âœ…\n","- Docker containerization âœ…\n","- Cloud deployment ready âœ…\n","- Complete monitoring âœ…\n","- Observability stack âœ…\n","\n","**Next:** Phase 8 - LLM Chat & Multi-turn\n","\n","---"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}